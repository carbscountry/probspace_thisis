{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21107,"status":"ok","timestamp":1682159644981,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"sMVmfQcW79nK","outputId":"6639140b-2a11-4d3f-9436-ad2d694abe42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23615,"status":"ok","timestamp":1682159668593,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"PMsVsVYs8Jib","outputId":"b54d95fb-4a37-44ce-9077-ee0c410c068a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.4)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.98\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1682159668993,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"qonwoL_F8Oe_","outputId":"d41a1ab9-f72f-439a-83ba-de699c8364a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Apr 22 10:34:27 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2tBjTH68Qnb"},"outputs":[],"source":["\n","import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyQ97ca88dRA"},"outputs":[],"source":["DIR = \"/content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","CUSTOM_MODEL_DIR = os.path.join(OUTPUT_DIR,'clrp_deberta_v3_base_epoch20')\n","OUTPUT_EXP_DIR = DIR + '/output/EXP023/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VCF2-czO8Svr"},"outputs":[],"source":["\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model_name=\"microsoft/deberta-v3-base\"\n","    # model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    model = CUSTOM_MODEL_DIR\n","    scheduler='polynomial' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=6\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","    num_reinit_layers = 1\n","    is_reinit_layer = True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7QkA50jQ80_3"},"outputs":[],"source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return accuracy_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_acc_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = accuracy_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    print(f\"thresh : {best_thresh}\")\n","    return accuracy_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRnSUEJR9A9y"},"outputs":[],"source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":1741,"status":"ok","timestamp":1682159679295,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"GUnukiIG9FM5","outputId":"6f464089-1006-48b7-e05b-902d899d8a40"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4974, 6)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                             title  year  \\\n","0   1      Hierarchical Adversarially Learned Inference  2018   \n","1   2    Learning to Compute Word Embeddings On the Fly  2018   \n","2   3  Graph2Seq: Scalable Learning Dynamics for Graphs  2018   \n","\n","                                            abstract  \\\n","0  We propose a novel hierarchical generative mod...   \n","1  Words in natural language follow a Zipfian dis...   \n","2  Neural networks are increasingly used as a gen...   \n","\n","                                            keywords  y  \n","0  generative, hierarchical, unsupervised, semisu...  0  \n","1      NLU, word embeddings, representation learning  0  \n","2                                                NaN  0  "],"text/html":["\n","  <div id=\"df-00ba4264-937f-4e98-9052-cc52092fcc29\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Hierarchical Adversarially Learned Inference</td>\n","      <td>2018</td>\n","      <td>We propose a novel hierarchical generative mod...</td>\n","      <td>generative, hierarchical, unsupervised, semisu...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Learning to Compute Word Embeddings On the Fly</td>\n","      <td>2018</td>\n","      <td>Words in natural language follow a Zipfian dis...</td>\n","      <td>NLU, word embeddings, representation learning</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Graph2Seq: Scalable Learning Dynamics for Graphs</td>\n","      <td>2018</td>\n","      <td>Neural networks are increasingly used as a gen...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00ba4264-937f-4e98-9052-cc52092fcc29')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-00ba4264-937f-4e98-9052-cc52092fcc29 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-00ba4264-937f-4e98-9052-cc52092fcc29');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                              title  year  \\\n","0   1  StyleAlign: Analysis and Applications of Align...  2022   \n","1   2  Embedding a random graph via GNN: mean-field i...  2021   \n","2   3  BBRefinement: an universal scheme to improve p...  2021   \n","\n","                                            abstract  \\\n","0  In this paper, we perform an in-depth study of...   \n","1  We develop a theory for embedding a random gra...   \n","2  We present a conceptually simple yet powerful ...   \n","\n","                                            keywords  \n","0  StyleGAN, transfer learning, fine tuning, mode...  \n","1  Graph neural network, graph embedding, multi-r...  \n","2  object detection, deep neural networks, refine...  "],"text/html":["\n","  <div id=\"df-cf2bb1fa-b9e0-432b-beae-a3b59931b0e5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>StyleAlign: Analysis and Applications of Align...</td>\n","      <td>2022</td>\n","      <td>In this paper, we perform an in-depth study of...</td>\n","      <td>StyleGAN, transfer learning, fine tuning, mode...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Embedding a random graph via GNN: mean-field i...</td>\n","      <td>2021</td>\n","      <td>We develop a theory for embedding a random gra...</td>\n","      <td>Graph neural network, graph embedding, multi-r...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>BBRefinement: an universal scheme to improve p...</td>\n","      <td>2021</td>\n","      <td>We present a conceptually simple yet powerful ...</td>\n","      <td>object detection, deep neural networks, refine...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf2bb1fa-b9e0-432b-beae-a3b59931b0e5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cf2bb1fa-b9e0-432b-beae-a3b59931b0e5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cf2bb1fa-b9e0-432b-beae-a3b59931b0e5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["   id  y\n","0   1  0\n","1   2  0\n","2   3  0"],"text/html":["\n","  <div id=\"df-353e5144-cb15-49c4-8705-088372306700\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-353e5144-cb15-49c4-8705-088372306700')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-353e5144-cb15-49c4-8705-088372306700 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-353e5144-cb15-49c4-8705-088372306700');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train_data.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test_data.csv\"))\n","sample_sub = pd.read_csv(os.path.join(INPUT_DIR,\"submission.csv\"))\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(sample_sub.shape)\n","display(sample_sub.head(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2LAKUbZ9L92"},"outputs":[],"source":["train[\"texts\"] = train[\"title\"] + \"[SEP]\" + train[\"abstract\"]  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MRHQQ6K9Zot"},"outputs":[],"source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.y)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kTf6lgW19iep"},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4001,"status":"ok","timestamp":1682159685551,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"wt2P1uC_9oRd","outputId":"f082df83-546b-4174-e770-4d689b19065b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4974/4974 [00:03<00:00, 1300.49it/s]\n","max_len: 522\n","INFO:__main__:max_len: 522\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 3 # cls\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rmsbpfsc92bq"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df['y'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","source":["def reinit_layers(model):\n","\n","    #for layer in model.model.encoder.layer[-CFG.num_reinit_layers:]:\n","    for layer in model.encoder.layer[-CFG.num_reinit_layers:]:    #Custome model内(backbone)\n","\n","            for module in layer.modules():\n","\n","                if isinstance(module,nn.Linear):\n","                    module.weight.data.normal_(mean=0.0,std=model.config.initializer_range)\n","                    if module.bias is not None:\n","                            module.bias.data.zero_()\n","                elif isinstance(module, nn.Embedding):\n","                        module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                        if module.padding_idx is not None:\n","                            module.weight.data[module.padding_idx].zero_()\n","                elif isinstance(module, nn.LayerNorm):\n","                        module.bias.data.zero_()\n","                        module.weight.data.fill_(1.0)\n","                        \n","    return model"],"metadata":{"id":"lrbC94U9cE_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbE2YLRd9-uk"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if CFG.is_reinit_layer:\n","            self.model = reinit_layers(self.model)\n","            print(f'Reinitializing Last {CFG.num_reinit_layers} Layers.')\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.high_dropout = nn.Dropout(p=0.5)\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self._init_weights(self.layer_norm1)\n","        self.sig = nn.Sigmoid()\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        feature = self.layer_norm1(feature)\n","        #feature = self.sig(feature)\n","        return feature, outputs\n","\n","    def forward(self, inputs=None, labels=None):\n","        feature, outputs = self.feature(inputs)\n","        logits = torch.mean(\n","            torch.stack(\n","                [self.fc(self.high_dropout(feature)) for _ in range(5)],\n","                dim=0,\n","            ),\n","            dim=0,\n","        )\n","        # calculate loss\n","        loss = None\n","        if labels is not None:\n","            loss_fn = nn.MSELoss()\n","            loss = loss_fn(logits.view(-1, 1), labels.view(-1, 1))\n","        \n","        output = (logits,) + outputs[2:]\n","        return ((loss,) + output) if loss is not None else output"]},{"cell_type":"code","source":["class Focal_MultiLabel_Loss(nn.Module):\n","    def __init__(self, gamma):\n","      super(Focal_MultiLabel_Loss, self).__init__()\n","      self.gamma = gamma\n","      self.bceloss = nn.BCEWithLogitsLoss()\n","\n","    def forward(self, outputs, targets):\n","      bce = self.bceloss(outputs.view(-1, 1), targets.view(-1, 1))\n","      bce_exp = torch.exp(-bce)\n","      focal_loss = (1-bce_exp)**self.gamma * bce\n","      return focal_loss.mean()"],"metadata":{"id":"QXpJidbVdCQU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_loss(inputs, labels, model, criterion, is_valid=True, device=\"cpu\"):    \n","    outputs = model(inputs,labels)\n","    loss, logits = outputs[:2]\n","    return (loss, logits) if is_valid else loss"],"metadata":{"id":"R5qmWLL1eeMd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Evhi1yCQ-Xjb"},"outputs":[],"source":["\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            loss = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=False, device=device)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        if scaler is not None:\n","            scaler.unscale_(optimizer)\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  #'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          #grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            loss, y_preds = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=True, device=device)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pR91ZhBL_pW4"},"outputs":[],"source":["\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['y'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr=5e-6, decoder_lr=1e-4, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \n","                    \"LayerNorm.weight\"]\n","        group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n","        group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n","        group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n","        group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n","        optimizer_parameters = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': weight_decay, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': weight_decay, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': weight_decay, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n], 'lr':decoder_lr, \"momentum\" : 0.99},\n","    ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        elif cfg.scheduler == 'polynomial':\n","            warmup_steps = int(len(train_folds) / CFG.batch_size * 0.1)\n","            scheduler = get_polynomial_decay_schedule_with_warmup(\n","                optimizer, warmup_steps, num_train_steps, lr_end=7e-7, power=3.0)\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.MSELoss()\n","    \n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score_05 = get_score(valid_labels, predictions)\n","        score = get_acc_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model_name.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZY5kSe1_1Fl","outputId":"d9b03278-4011-4ad7-adb9-c5b47f894b0f","executionInfo":{"status":"ok","timestamp":1682161991717,"user_tz":-540,"elapsed":2306171,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 3s (remain 16m 41s) Loss: 0.5521(0.5521) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 15s (remain 0m 26s) Loss: 0.3362(0.3035) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.2266(0.2760) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 35s (remain 0m 0s) Loss: 0.1974(0.2624) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.0713(0.0713) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2624  avg_val_loss: 0.1978  time: 39s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2624  avg_val_loss: 0.1978  time: 39s\n","Epoch 1 - Score: 0.7008\n","INFO:__main__:Epoch 1 - Score: 0.7008\n","Epoch 1 - Save Best Score: 0.7008 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7008 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4485(0.1978) \n","f1 score : 0.46841294298921415\n","recall score : 1.0\n","precision score : 0.3058350100603622\n","thresh : 0.6\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.1127(0.1127) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.3336(0.2115) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2384(0.2083) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2189(0.2081) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.1200(0.1200) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2081  avg_val_loss: 0.1971  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2081  avg_val_loss: 0.1971  time: 36s\n","Epoch 2 - Score: 0.7028\n","INFO:__main__:Epoch 2 - Score: 0.7028\n","Epoch 2 - Save Best Score: 0.7028 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7028 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3075(0.1971) \n","f1 score : 0.47058823529411764\n","recall score : 1.0\n","precision score : 0.3076923076923077\n","thresh : 0.64\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.1899(0.1899) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1909(0.1935) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1789(0.1898) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1776(0.1902) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0977(0.0977) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1902  avg_val_loss: 0.1923  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1902  avg_val_loss: 0.1923  time: 36s\n","Epoch 3 - Score: 0.7088\n","INFO:__main__:Epoch 3 - Score: 0.7088\n","Epoch 3 - Save Best Score: 0.7088 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7088 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3539(0.1923) \n","f1 score : 0.4794952681388012\n","recall score : 1.0\n","precision score : 0.3153526970954357\n","thresh : 0.64\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.1337(0.1337) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.0922(0.1690) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1572(0.1697) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2188(0.1704) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.1000(0.1000) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1704  avg_val_loss: 0.1964  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1704  avg_val_loss: 0.1964  time: 36s\n","Epoch 4 - Score: 0.7108\n","INFO:__main__:Epoch 4 - Score: 0.7108\n","Epoch 4 - Save Best Score: 0.7108 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7108 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3475(0.1964) \n","f1 score : 0.49185667752442996\n","recall score : 0.993421052631579\n","precision score : 0.3268398268398268\n","thresh : 0.63\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.1190(0.1190) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1208(0.1610) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1214(0.1565) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1880(0.1544) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0886(0.0886) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1544  avg_val_loss: 0.2015  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1544  avg_val_loss: 0.2015  time: 36s\n","Epoch 5 - Score: 0.7068\n","INFO:__main__:Epoch 5 - Score: 0.7068\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3916(0.2015) \n","f1 score : 0.49662162162162166\n","recall score : 0.9671052631578947\n","precision score : 0.3340909090909091\n","thresh : 0.64\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 24s) Loss: 0.2218(0.2218) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1028(0.1391) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1091(0.1419) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1697(0.1435) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0731(0.0731) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1435  avg_val_loss: 0.2056  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1435  avg_val_loss: 0.2056  time: 36s\n","Epoch 6 - Score: 0.7129\n","INFO:__main__:Epoch 6 - Score: 0.7129\n","Epoch 6 - Save Best Score: 0.7129 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7129 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4388(0.2056) \n","f1 score : 0.5025817555938038\n","recall score : 0.9605263157894737\n","precision score : 0.34032634032634035\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.4197\n","INFO:__main__:Score: 0.4197\n","ACC BEST Score: 0.7129\n","INFO:__main__:ACC BEST Score: 0.7129\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5025817555938038\n","recall score : 0.9605263157894737\n","precision score : 0.34032634032634035\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 45s) Loss: 0.5626(0.5626) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.3046(0.3136) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2958(0.2731) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.3320(0.2568) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0147(0.0147) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2568  avg_val_loss: 0.2358  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2568  avg_val_loss: 0.2358  time: 36s\n","Epoch 1 - Score: 0.7149\n","INFO:__main__:Epoch 1 - Score: 0.7149\n","Epoch 1 - Save Best Score: 0.7149 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7149 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7312(0.2358) \n","f1 score : 0.5017667844522968\n","recall score : 0.9281045751633987\n","precision score : 0.34382566585956414\n","thresh : 0.56\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 47s) Loss: 0.2484(0.2484) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1131(0.2087) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2818(0.2063) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1411(0.2051) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0250(0.0250) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2051  avg_val_loss: 0.2183  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2051  avg_val_loss: 0.2183  time: 36s\n","Epoch 2 - Score: 0.7088\n","INFO:__main__:Epoch 2 - Score: 0.7088\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6439(0.2183) \n","f1 score : 0.4899328859060402\n","recall score : 0.954248366013072\n","precision score : 0.3295711060948081\n","thresh : 0.57\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.1274(0.1274) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1481(0.1820) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2673(0.1848) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1918(0.1843) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0819(0.0819) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1843  avg_val_loss: 0.1902  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1843  avg_val_loss: 0.1902  time: 36s\n","Epoch 3 - Score: 0.7249\n","INFO:__main__:Epoch 3 - Score: 0.7249\n","Epoch 3 - Save Best Score: 0.7249 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7249 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3947(0.1902) \n","f1 score : 0.4757433489827857\n","recall score : 0.9934640522875817\n","precision score : 0.31275720164609055\n","thresh : 0.6\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.1343(0.1343) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2355(0.1789) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2063(0.1737) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1770(0.1717) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0955(0.0955) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1717  avg_val_loss: 0.1902  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1717  avg_val_loss: 0.1902  time: 36s\n","Epoch 4 - Score: 0.7369\n","INFO:__main__:Epoch 4 - Score: 0.7369\n","Epoch 4 - Save Best Score: 0.7369 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7369 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3560(0.1902) \n","f1 score : 0.47634069400630913\n","recall score : 0.9869281045751634\n","precision score : 0.31392931392931395\n","thresh : 0.62\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 47s) Loss: 0.1840(0.1840) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2428(0.1579) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1586(0.1572) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1808(0.1586) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1412(0.1412) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1586  avg_val_loss: 0.2009  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1586  avg_val_loss: 0.2009  time: 36s\n","Epoch 5 - Score: 0.7390\n","INFO:__main__:Epoch 5 - Score: 0.7390\n","Epoch 5 - Save Best Score: 0.7390 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7390 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2714(0.2009) \n","f1 score : 0.471875\n","recall score : 0.9869281045751634\n","precision score : 0.31006160164271046\n","thresh : 0.64\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.1544(0.1544) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1297(0.1516) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2291(0.1509) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1669(0.1498) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0838(0.0838) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1498  avg_val_loss: 0.1944  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1498  avg_val_loss: 0.1944  time: 36s\n","Epoch 6 - Score: 0.7349\n","INFO:__main__:Epoch 6 - Score: 0.7349\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3918(0.1944) \n","f1 score : 0.49337748344370863\n","recall score : 0.9738562091503268\n","precision score : 0.3303769401330377\n","thresh : 0.62\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.3213\n","INFO:__main__:Score: 0.3213\n","ACC BEST Score: 0.7390\n","INFO:__main__:ACC BEST Score: 0.7390\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.471875\n","recall score : 0.9869281045751634\n","precision score : 0.31006160164271046\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 47s) Loss: 0.4299(0.4299) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.2763(0.2731) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2415(0.2571) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2365(0.2492) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0215(0.0215) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2492  avg_val_loss: 0.2240  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2492  avg_val_loss: 0.2240  time: 36s\n","Epoch 1 - Score: 0.7088\n","INFO:__main__:Epoch 1 - Score: 0.7088\n","Epoch 1 - Save Best Score: 0.7088 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7088 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7025(0.2240) \n","f1 score : 0.48465266558966075\n","recall score : 0.9803921568627451\n","precision score : 0.3218884120171674\n","thresh : 0.58\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.1936(0.1936) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1396(0.2098) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1925(0.2108) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2164(0.2094) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0550(0.0550) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2094  avg_val_loss: 0.1931  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2094  avg_val_loss: 0.1931  time: 36s\n","Epoch 2 - Score: 0.7129\n","INFO:__main__:Epoch 2 - Score: 0.7129\n","Epoch 2 - Save Best Score: 0.7129 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7129 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5246(0.1931) \n","f1 score : 0.4801271860095389\n","recall score : 0.9869281045751634\n","precision score : 0.3172268907563025\n","thresh : 0.61\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.2361(0.2361) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1550(0.1959) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1463(0.1903) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1243(0.1888) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0637(0.0637) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1888  avg_val_loss: 0.1888  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1888  avg_val_loss: 0.1888  time: 36s\n","Epoch 3 - Score: 0.7108\n","INFO:__main__:Epoch 3 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4879(0.1888) \n","f1 score : 0.4856230031948881\n","recall score : 0.9934640522875817\n","precision score : 0.321353065539112\n","thresh : 0.61\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.1876(0.1876) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1387(0.1753) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1484(0.1705) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1347(0.1704) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1005(0.1005) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1704  avg_val_loss: 0.1845  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1704  avg_val_loss: 0.1845  time: 36s\n","Epoch 4 - Score: 0.7129\n","INFO:__main__:Epoch 4 - Score: 0.7129\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4032(0.1845) \n","f1 score : 0.4872611464968153\n","recall score : 1.0\n","precision score : 0.32210526315789473\n","thresh : 0.64\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 35s) Loss: 0.1466(0.1466) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2253(0.1613) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1486(0.1591) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1518(0.1593) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1148(0.1148) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1593  avg_val_loss: 0.1863  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1593  avg_val_loss: 0.1863  time: 36s\n","Epoch 5 - Score: 0.7088\n","INFO:__main__:Epoch 5 - Score: 0.7088\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3863(0.1863) \n","f1 score : 0.4903225806451613\n","recall score : 0.9934640522875817\n","precision score : 0.32548179871520344\n","thresh : 0.62\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 35s) Loss: 0.1159(0.1159) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1448(0.1503) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2098(0.1537) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1340(0.1517) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1111(0.1111) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1517  avg_val_loss: 0.1875  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1517  avg_val_loss: 0.1875  time: 36s\n","Epoch 6 - Score: 0.7249\n","INFO:__main__:Epoch 6 - Score: 0.7249\n","Epoch 6 - Save Best Score: 0.7249 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7249 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4082(0.1875) \n","f1 score : 0.5024793388429752\n","recall score : 0.9934640522875817\n","precision score : 0.336283185840708\n","thresh : 0.62\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.3956\n","INFO:__main__:Score: 0.3956\n","ACC BEST Score: 0.7249\n","INFO:__main__:ACC BEST Score: 0.7249\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5024793388429752\n","recall score : 0.9934640522875817\n","precision score : 0.336283185840708\n","thresh : 0.62\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 1.2187(1.2187) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2265(0.3691) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1373(0.3027) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2183(0.2830) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0739(0.0739) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2830  avg_val_loss: 0.2028  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2830  avg_val_loss: 0.2028  time: 36s\n","Epoch 1 - Score: 0.7048\n","INFO:__main__:Epoch 1 - Score: 0.7048\n","Epoch 1 - Save Best Score: 0.7048 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7048 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4719(0.2028) \n","f1 score : 0.47149460708782737\n","recall score : 1.0\n","precision score : 0.3084677419354839\n","thresh : 0.59\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.2017(0.2017) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1581(0.2101) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2707(0.2099) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2477(0.2090) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0674(0.0674) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2090  avg_val_loss: 0.2008  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2090  avg_val_loss: 0.2008  time: 36s\n","Epoch 2 - Score: 0.7068\n","INFO:__main__:Epoch 2 - Score: 0.7068\n","Epoch 2 - Save Best Score: 0.7068 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7068 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4823(0.2008) \n","f1 score : 0.47663551401869164\n","recall score : 1.0\n","precision score : 0.3128834355828221\n","thresh : 0.61\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 45s) Loss: 0.1957(0.1957) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2266(0.1943) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1901(0.1936) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1505(0.1905) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0676(0.0676) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1905  avg_val_loss: 0.1974  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1905  avg_val_loss: 0.1974  time: 36s\n","Epoch 3 - Score: 0.7068\n","INFO:__main__:Epoch 3 - Score: 0.7068\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4541(0.1974) \n","f1 score : 0.48253968253968255\n","recall score : 0.9934640522875817\n","precision score : 0.31865828092243187\n","thresh : 0.6\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.2095(0.2095) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1363(0.1714) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2817(0.1738) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1919(0.1743) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0523(0.0523) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1743  avg_val_loss: 0.2052  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1743  avg_val_loss: 0.2052  time: 36s\n","Epoch 4 - Score: 0.7129\n","INFO:__main__:Epoch 4 - Score: 0.7129\n","Epoch 4 - Save Best Score: 0.7129 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7129 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5228(0.2052) \n","f1 score : 0.5017182130584193\n","recall score : 0.954248366013072\n","precision score : 0.34032634032634035\n","thresh : 0.61\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.1289(0.1289) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1240(0.1652) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0651(0.1621) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2728(0.1617) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0913(0.0913) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1617  avg_val_loss: 0.1945  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1617  avg_val_loss: 0.1945  time: 36s\n","Epoch 5 - Score: 0.7189\n","INFO:__main__:Epoch 5 - Score: 0.7189\n","Epoch 5 - Save Best Score: 0.7189 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7189 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3780(0.1945) \n","f1 score : 0.48445171849427165\n","recall score : 0.9673202614379085\n","precision score : 0.3231441048034934\n","thresh : 0.64\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.1352(0.1352) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1150(0.1480) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 24s (remain 0m 9s) Loss: 0.2099(0.1561) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1387(0.1546) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0594(0.0594) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1546  avg_val_loss: 0.2052  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1546  avg_val_loss: 0.2052  time: 36s\n","Epoch 6 - Score: 0.7249\n","INFO:__main__:Epoch 6 - Score: 0.7249\n","Epoch 6 - Save Best Score: 0.7249 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7249 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4927(0.2052) \n","f1 score : 0.5089605734767026\n","recall score : 0.9281045751633987\n","precision score : 0.3506172839506173\n","thresh : 0.62\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.4498\n","INFO:__main__:Score: 0.4498\n","ACC BEST Score: 0.7249\n","INFO:__main__:ACC BEST Score: 0.7249\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5089605734767026\n","recall score : 0.9281045751633987\n","precision score : 0.3506172839506173\n","thresh : 0.62\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.3482(0.3482) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2897(0.2964) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1082(0.2757) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.3314(0.2615) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0088(0.0088) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2615  avg_val_loss: 0.2934  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2615  avg_val_loss: 0.2934  time: 36s\n","Epoch 1 - Score: 0.7042\n","INFO:__main__:Epoch 1 - Score: 0.7042\n","Epoch 1 - Save Best Score: 0.7042 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7042 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9263(0.2934) \n","f1 score : 0.5050505050505051\n","recall score : 0.6578947368421053\n","precision score : 0.4098360655737705\n","thresh : 0.54\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 45s) Loss: 0.1753(0.1753) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1678(0.2111) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2449(0.2069) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2304(0.2058) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1121(0.1121) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2058  avg_val_loss: 0.1942  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2058  avg_val_loss: 0.1942  time: 36s\n","Epoch 2 - Score: 0.7062\n","INFO:__main__:Epoch 2 - Score: 0.7062\n","Epoch 2 - Save Best Score: 0.7062 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7062 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3270(0.1942) \n","f1 score : 0.46986089644513135\n","recall score : 1.0\n","precision score : 0.30707070707070705\n","thresh : 0.61\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.1921(0.1921) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2820(0.1941) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2031(0.1902) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2165(0.1872) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1213(0.1213) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1872  avg_val_loss: 0.1963  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1872  avg_val_loss: 0.1963  time: 36s\n","Epoch 3 - Score: 0.7143\n","INFO:__main__:Epoch 3 - Score: 0.7143\n","Epoch 3 - Save Best Score: 0.7143 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7143 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2990(0.1963) \n","f1 score : 0.47574334898278564\n","recall score : 1.0\n","precision score : 0.31211498973305957\n","thresh : 0.63\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 45s) Loss: 0.0869(0.0869) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1934(0.1751) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1645(0.1741) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1626(0.1707) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0839(0.0839) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1707  avg_val_loss: 0.1947  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1707  avg_val_loss: 0.1947  time: 36s\n","Epoch 4 - Score: 0.7264\n","INFO:__main__:Epoch 4 - Score: 0.7264\n","Epoch 4 - Save Best Score: 0.7264 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7264 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3845(0.1947) \n","f1 score : 0.48788368336025845\n","recall score : 0.993421052631579\n","precision score : 0.3233404710920771\n","thresh : 0.62\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.1666(0.1666) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1338(0.1554) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1474(0.1557) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1941(0.1546) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0858(0.0858) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1546  avg_val_loss: 0.1987  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1546  avg_val_loss: 0.1987  time: 36s\n","Epoch 5 - Score: 0.7324\n","INFO:__main__:Epoch 5 - Score: 0.7324\n","Epoch 5 - Save Best Score: 0.7324 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7324 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3901(0.1987) \n","f1 score : 0.48701298701298706\n","recall score : 0.9868421052631579\n","precision score : 0.3232758620689655\n","thresh : 0.63\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.1823(0.1823) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1212(0.1413) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1233(0.1408) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1579(0.1420) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1278(0.1278) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1420  avg_val_loss: 0.2051  time: 37s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1420  avg_val_loss: 0.2051  time: 37s\n","Epoch 6 - Score: 0.7304\n","INFO:__main__:Epoch 6 - Score: 0.7304\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3054(0.2051) \n","f1 score : 0.47846889952153104\n","recall score : 0.9868421052631579\n","precision score : 0.3157894736842105\n","thresh : 0.65\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n","Score: 0.3642\n","INFO:__main__:Score: 0.3642\n","ACC BEST Score: 0.7324\n","INFO:__main__:ACC BEST Score: 0.7324\n","========== fold: 5 training ==========\n","INFO:__main__:========== fold: 5 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.48701298701298706\n","recall score : 0.9868421052631579\n","precision score : 0.3232758620689655\n","thresh : 0.63\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.4645(0.4645) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2546(0.3595) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1671(0.2995) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.3059(0.2795) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0146(0.0146) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2795  avg_val_loss: 0.2470  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2795  avg_val_loss: 0.2470  time: 36s\n","Epoch 1 - Score: 0.6942\n","INFO:__main__:Epoch 1 - Score: 0.6942\n","Epoch 1 - Save Best Score: 0.6942 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6942 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7401(0.2470) \n","f1 score : 0.4956672443674177\n","recall score : 0.9407894736842105\n","precision score : 0.33647058823529413\n","thresh : 0.57\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.3017(0.3017) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2041(0.2053) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1234(0.2046) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1356(0.2078) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1166(0.1166) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2078  avg_val_loss: 0.2032  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2078  avg_val_loss: 0.2032  time: 36s\n","Epoch 2 - Score: 0.6942\n","INFO:__main__:Epoch 2 - Score: 0.6942\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3840(0.2032) \n","f1 score : 0.4713178294573644\n","recall score : 1.0\n","precision score : 0.30831643002028397\n","thresh : 0.66\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.2068(0.2068) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1787(0.1956) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1748(0.1905) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1389(0.1889) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1171(0.1171) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1889  avg_val_loss: 0.2040  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1889  avg_val_loss: 0.2040  time: 36s\n","Epoch 3 - Score: 0.6942\n","INFO:__main__:Epoch 3 - Score: 0.6942\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3740(0.2040) \n","f1 score : 0.4740973312401883\n","recall score : 0.993421052631579\n","precision score : 0.311340206185567\n","thresh : 0.65\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.1868(0.1868) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1180(0.1795) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0787(0.1719) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1358(0.1713) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1720(0.1720) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1713  avg_val_loss: 0.2133  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1713  avg_val_loss: 0.2133  time: 36s\n","Epoch 4 - Score: 0.6962\n","INFO:__main__:Epoch 4 - Score: 0.6962\n","Epoch 4 - Save Best Score: 0.6962 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.6962 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2869(0.2133) \n","f1 score : 0.4711388455538222\n","recall score : 0.993421052631579\n","precision score : 0.30879345603271985\n","thresh : 0.71\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.1415(0.1415) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1611(0.1629) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1771(0.1599) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1939(0.1581) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1284(0.1284) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1581  avg_val_loss: 0.2097  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1581  avg_val_loss: 0.2097  time: 36s\n","Epoch 5 - Score: 0.7002\n","INFO:__main__:Epoch 5 - Score: 0.7002\n","Epoch 5 - Save Best Score: 0.7002 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7002 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3551(0.2097) \n","f1 score : 0.4868421052631579\n","recall score : 0.9736842105263158\n","precision score : 0.32456140350877194\n","thresh : 0.68\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.1576(0.1576) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0946(0.1422) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2080(0.1490) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1552(0.1471) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1116(0.1116) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1471  avg_val_loss: 0.2117  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1471  avg_val_loss: 0.2117  time: 36s\n","Epoch 6 - Score: 0.6962\n","INFO:__main__:Epoch 6 - Score: 0.6962\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3860(0.2117) \n","f1 score : 0.48747913188647746\n","recall score : 0.9605263157894737\n","precision score : 0.32662192393736017\n","thresh : 0.68\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 5 result ==========\n","INFO:__main__:========== fold: 5 result ==========\n","Score: 0.3722\n","INFO:__main__:Score: 0.3722\n","ACC BEST Score: 0.7002\n","INFO:__main__:ACC BEST Score: 0.7002\n","========== fold: 6 training ==========\n","INFO:__main__:========== fold: 6 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4868421052631579\n","recall score : 0.9736842105263158\n","precision score : 0.32456140350877194\n","thresh : 0.68\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 47s) Loss: 0.1803(0.1803) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2236(0.3039) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2024(0.2710) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2186(0.2604) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0937(0.0937) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2604  avg_val_loss: 0.1975  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2604  avg_val_loss: 0.1975  time: 36s\n","Epoch 1 - Score: 0.7042\n","INFO:__main__:Epoch 1 - Score: 0.7042\n","Epoch 1 - Save Best Score: 0.7042 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7042 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4232(0.1975) \n","f1 score : 0.46841294298921415\n","recall score : 1.0\n","precision score : 0.3058350100603622\n","thresh : 0.62\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.2360(0.2360) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1961(0.2090) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1900(0.2072) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1184(0.2061) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0695(0.0695) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2061  avg_val_loss: 0.1933  time: 37s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2061  avg_val_loss: 0.1933  time: 37s\n","Epoch 2 - Score: 0.7082\n","INFO:__main__:Epoch 2 - Score: 0.7082\n","Epoch 2 - Save Best Score: 0.7082 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7082 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4571(0.1933) \n","f1 score : 0.4720496894409938\n","recall score : 1.0\n","precision score : 0.3089430894308943\n","thresh : 0.6\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 47s) Loss: 0.2330(0.2330) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1465(0.1846) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 24s (remain 0m 9s) Loss: 0.1946(0.1857) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 33s (remain 0m 0s) Loss: 0.2025(0.1881) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.0913(0.0913) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1881  avg_val_loss: 0.1923  time: 37s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1881  avg_val_loss: 0.1923  time: 37s\n","Epoch 3 - Score: 0.7082\n","INFO:__main__:Epoch 3 - Score: 0.7082\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4006(0.1923) \n","f1 score : 0.4735202492211838\n","recall score : 1.0\n","precision score : 0.31020408163265306\n","thresh : 0.62\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.1670(0.1670) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1176(0.1675) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1931(0.1721) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1714(0.1733) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0717(0.0717) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1733  avg_val_loss: 0.1934  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1733  avg_val_loss: 0.1934  time: 36s\n","Epoch 4 - Score: 0.7062\n","INFO:__main__:Epoch 4 - Score: 0.7062\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4601(0.1934) \n","f1 score : 0.49586776859504134\n","recall score : 0.9868421052631579\n","precision score : 0.33112582781456956\n","thresh : 0.61\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 55s) Loss: 0.1339(0.1339) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1884(0.1589) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1651(0.1600) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1109(0.1618) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1208(0.1208) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1618  avg_val_loss: 0.1963  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1618  avg_val_loss: 0.1963  time: 36s\n","Epoch 5 - Score: 0.7123\n","INFO:__main__:Epoch 5 - Score: 0.7123\n","Epoch 5 - Save Best Score: 0.7123 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7123 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3478(0.1963) \n","f1 score : 0.47936507936507944\n","recall score : 0.993421052631579\n","precision score : 0.3158995815899582\n","thresh : 0.65\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.1661(0.1661) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1314(0.1486) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1520(0.1529) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1689(0.1541) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1078(0.1078) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1541  avg_val_loss: 0.1952  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1541  avg_val_loss: 0.1952  time: 36s\n","Epoch 6 - Score: 0.7103\n","INFO:__main__:Epoch 6 - Score: 0.7103\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3877(0.1952) \n","f1 score : 0.48387096774193544\n","recall score : 0.9868421052631579\n","precision score : 0.32051282051282054\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 6 result ==========\n","INFO:__main__:========== fold: 6 result ==========\n","Score: 0.3400\n","INFO:__main__:Score: 0.3400\n","ACC BEST Score: 0.7123\n","INFO:__main__:ACC BEST Score: 0.7123\n","========== fold: 7 training ==========\n","INFO:__main__:========== fold: 7 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.47936507936507944\n","recall score : 0.993421052631579\n","precision score : 0.3158995815899582\n","thresh : 0.65\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 50s) Loss: 0.2180(0.2180) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2128(0.3060) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.3123(0.2831) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0864(0.2689) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0226(0.0226) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2689  avg_val_loss: 0.2363  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2689  avg_val_loss: 0.2363  time: 36s\n","Epoch 1 - Score: 0.7103\n","INFO:__main__:Epoch 1 - Score: 0.7103\n","Epoch 1 - Save Best Score: 0.7103 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7103 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7023(0.2363) \n","f1 score : 0.48287671232876705\n","recall score : 0.9276315789473685\n","precision score : 0.3263888888888889\n","thresh : 0.57\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.1786(0.1786) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2531(0.2054) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2856(0.2024) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1834(0.2054) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0553(0.0553) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2054  avg_val_loss: 0.2032  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2054  avg_val_loss: 0.2032  time: 36s\n","Epoch 2 - Score: 0.7103\n","INFO:__main__:Epoch 2 - Score: 0.7103\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5132(0.2032) \n","f1 score : 0.47770700636942676\n","recall score : 0.9868421052631579\n","precision score : 0.31512605042016806\n","thresh : 0.59\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.1560(0.1560) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2615(0.2025) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1290(0.1919) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1753(0.1914) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1144(0.1144) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1914  avg_val_loss: 0.1986  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1914  avg_val_loss: 0.1986  time: 36s\n","Epoch 3 - Score: 0.7143\n","INFO:__main__:Epoch 3 - Score: 0.7143\n","Epoch 3 - Save Best Score: 0.7143 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7143 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3536(0.1986) \n","f1 score : 0.4735202492211838\n","recall score : 1.0\n","precision score : 0.31020408163265306\n","thresh : 0.63\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.2331(0.2331) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1880(0.1791) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2059(0.1767) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1451(0.1763) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0941(0.0941) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1763  avg_val_loss: 0.1970  time: 37s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1763  avg_val_loss: 0.1970  time: 37s\n","Epoch 4 - Score: 0.7183\n","INFO:__main__:Epoch 4 - Score: 0.7183\n","Epoch 4 - Save Best Score: 0.7183 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7183 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3940(0.1970) \n","f1 score : 0.48242811501597443\n","recall score : 0.993421052631579\n","precision score : 0.31856540084388185\n","thresh : 0.64\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.1066(0.1066) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1888(0.1694) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1136(0.1684) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1897(0.1650) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0993(0.0993) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1650  avg_val_loss: 0.1969  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1650  avg_val_loss: 0.1969  time: 36s\n","Epoch 5 - Score: 0.7203\n","INFO:__main__:Epoch 5 - Score: 0.7203\n","Epoch 5 - Save Best Score: 0.7203 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7203 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3768(0.1969) \n","f1 score : 0.48000000000000004\n","recall score : 0.9868421052631579\n","precision score : 0.3171247357293869\n","thresh : 0.65\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.2340(0.2340) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1875(0.1550) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1393(0.1560) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0860(0.1567) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0909(0.0909) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1567  avg_val_loss: 0.1968  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1567  avg_val_loss: 0.1968  time: 36s\n","Epoch 6 - Score: 0.7223\n","INFO:__main__:Epoch 6 - Score: 0.7223\n","Epoch 6 - Save Best Score: 0.7223 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7223 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3999(0.1968) \n","f1 score : 0.4813008130081301\n","recall score : 0.9736842105263158\n","precision score : 0.31965442764578833\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 7 result ==========\n","INFO:__main__:========== fold: 7 result ==========\n","Score: 0.3581\n","INFO:__main__:Score: 0.3581\n","ACC BEST Score: 0.7223\n","INFO:__main__:ACC BEST Score: 0.7223\n","========== fold: 8 training ==========\n","INFO:__main__:========== fold: 8 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4813008130081301\n","recall score : 0.9736842105263158\n","precision score : 0.31965442764578833\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.8139(0.8139) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2947(0.3878) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2011(0.3183) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 33s (remain 0m 0s) Loss: 0.2614(0.2912) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0830(0.0830) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2912  avg_val_loss: 0.1947  time: 37s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2912  avg_val_loss: 0.1947  time: 37s\n","Epoch 1 - Score: 0.7123\n","INFO:__main__:Epoch 1 - Score: 0.7123\n","Epoch 1 - Save Best Score: 0.7123 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7123 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4170(0.1947) \n","f1 score : 0.46841294298921415\n","recall score : 1.0\n","precision score : 0.3058350100603622\n","thresh : 0.59\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.1758(0.1758) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2217(0.2155) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2162(0.2146) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0745(0.2122) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0516(0.0516) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2122  avg_val_loss: 0.1953  time: 37s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2122  avg_val_loss: 0.1953  time: 37s\n","Epoch 2 - Score: 0.7163\n","INFO:__main__:Epoch 2 - Score: 0.7163\n","Epoch 2 - Save Best Score: 0.7163 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7163 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4729(0.1953) \n","f1 score : 0.4720496894409938\n","recall score : 1.0\n","precision score : 0.3089430894308943\n","thresh : 0.58\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.2425(0.2425) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.2534(0.1919) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2631(0.1941) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1880(0.1931) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1663(0.1663) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1931  avg_val_loss: 0.1933  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1931  avg_val_loss: 0.1933  time: 36s\n","Epoch 3 - Score: 0.7183\n","INFO:__main__:Epoch 3 - Score: 0.7183\n","Epoch 3 - Save Best Score: 0.7183 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7183 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2180(0.1933) \n","f1 score : 0.46841294298921415\n","recall score : 1.0\n","precision score : 0.3058350100603622\n","thresh : 0.63\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.2544(0.2544) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1352(0.1823) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1881(0.1740) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1545(0.1716) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.1129(0.1129) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1716  avg_val_loss: 0.1845  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1716  avg_val_loss: 0.1845  time: 36s\n","Epoch 4 - Score: 0.7183\n","INFO:__main__:Epoch 4 - Score: 0.7183\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2799(0.1845) \n","f1 score : 0.488673139158576\n","recall score : 0.993421052631579\n","precision score : 0.3240343347639485\n","thresh : 0.62\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.1656(0.1656) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1127(0.1627) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1887(0.1619) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1401(0.1617) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1213(0.1213) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1617  avg_val_loss: 0.1865  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1617  avg_val_loss: 0.1865  time: 36s\n","Epoch 5 - Score: 0.7223\n","INFO:__main__:Epoch 5 - Score: 0.7223\n","Epoch 5 - Save Best Score: 0.7223 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7223 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2544(0.1865) \n","f1 score : 0.4894651539708266\n","recall score : 0.993421052631579\n","precision score : 0.3247311827956989\n","thresh : 0.62\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.1852(0.1852) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0236(0.1513) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1098(0.1543) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1258(0.1547) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1355(0.1355) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1547  avg_val_loss: 0.1908  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1547  avg_val_loss: 0.1908  time: 36s\n","Epoch 6 - Score: 0.7304\n","INFO:__main__:Epoch 6 - Score: 0.7304\n","Epoch 6 - Save Best Score: 0.7304 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7304 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2389(0.1908) \n","f1 score : 0.49185667752442996\n","recall score : 0.993421052631579\n","precision score : 0.3268398268398268\n","thresh : 0.63\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 8 result ==========\n","INFO:__main__:========== fold: 8 result ==========\n","Score: 0.3722\n","INFO:__main__:Score: 0.3722\n","ACC BEST Score: 0.7304\n","INFO:__main__:ACC BEST Score: 0.7304\n","========== fold: 9 training ==========\n","INFO:__main__:========== fold: 9 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch20\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.49185667752442996\n","recall score : 0.993421052631579\n","precision score : 0.3268398268398268\n","thresh : 0.63\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch20 were not used when initializing DebertaV2Model: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Reinitializing Last 1 Layers.\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 49s) Loss: 0.4551(0.4551) LR: 0.00000074  \n","Epoch: [1][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.3042(0.2702) LR: 0.00001752  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2213(0.2562) LR: 0.00001452  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1345(0.2486) LR: 0.00001244  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0999(0.0999) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2486  avg_val_loss: 0.2014  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2486  avg_val_loss: 0.2014  time: 36s\n","Epoch 1 - Score: 0.6982\n","INFO:__main__:Epoch 1 - Score: 0.6982\n","Epoch 1 - Save Best Score: 0.6982 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6982 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3768(0.2014) \n","f1 score : 0.46913580246913583\n","recall score : 1.0\n","precision score : 0.3064516129032258\n","thresh : 0.61\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.1408(0.1408) LR: 0.00001242  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.3439(0.1998) LR: 0.00001008  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0934(0.2020) LR: 0.00000807  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2340(0.2021) LR: 0.00000673  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1258(0.1258) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2021  avg_val_loss: 0.2035  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2021  avg_val_loss: 0.2035  time: 36s\n","Epoch 2 - Score: 0.7022\n","INFO:__main__:Epoch 2 - Score: 0.7022\n","Epoch 2 - Save Best Score: 0.7022 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7022 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3278(0.2035) \n","f1 score : 0.46913580246913583\n","recall score : 1.0\n","precision score : 0.3064516129032258\n","thresh : 0.64\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 47s) Loss: 0.1649(0.1649) LR: 0.00000671  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.1095(0.2002) LR: 0.00000524  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1803(0.1899) LR: 0.00000403  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1987(0.1858) LR: 0.00000325  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1558(0.1558) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1858  avg_val_loss: 0.2124  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1858  avg_val_loss: 0.2124  time: 36s\n","Epoch 3 - Score: 0.7062\n","INFO:__main__:Epoch 3 - Score: 0.7062\n","Epoch 3 - Save Best Score: 0.7062 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7062 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2425(0.2124) \n","f1 score : 0.4713178294573644\n","recall score : 1.0\n","precision score : 0.30831643002028397\n","thresh : 0.66\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.2055(0.2055) LR: 0.00000324  \n","Epoch: [4][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0945(0.1575) LR: 0.00000244  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2690(0.1618) LR: 0.00000182  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1695(0.1616) LR: 0.00000146  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1121(0.1121) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1616  avg_val_loss: 0.2018  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1616  avg_val_loss: 0.2018  time: 36s\n","Epoch 4 - Score: 0.7103\n","INFO:__main__:Epoch 4 - Score: 0.7103\n","Epoch 4 - Save Best Score: 0.7103 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7103 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.2916(0.2018) \n","f1 score : 0.47936507936507944\n","recall score : 0.993421052631579\n","precision score : 0.3158995815899582\n","thresh : 0.65\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 0.1655(0.1655) LR: 0.00000146  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.1193(0.1490) LR: 0.00000112  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1297(0.1482) LR: 0.00000090  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1750(0.1475) LR: 0.00000080  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0795(0.0795) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1475  avg_val_loss: 0.2056  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1475  avg_val_loss: 0.2056  time: 36s\n","Epoch 5 - Score: 0.7103\n","INFO:__main__:Epoch 5 - Score: 0.7103\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3806(0.2056) \n","f1 score : 0.49498327759197325\n","recall score : 0.9736842105263158\n","precision score : 0.33183856502242154\n","thresh : 0.65\n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.0964(0.0964) LR: 0.00000080  \n","Epoch: [6][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.1501(0.1432) LR: 0.00000073  \n","Epoch: [6][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1427(0.1376) LR: 0.00000070  \n","Epoch: [6][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0931(0.1376) LR: 0.00000070  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.0705(0.0705) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1376  avg_val_loss: 0.2093  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.1376  avg_val_loss: 0.2093  time: 36s\n","Epoch 6 - Score: 0.7123\n","INFO:__main__:Epoch 6 - Score: 0.7123\n","Epoch 6 - Save Best Score: 0.7123 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7123 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4022(0.2093) \n","f1 score : 0.4931506849315068\n","recall score : 0.9473684210526315\n","precision score : 0.3333333333333333\n","thresh : 0.63\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 9 result ==========\n","INFO:__main__:========== fold: 9 result ==========\n","Score: 0.4044\n","INFO:__main__:Score: 0.4044\n","ACC BEST Score: 0.7123\n","INFO:__main__:ACC BEST Score: 0.7123\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.3798\n","INFO:__main__:Score: 0.3798\n","ACC BEST Score: 0.7107\n","INFO:__main__:ACC BEST Score: 0.7107\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4931506849315068\n","recall score : 0.9473684210526315\n","precision score : 0.3333333333333333\n","thresh : 0.63\n","f1 score : 0.490166914559577\n","recall score : 0.9737360472751149\n","precision score : 0.32751766784452296\n","thresh : 0.63\n"]}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['y'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        acc_score = get_acc_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'ACC BEST Score: {acc_score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLy2EqucW--T"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBcToO10Ok_c"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNUMGLINFLr8uH1I6r7NIsZ"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}