{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4MzvYz9Q/1j5NOsSWtglZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"dd2fa5de56eb4825bb3eaf4976858520":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3090c59a814f414f91d5cc69a1282542","IPY_MODEL_307ba80786184025828cd70ce04d78e8","IPY_MODEL_9675a8a48918494fbe976e34d495f7dd"],"layout":"IPY_MODEL_e5fd927eb0474e549943e617a4304883"}},"3090c59a814f414f91d5cc69a1282542":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa44173fccf2430391a56a895ee0bdff","placeholder":"​","style":"IPY_MODEL_974cf8f25be54dbb80ecd5c3a27f69f0","value":"Downloading (…)okenizer_config.json: 100%"}},"307ba80786184025828cd70ce04d78e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c0d28ae85364e75818f5d9742e5b9a4","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae873d9e11dd4140807fcef62efb0879","value":52}},"9675a8a48918494fbe976e34d495f7dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7fff671f474e539af074965593402b","placeholder":"​","style":"IPY_MODEL_dee0f91f2dc244af9d8b9652f668e270","value":" 52.0/52.0 [00:00&lt;00:00, 2.57kB/s]"}},"e5fd927eb0474e549943e617a4304883":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa44173fccf2430391a56a895ee0bdff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"974cf8f25be54dbb80ecd5c3a27f69f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c0d28ae85364e75818f5d9742e5b9a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae873d9e11dd4140807fcef62efb0879":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d7fff671f474e539af074965593402b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dee0f91f2dc244af9d8b9652f668e270":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64fa9063fba9409bb017a7cd07afdd9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd2a0919b6e48408159744439a05d45","IPY_MODEL_eb03895b667d438bbed693bb2548d590","IPY_MODEL_e976cd66da7140d1938fbcd626e3300a"],"layout":"IPY_MODEL_5850d1da1bd044e58717db9fd901b2bc"}},"dfd2a0919b6e48408159744439a05d45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc41b2eb41894bcfac43506f91efc7a5","placeholder":"​","style":"IPY_MODEL_bd310d739b9b40d6bb2c9e7753d487f4","value":"Downloading (…)lve/main/config.json: 100%"}},"eb03895b667d438bbed693bb2548d590":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe52fccf4d04a52a6e094b88aeb5cdb","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc9765843ff3496fb49177645f53c33a","value":579}},"e976cd66da7140d1938fbcd626e3300a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ee5bf68c8245898cc86653a9e2ed9b","placeholder":"​","style":"IPY_MODEL_e1f7048d037641758e559df2a3378ec4","value":" 579/579 [00:00&lt;00:00, 27.8kB/s]"}},"5850d1da1bd044e58717db9fd901b2bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc41b2eb41894bcfac43506f91efc7a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd310d739b9b40d6bb2c9e7753d487f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fe52fccf4d04a52a6e094b88aeb5cdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc9765843ff3496fb49177645f53c33a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4ee5bf68c8245898cc86653a9e2ed9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1f7048d037641758e559df2a3378ec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9315075a21c42c6a2201a9be22ccb0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_522537a8aa7c48379c801774175e72dd","IPY_MODEL_d3c1595ae9d94974a0fb2243c041ad97","IPY_MODEL_9aa870957743401f96bd9bd0a6c4986c"],"layout":"IPY_MODEL_357f0f5681274c79b9d8365f63ac4d6b"}},"522537a8aa7c48379c801774175e72dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968a7abd6585449aa3c847af99eea330","placeholder":"​","style":"IPY_MODEL_be3cd2e79db245e6b42bb614f63ecdb1","value":"Downloading (…)&quot;spm.model&quot;;: 100%"}},"d3c1595ae9d94974a0fb2243c041ad97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2dc5f20063543ed83425def44554d58","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_491516b9f23b48659aeb9d47235a5f06","value":2464616}},"9aa870957743401f96bd9bd0a6c4986c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9701cf3e74ef497db4327732a7e9da78","placeholder":"​","style":"IPY_MODEL_9711ea87dd4e46ffa97c4f81e92fb8cb","value":" 2.46M/2.46M [00:00&lt;00:00, 15.9MB/s]"}},"357f0f5681274c79b9d8365f63ac4d6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"968a7abd6585449aa3c847af99eea330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be3cd2e79db245e6b42bb614f63ecdb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2dc5f20063543ed83425def44554d58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"491516b9f23b48659aeb9d47235a5f06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9701cf3e74ef497db4327732a7e9da78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9711ea87dd4e46ffa97c4f81e92fb8cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"813188b33ceb46bea90c91c0a3b42cea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27ba7007d2d14db4b4c6f8a2c81739b1","IPY_MODEL_df062c3c80824ff2aef40bb57548d785","IPY_MODEL_b8623a0a105c4cda93945b4e237c84e4"],"layout":"IPY_MODEL_69c73f68c21d4afd9f0afde9ee0752d6"}},"27ba7007d2d14db4b4c6f8a2c81739b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1da8150bfc74163b6696f249ca25227","placeholder":"​","style":"IPY_MODEL_18986e5f10c344aea5ef7e64b045a56a","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"df062c3c80824ff2aef40bb57548d785":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4857cbe47eb94f05bc1a37577c4d70ae","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6ecdbb5e58847558fc71b4f6ab0635a","value":371146213}},"b8623a0a105c4cda93945b4e237c84e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a0cea73c08b4e7d9f748f1daf7315cf","placeholder":"​","style":"IPY_MODEL_3407b15bb35c4a5b8cd91526b351bb43","value":" 371M/371M [00:02&lt;00:00, 201MB/s]"}},"69c73f68c21d4afd9f0afde9ee0752d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1da8150bfc74163b6696f249ca25227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18986e5f10c344aea5ef7e64b045a56a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4857cbe47eb94f05bc1a37577c4d70ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6ecdbb5e58847558fc71b4f6ab0635a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a0cea73c08b4e7d9f748f1daf7315cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3407b15bb35c4a5b8cd91526b351bb43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMVmfQcW79nK","executionInfo":{"status":"ok","timestamp":1676642210943,"user_tz":-540,"elapsed":21143,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"19af0c0e-9c26-42a8-9709-c1d631a1aa4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMsVsVYs8Jib","executionInfo":{"status":"ok","timestamp":1676642230001,"user_tz":-540,"elapsed":19062,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"66b15d95-3047-4337-a0e7-142f552744e1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.9.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qonwoL_F8Oe_","executionInfo":{"status":"ok","timestamp":1676642231932,"user_tz":-540,"elapsed":1935,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"7dcd1143-cd6c-4c12-ce75-0a49fa15c2a7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Feb 17 13:57:10 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    51W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["\n","import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"y2tBjTH68Qnb","executionInfo":{"status":"ok","timestamp":1676642237399,"user_tz":-540,"elapsed":5470,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=10\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = True\n","    freezing = True\n","    clean_content = True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"],"metadata":{"id":"VCF2-czO8Svr","executionInfo":{"status":"ok","timestamp":1676642237399,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["DIR = \"/content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","OUTPUT_EXP_DIR = DIR + '/output/EXP009/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"],"metadata":{"id":"JyQ97ca88dRA","executionInfo":{"status":"ok","timestamp":1676642238631,"user_tz":-540,"elapsed":1235,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    return recall_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_acc_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.70, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = accuracy_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    return accuracy_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"7QkA50jQ80_3","executionInfo":{"status":"ok","timestamp":1676642238631,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"wRnSUEJR9A9y","executionInfo":{"status":"ok","timestamp":1676642238631,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train_data.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test_data.csv\"))\n","sample_sub = pd.read_csv(os.path.join(INPUT_DIR,\"submission.csv\"))\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(sample_sub.shape)\n","display(sample_sub.head(3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"GUnukiIG9FM5","executionInfo":{"status":"ok","timestamp":1676642239674,"user_tz":-540,"elapsed":1045,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"12f55785-dc72-4298-88d3-8e88abf4e4a6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["(4974, 6)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                             title  year  \\\n","0   1      Hierarchical Adversarially Learned Inference  2018   \n","1   2    Learning to Compute Word Embeddings On the Fly  2018   \n","2   3  Graph2Seq: Scalable Learning Dynamics for Graphs  2018   \n","\n","                                            abstract  \\\n","0  We propose a novel hierarchical generative mod...   \n","1  Words in natural language follow a Zipfian dis...   \n","2  Neural networks are increasingly used as a gen...   \n","\n","                                            keywords  y  \n","0  generative, hierarchical, unsupervised, semisu...  0  \n","1      NLU, word embeddings, representation learning  0  \n","2                                                NaN  0  "],"text/html":["\n","  <div id=\"df-045b6f16-ba52-4d44-951c-2d16b962f108\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Hierarchical Adversarially Learned Inference</td>\n","      <td>2018</td>\n","      <td>We propose a novel hierarchical generative mod...</td>\n","      <td>generative, hierarchical, unsupervised, semisu...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Learning to Compute Word Embeddings On the Fly</td>\n","      <td>2018</td>\n","      <td>Words in natural language follow a Zipfian dis...</td>\n","      <td>NLU, word embeddings, representation learning</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Graph2Seq: Scalable Learning Dynamics for Graphs</td>\n","      <td>2018</td>\n","      <td>Neural networks are increasingly used as a gen...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-045b6f16-ba52-4d44-951c-2d16b962f108')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-045b6f16-ba52-4d44-951c-2d16b962f108 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-045b6f16-ba52-4d44-951c-2d16b962f108');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                              title  year  \\\n","0   1  StyleAlign: Analysis and Applications of Align...  2022   \n","1   2  Embedding a random graph via GNN: mean-field i...  2021   \n","2   3  BBRefinement: an universal scheme to improve p...  2021   \n","\n","                                            abstract  \\\n","0  In this paper, we perform an in-depth study of...   \n","1  We develop a theory for embedding a random gra...   \n","2  We present a conceptually simple yet powerful ...   \n","\n","                                            keywords  \n","0  StyleGAN, transfer learning, fine tuning, mode...  \n","1  Graph neural network, graph embedding, multi-r...  \n","2  object detection, deep neural networks, refine...  "],"text/html":["\n","  <div id=\"df-302131d8-fece-48be-8d2f-655e13b72344\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>StyleAlign: Analysis and Applications of Align...</td>\n","      <td>2022</td>\n","      <td>In this paper, we perform an in-depth study of...</td>\n","      <td>StyleGAN, transfer learning, fine tuning, mode...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Embedding a random graph via GNN: mean-field i...</td>\n","      <td>2021</td>\n","      <td>We develop a theory for embedding a random gra...</td>\n","      <td>Graph neural network, graph embedding, multi-r...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>BBRefinement: an universal scheme to improve p...</td>\n","      <td>2021</td>\n","      <td>We present a conceptually simple yet powerful ...</td>\n","      <td>object detection, deep neural networks, refine...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-302131d8-fece-48be-8d2f-655e13b72344')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-302131d8-fece-48be-8d2f-655e13b72344 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-302131d8-fece-48be-8d2f-655e13b72344');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["   id  y\n","0   1  0\n","1   2  0\n","2   3  0"],"text/html":["\n","  <div id=\"df-b00e94f0-edaf-49fd-89d6-a66faee072a0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b00e94f0-edaf-49fd-89d6-a66faee072a0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b00e94f0-edaf-49fd-89d6-a66faee072a0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b00e94f0-edaf-49fd-89d6-a66faee072a0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["train[\"texts\"] = train[\"abstract\"]  "],"metadata":{"id":"S2LAKUbZ9L92","executionInfo":{"status":"ok","timestamp":1676642239675,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.y)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"9MRHQQ6K9Zot","executionInfo":{"status":"ok","timestamp":1676642239675,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["dd2fa5de56eb4825bb3eaf4976858520","3090c59a814f414f91d5cc69a1282542","307ba80786184025828cd70ce04d78e8","9675a8a48918494fbe976e34d495f7dd","e5fd927eb0474e549943e617a4304883","aa44173fccf2430391a56a895ee0bdff","974cf8f25be54dbb80ecd5c3a27f69f0","7c0d28ae85364e75818f5d9742e5b9a4","ae873d9e11dd4140807fcef62efb0879","7d7fff671f474e539af074965593402b","dee0f91f2dc244af9d8b9652f668e270","64fa9063fba9409bb017a7cd07afdd9b","dfd2a0919b6e48408159744439a05d45","eb03895b667d438bbed693bb2548d590","e976cd66da7140d1938fbcd626e3300a","5850d1da1bd044e58717db9fd901b2bc","cc41b2eb41894bcfac43506f91efc7a5","bd310d739b9b40d6bb2c9e7753d487f4","8fe52fccf4d04a52a6e094b88aeb5cdb","cc9765843ff3496fb49177645f53c33a","d4ee5bf68c8245898cc86653a9e2ed9b","e1f7048d037641758e559df2a3378ec4","c9315075a21c42c6a2201a9be22ccb0d","522537a8aa7c48379c801774175e72dd","d3c1595ae9d94974a0fb2243c041ad97","9aa870957743401f96bd9bd0a6c4986c","357f0f5681274c79b9d8365f63ac4d6b","968a7abd6585449aa3c847af99eea330","be3cd2e79db245e6b42bb614f63ecdb1","a2dc5f20063543ed83425def44554d58","491516b9f23b48659aeb9d47235a5f06","9701cf3e74ef497db4327732a7e9da78","9711ea87dd4e46ffa97c4f81e92fb8cb"]},"id":"kTf6lgW19iep","executionInfo":{"status":"ok","timestamp":1676642243170,"user_tz":-540,"elapsed":3499,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"7cb34373-2804-4d75-90e1-208db61e2c17"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd2fa5de56eb4825bb3eaf4976858520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64fa9063fba9409bb017a7cd07afdd9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"spm.model\";:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9315075a21c42c6a2201a9be22ccb0d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 1 # cls\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wt2P1uC_9oRd","executionInfo":{"status":"ok","timestamp":1676642246023,"user_tz":-540,"elapsed":2865,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c464ff60-0056-42cd-a884-061ba42c29a7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4974/4974 [00:03<00:00, 1381.60it/s]\n","max_len: 510\n","INFO:__main__:max_len: 510\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df['y'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"rmsbpfsc92bq","executionInfo":{"status":"ok","timestamp":1676642246023,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"],"metadata":{"id":"DbE2YLRd9-uk","executionInfo":{"status":"ok","timestamp":1676642246023,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"Evhi1yCQ-Xjb","executionInfo":{"status":"ok","timestamp":1676642246023,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['y'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"],"metadata":{"id":"pR91ZhBL_pW4","executionInfo":{"status":"ok","timestamp":1676642246024,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['y'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        acc_score = get_acc_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'ACC BEST Score: {acc_score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["813188b33ceb46bea90c91c0a3b42cea","27ba7007d2d14db4b4c6f8a2c81739b1","df062c3c80824ff2aef40bb57548d785","b8623a0a105c4cda93945b4e237c84e4","69c73f68c21d4afd9f0afde9ee0752d6","f1da8150bfc74163b6696f249ca25227","18986e5f10c344aea5ef7e64b045a56a","4857cbe47eb94f05bc1a37577c4d70ae","d6ecdbb5e58847558fc71b4f6ab0635a","3a0cea73c08b4e7d9f748f1daf7315cf","3407b15bb35c4a5b8cd91526b351bb43"]},"id":"gZY5kSe1_1Fl","executionInfo":{"status":"ok","timestamp":1676646449567,"user_tz":-540,"elapsed":4203548,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"0573a1c6-7892-42bf-82df-099d8274445d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/371M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"813188b33ceb46bea90c91c0a3b42cea"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 4s (remain 20m 20s) Loss: 0.9441(0.9441) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 17s (remain 0m 31s) Loss: 0.6226(0.6394) Grad: 1.0363  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 31s (remain 0m 12s) Loss: 0.5173(0.6280) Grad: 3.7887  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 41s (remain 0m 0s) Loss: 0.4559(0.6195) Grad: 6.1773  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4111(0.4111) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6195  avg_val_loss: 0.5883  time: 45s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6195  avg_val_loss: 0.5883  time: 45s\n","Epoch 1 - Score: 0.0855\n","INFO:__main__:Epoch 1 - Score: 0.0855\n","Epoch 1 - Save Best Score: 0.0855 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0855 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9451(0.5883) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 24s) Loss: 0.4446(0.4446) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.6124(0.5694) Grad: 3.5148  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.3922(0.5703) Grad: 1.4912  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.6534(0.5699) Grad: 2.3198  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4529(0.4529) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5699  avg_val_loss: 0.6056  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5699  avg_val_loss: 0.6056  time: 41s\n","Epoch 2 - Score: 0.5066\n","INFO:__main__:Epoch 2 - Score: 0.5066\n","Epoch 2 - Save Best Score: 0.5066 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5066 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8596(0.6056) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.4481(0.4481) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 1.0812(0.4449) Grad: 15.9016  LR: 0.00001738  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.2747(0.4322) Grad: 3.3652  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.5016(0.4222) Grad: 5.3500  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.1658(0.1658) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4222  avg_val_loss: 0.7006  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4222  avg_val_loss: 0.7006  time: 41s\n","Epoch 3 - Score: 0.2763\n","INFO:__main__:Epoch 3 - Score: 0.2763\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.9082(0.7006) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 26s) Loss: 0.1654(0.1654) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.1069(0.1550) Grad: 7.8932  LR: 0.00001494  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.2883(0.1413) Grad: 11.9086  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0775(0.1349) Grad: 9.7213  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.0593(0.0593) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1349  avg_val_loss: 1.1343  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1349  avg_val_loss: 1.1343  time: 41s\n","Epoch 4 - Score: 0.2895\n","INFO:__main__:Epoch 4 - Score: 0.2895\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.1517(1.1343) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 24s) Loss: 0.0152(0.0152) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0814(0.0411) Grad: 8.8571  LR: 0.00001202  \n","Epoch: [5][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0222(0.0312) Grad: 4.0073  LR: 0.00001091  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0107(0.0282) Grad: 2.2989  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.1485(0.1485) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0282  avg_val_loss: 1.3848  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0282  avg_val_loss: 1.3848  time: 41s\n","Epoch 5 - Score: 0.2105\n","INFO:__main__:Epoch 5 - Score: 0.2105\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 4.1589(1.3848) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0029(0.0029) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0046(0.0105) Grad: 0.4610  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.1111(0.0076) Grad: 20.4136  LR: 0.00000780  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0016(0.0066) Grad: 0.0542  LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3472(0.3472) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0066  avg_val_loss: 1.4982  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0066  avg_val_loss: 1.4982  time: 41s\n","Epoch 6 - Score: 0.3553\n","INFO:__main__:Epoch 6 - Score: 0.3553\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.2575(1.4982) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 29s) Loss: 0.0032(0.0032) Grad: nan  LR: 0.00000694  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0017(0.0019) Grad: 0.0982  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0019(0.0032) Grad: 0.2290  LR: 0.00000490  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0009(0.0027) Grad: 0.0303  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2818(0.2818) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0027  avg_val_loss: 1.5867  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0027  avg_val_loss: 1.5867  time: 41s\n","Epoch 7 - Score: 0.3158\n","INFO:__main__:Epoch 7 - Score: 0.3158\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.8780(1.5867) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 23s) Loss: 0.0008(0.0008) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0011(0.0013) Grad: 0.0439  LR: 0.00000328  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0012(0.0013) Grad: 0.0668  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0014(0.0012) Grad: 0.0941  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3071(0.3071) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0012  avg_val_loss: 1.6227  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0012  avg_val_loss: 1.6227  time: 41s\n","Epoch 8 - Score: 0.3158\n","INFO:__main__:Epoch 8 - Score: 0.3158\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.9190(1.6227) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 23s) Loss: 0.0009(0.0009) Grad: nan  LR: 0.00000194  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0007(0.0010) Grad: 0.0410  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0015(0.0011) Grad: 0.1499  LR: 0.00000082  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0008(0.0011) Grad: 0.0370  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3071(0.3071) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0011  avg_val_loss: 1.6381  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0011  avg_val_loss: 1.6381  time: 41s\n","Epoch 9 - Score: 0.3158\n","INFO:__main__:Epoch 9 - Score: 0.3158\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.9756(1.6381) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0012(0.0012) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0011(0.0011) Grad: 0.0608  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0022(0.0011) Grad: 0.1573  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0014(0.0010) Grad: 0.0588  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3104(0.3104) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0010  avg_val_loss: 1.6399  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0010  avg_val_loss: 1.6399  time: 41s\n","Epoch 10 - Score: 0.3158\n","INFO:__main__:Epoch 10 - Score: 0.3158\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.9697(1.6399) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.5066\n","INFO:__main__:Score: 0.5066\n","ACC BEST Score: 0.7149\n","INFO:__main__:ACC BEST Score: 0.7149\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 0.5901(0.5901) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.6114(0.6055) Grad: 1.9105  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.7350(0.5995) Grad: 5.0241  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.5725(0.5990) Grad: 1.8346  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2206(0.2206) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5990  avg_val_loss: 0.5897  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5990  avg_val_loss: 0.5897  time: 41s\n","Epoch 1 - Score: 0.0065\n","INFO:__main__:Epoch 1 - Score: 0.0065\n","Epoch 1 - Save Best Score: 0.0065 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0065 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.3888(0.5897) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.3924(0.3924) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.7110(0.5272) Grad: 7.6147  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.4740(0.5034) Grad: 5.2017  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.7112(0.5042) Grad: 9.4747  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2854(0.2854) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5042  avg_val_loss: 0.5804  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5042  avg_val_loss: 0.5804  time: 41s\n","Epoch 2 - Score: 0.2549\n","INFO:__main__:Epoch 2 - Score: 0.2549\n","Epoch 2 - Save Best Score: 0.2549 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.2549 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.2151(0.5804) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 31s) Loss: 0.3329(0.3329) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0902(0.2201) Grad: 3.6986  LR: 0.00001738  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.2544(0.2403) Grad: 9.5521  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.0850(0.2294) Grad: 6.6846  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.0678(0.0678) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2294  avg_val_loss: 1.0566  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2294  avg_val_loss: 1.0566  time: 41s\n","Epoch 3 - Score: 0.1569\n","INFO:__main__:Epoch 3 - Score: 0.1569\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.2085(1.0566) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0819(0.0819) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0802(0.0548) Grad: 10.0032  LR: 0.00001494  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0056(0.0458) Grad: 0.2951  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0376(0.0403) Grad: 6.9007  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6505(0.6505) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0403  avg_val_loss: 1.1453  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0403  avg_val_loss: 1.1453  time: 41s\n","Epoch 4 - Score: 0.4314\n","INFO:__main__:Epoch 4 - Score: 0.4314\n","Epoch 4 - Save Best Score: 0.4314 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4314 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.9990(1.1453) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0048(0.0048) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.0024(0.0047) Grad: 0.1829  LR: 0.00001202  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0015(0.0047) Grad: 0.1095  LR: 0.00001091  \n","Epoch: [5][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.0028(0.0043) Grad: 0.2448  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5199(0.5199) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0043  avg_val_loss: 1.3432  time: 42s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0043  avg_val_loss: 1.3432  time: 42s\n","Epoch 5 - Score: 0.3791\n","INFO:__main__:Epoch 5 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.8562(1.3432) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 35s) Loss: 0.0013(0.0013) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0015(0.0013) Grad: 0.1402  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0009(0.0011) Grad: 0.0464  LR: 0.00000780  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0012(0.0011) Grad: 0.0612  LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5965(0.5965) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0011  avg_val_loss: 1.4263  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0011  avg_val_loss: 1.4263  time: 41s\n","Epoch 6 - Score: 0.3922\n","INFO:__main__:Epoch 6 - Score: 0.3922\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.9329(1.4263) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0009(0.0009) Grad: nan  LR: 0.00000694  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0006(0.0008) Grad: 0.0377  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0009(0.0007) Grad: 0.0761  LR: 0.00000490  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0004(0.0007) Grad: 0.0270  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5770(0.5770) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0007  avg_val_loss: 1.4766  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0007  avg_val_loss: 1.4766  time: 41s\n","Epoch 7 - Score: 0.3791\n","INFO:__main__:Epoch 7 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.1160(1.4766) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.0003(0.0003) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0005(0.0006) Grad: 0.0358  LR: 0.00000328  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0002(0.0006) Grad: 0.0172  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0005(0.0006) Grad: 0.0303  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5821(0.5821) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0006  avg_val_loss: 1.5022  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0006  avg_val_loss: 1.5022  time: 41s\n","Epoch 8 - Score: 0.3791\n","INFO:__main__:Epoch 8 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.1796(1.5022) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0007(0.0007) Grad: nan  LR: 0.00000194  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0002(0.0005) Grad: 0.0219  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0006(0.0005) Grad: 0.0551  LR: 0.00000082  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0006(0.0005) Grad: 0.0569  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5809(0.5809) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0005  avg_val_loss: 1.5132  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0005  avg_val_loss: 1.5132  time: 41s\n","Epoch 9 - Score: 0.3791\n","INFO:__main__:Epoch 9 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.2147(1.5132) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0005(0.0005) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0002(0.0005) Grad: 0.0164  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0002(0.0005) Grad: 0.0329  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0004(0.0005) Grad: 0.0257  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5818(0.5818) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0005  avg_val_loss: 1.5146  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0005  avg_val_loss: 1.5146  time: 41s\n","Epoch 10 - Score: 0.3791\n","INFO:__main__:Epoch 10 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.2172(1.5146) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.4314\n","INFO:__main__:Score: 0.4314\n","ACC BEST Score: 0.6928\n","INFO:__main__:ACC BEST Score: 0.6928\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.8085(0.8085) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.6897(0.6314) Grad: 2.3622  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5108(0.6258) Grad: 4.2958  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.6219(0.6189) Grad: 0.9405  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4241(0.4241) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6189  avg_val_loss: 0.5914  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6189  avg_val_loss: 0.5914  time: 41s\n","Epoch 1 - Score: 0.0000\n","INFO:__main__:Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0000 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9949(0.5914) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.4896(0.4896) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.4980(0.5707) Grad: 1.5132  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.3711(0.5699) Grad: 1.5114  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4811(0.5684) Grad: 5.8560  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4540(0.4540) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5684  avg_val_loss: 0.5670  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5684  avg_val_loss: 0.5670  time: 41s\n","Epoch 2 - Score: 0.4118\n","INFO:__main__:Epoch 2 - Score: 0.4118\n","Epoch 2 - Save Best Score: 0.4118 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4118 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8554(0.5670) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.4489(0.4489) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.4729(0.4467) Grad: 3.5947  LR: 0.00001738  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.1783(0.4322) Grad: 3.0901  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.3750(0.4288) Grad: 5.8486  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2527(0.2527) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4288  avg_val_loss: 0.6409  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4288  avg_val_loss: 0.6409  time: 41s\n","Epoch 3 - Score: 0.2222\n","INFO:__main__:Epoch 3 - Score: 0.2222\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.8588(0.6409) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.1245(0.1245) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0811(0.1366) Grad: 7.4815  LR: 0.00001494  \n","Epoch: [4][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0474(0.1278) Grad: 4.5302  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4438(0.1233) Grad: 29.5140  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.9055(0.9055) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1233  avg_val_loss: 0.9412  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1233  avg_val_loss: 0.9412  time: 41s\n","Epoch 4 - Score: 0.6144\n","INFO:__main__:Epoch 4 - Score: 0.6144\n","Epoch 4 - Save Best Score: 0.6144 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.6144 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.5424(0.9412) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 49s) Loss: 0.0112(0.0112) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0113(0.0313) Grad: 2.0209  LR: 0.00001202  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0071(0.0246) Grad: 0.6149  LR: 0.00001091  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0010(0.0212) Grad: 0.0936  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.3498(0.3498) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0212  avg_val_loss: 1.2312  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0212  avg_val_loss: 1.2312  time: 41s\n","Epoch 5 - Score: 0.2876\n","INFO:__main__:Epoch 5 - Score: 0.2876\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.6340(1.2312) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 2m 0s) Loss: 0.0010(0.0010) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0019(0.0026) Grad: 0.1307  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0013(0.0021) Grad: 0.0771  LR: 0.00000780  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0021(0.0021) Grad: 0.1604  LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5538(0.5538) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0021  avg_val_loss: 1.2938  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0021  avg_val_loss: 1.2938  time: 41s\n","Epoch 6 - Score: 0.3660\n","INFO:__main__:Epoch 6 - Score: 0.3660\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.4959(1.2938) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0010(0.0010) Grad: nan  LR: 0.00000694  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0015(0.0012) Grad: 0.0772  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0009(0.0010) Grad: 0.0698  LR: 0.00000490  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0007(0.0010) Grad: 0.0386  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6302(0.6302) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0010  avg_val_loss: 1.3456  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0010  avg_val_loss: 1.3456  time: 41s\n","Epoch 7 - Score: 0.3791\n","INFO:__main__:Epoch 7 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.5437(1.3456) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0008(0.0008) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0012(0.0007) Grad: 0.0802  LR: 0.00000328  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0005(0.0008) Grad: 0.0335  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0005(0.0007) Grad: 0.0291  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6460(0.6460) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0007  avg_val_loss: 1.3757  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0007  avg_val_loss: 1.3757  time: 41s\n","Epoch 8 - Score: 0.3791\n","INFO:__main__:Epoch 8 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.6102(1.3757) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 28s) Loss: 0.0012(0.0012) Grad: nan  LR: 0.00000194  \n","Epoch: [9][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0005(0.0008) Grad: 0.0487  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0007(0.0007) Grad: 0.0416  LR: 0.00000082  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0003(0.0006) Grad: 0.0216  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6469(0.6469) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0006  avg_val_loss: 1.3880  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0006  avg_val_loss: 1.3880  time: 41s\n","Epoch 9 - Score: 0.3791\n","INFO:__main__:Epoch 9 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.6463(1.3880) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 31s) Loss: 0.0004(0.0004) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0008(0.0006) Grad: 0.0634  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0007(0.0006) Grad: 0.0329  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0003(0.0006) Grad: 0.0138  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6480(0.6480) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0006  avg_val_loss: 1.3896  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0006  avg_val_loss: 1.3896  time: 41s\n","Epoch 10 - Score: 0.3791\n","INFO:__main__:Epoch 10 - Score: 0.3791\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.6496(1.3896) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.6144\n","INFO:__main__:Score: 0.6144\n","ACC BEST Score: 0.6888\n","INFO:__main__:ACC BEST Score: 0.6888\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.8458(0.8458) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.4634(0.6571) Grad: 5.0727  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5098(0.6370) Grad: 6.3033  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.6291(0.6286) Grad: 1.9398  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4494(0.4494) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6286  avg_val_loss: 0.6139  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6286  avg_val_loss: 0.6139  time: 41s\n","Epoch 1 - Score: 0.0000\n","INFO:__main__:Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0000 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9919(0.6139) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 49s) Loss: 0.5907(0.5907) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.5936(0.5931) Grad: 0.6107  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5517(0.5892) Grad: 2.8547  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.6157(0.5954) Grad: 7.9228  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5521(0.5521) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5954  avg_val_loss: 0.6309  time: 42s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5954  avg_val_loss: 0.6309  time: 42s\n","Epoch 2 - Score: 0.3725\n","INFO:__main__:Epoch 2 - Score: 0.3725\n","Epoch 2 - Save Best Score: 0.3725 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.3725 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7610(0.6309) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.6583(0.6583) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.3317(0.5483) Grad: 3.2685  LR: 0.00001738  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5585(0.5456) Grad: 3.0125  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4044(0.5339) Grad: 1.7682  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2149(0.2149) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5339  avg_val_loss: 0.6044  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.5339  avg_val_loss: 0.6044  time: 41s\n","Epoch 3 - Score: 0.0523\n","INFO:__main__:Epoch 3 - Score: 0.0523\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.3911(0.6044) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 26s) Loss: 0.4595(0.4595) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.1921(0.3606) Grad: 3.3636  LR: 0.00001494  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.3251(0.3330) Grad: 11.7310  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4327(0.3257) Grad: 10.1146  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2738(0.2738) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3257  avg_val_loss: 0.7019  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3257  avg_val_loss: 0.7019  time: 41s\n","Epoch 4 - Score: 0.2680\n","INFO:__main__:Epoch 4 - Score: 0.2680\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.4791(0.7019) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.0540(0.0540) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0519(0.0545) Grad: 6.3684  LR: 0.00001202  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0633(0.0650) Grad: 5.8982  LR: 0.00001091  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0191(0.0597) Grad: 3.6595  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.2988(0.2988) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0597  avg_val_loss: 1.1385  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0597  avg_val_loss: 1.1385  time: 41s\n","Epoch 5 - Score: 0.3072\n","INFO:__main__:Epoch 5 - Score: 0.3072\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.5203(1.1385) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 31s) Loss: 0.0175(0.0175) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0035(0.0059) Grad: 0.2625  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0013(0.0053) Grad: 0.0535  LR: 0.00000780  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0018(0.0051) Grad: 0.1824  LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5005(0.5005) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0051  avg_val_loss: 1.3753  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0051  avg_val_loss: 1.3753  time: 41s\n","Epoch 6 - Score: 0.3399\n","INFO:__main__:Epoch 6 - Score: 0.3399\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.3650(1.3753) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.0028(0.0028) Grad: nan  LR: 0.00000694  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0014(0.0020) Grad: 0.1008  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0010(0.0016) Grad: 0.0832  LR: 0.00000490  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0007(0.0015) Grad: 0.0457  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3896(0.3896) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0015  avg_val_loss: 1.5050  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0015  avg_val_loss: 1.5050  time: 41s\n","Epoch 7 - Score: 0.3007\n","INFO:__main__:Epoch 7 - Score: 0.3007\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0384(1.5050) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 26s) Loss: 0.0013(0.0013) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0005(0.0012) Grad: 0.0337  LR: 0.00000328  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0004(0.0011) Grad: 0.0248  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0014(0.0010) Grad: 0.0846  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4053(0.4053) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0010  avg_val_loss: 1.5489  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0010  avg_val_loss: 1.5489  time: 41s\n","Epoch 8 - Score: 0.3007\n","INFO:__main__:Epoch 8 - Score: 0.3007\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.1309(1.5489) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0007(0.0007) Grad: nan  LR: 0.00000194  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0010(0.0009) Grad: 0.0471  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0007(0.0009) Grad: 0.0352  LR: 0.00000082  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0005(0.0009) Grad: 0.0323  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4160(0.4160) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0009  avg_val_loss: 1.5649  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0009  avg_val_loss: 1.5649  time: 41s\n","Epoch 9 - Score: 0.3007\n","INFO:__main__:Epoch 9 - Score: 0.3007\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.1527(1.5649) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.0005(0.0005) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0009(0.0008) Grad: 0.1033  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0006(0.0008) Grad: 0.0266  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0002(0.0008) Grad: 0.0249  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4204(0.4204) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0008  avg_val_loss: 1.5663  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0008  avg_val_loss: 1.5663  time: 41s\n","Epoch 10 - Score: 0.3007\n","INFO:__main__:Epoch 10 - Score: 0.3007\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.1446(1.5663) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.3725\n","INFO:__main__:Score: 0.3725\n","ACC BEST Score: 0.7048\n","INFO:__main__:ACC BEST Score: 0.7048\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.6623(0.6623) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.5144(0.6198) Grad: 4.9023  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5240(0.6172) Grad: 9.4712  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.6373(0.6106) Grad: 1.1889  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5191(0.5191) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6106  avg_val_loss: 0.6087  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6106  avg_val_loss: 0.6087  time: 41s\n","Epoch 1 - Score: 0.2829\n","INFO:__main__:Epoch 1 - Score: 0.2829\n","Epoch 1 - Save Best Score: 0.2829 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.2829 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7525(0.6087) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.6279(0.6279) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.6139(0.5382) Grad: 3.4415  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.3408(0.5363) Grad: 4.1973  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.3721(0.5321) Grad: 4.4738  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2981(0.2981) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5321  avg_val_loss: 0.5819  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5321  avg_val_loss: 0.5819  time: 41s\n","Epoch 2 - Score: 0.1645\n","INFO:__main__:Epoch 2 - Score: 0.1645\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.1747(0.5819) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 29s) Loss: 0.5098(0.5098) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.3512(0.3325) Grad: 7.2442  LR: 0.00001739  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.2565(0.3319) Grad: 6.3050  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1238(0.3157) Grad: 5.8186  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6004(0.6004) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3157  avg_val_loss: 0.7448  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3157  avg_val_loss: 0.7448  time: 41s\n","Epoch 3 - Score: 0.4211\n","INFO:__main__:Epoch 3 - Score: 0.4211\n","Epoch 3 - Save Best Score: 0.4211 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4211 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9156(0.7448) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.0483(0.0483) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0279(0.0523) Grad: 2.8438  LR: 0.00001495  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0309(0.0562) Grad: 3.8549  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.3842(0.0550) Grad: 6.2685  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6418(0.6418) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0550  avg_val_loss: 1.1332  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0550  avg_val_loss: 1.1332  time: 41s\n","Epoch 4 - Score: 0.3092\n","INFO:__main__:Epoch 4 - Score: 0.3092\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.0113(1.1332) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0088(0.0088) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0202(0.0079) Grad: 4.2258  LR: 0.00001203  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0025(0.0067) Grad: 0.2006  LR: 0.00001092  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0025(0.0058) Grad: 0.3907  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.8633(0.8633) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0058  avg_val_loss: 1.3597  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0058  avg_val_loss: 1.3597  time: 41s\n","Epoch 5 - Score: 0.3684\n","INFO:__main__:Epoch 5 - Score: 0.3684\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.4556(1.3597) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.0018(0.0018) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0010(0.0020) Grad: 0.0637  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0013(0.0016) Grad: 0.0810  LR: 0.00000781  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0010(0.0015) Grad: 0.1032  LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.8532(0.8532) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0015  avg_val_loss: 1.4433  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0015  avg_val_loss: 1.4433  time: 41s\n","Epoch 6 - Score: 0.3618\n","INFO:__main__:Epoch 6 - Score: 0.3618\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.7354(1.4433) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.0014(0.0014) Grad: nan  LR: 0.00000695  \n","Epoch: [7][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0004(0.0008) Grad: 0.0355  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0004(0.0008) Grad: 0.0314  LR: 0.00000491  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0009(0.0008) Grad: 0.0906  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.8310(0.8310) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0008  avg_val_loss: 1.4979  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0008  avg_val_loss: 1.4979  time: 41s\n","Epoch 7 - Score: 0.3553\n","INFO:__main__:Epoch 7 - Score: 0.3553\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.9258(1.4979) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.0012(0.0012) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0005(0.0007) Grad: 0.0361  LR: 0.00000329  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0007(0.0006) Grad: 0.0790  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0004(0.0006) Grad: 0.0296  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.8222(0.8222) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0006  avg_val_loss: 1.5269  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0006  avg_val_loss: 1.5269  time: 41s\n","Epoch 8 - Score: 0.3553\n","INFO:__main__:Epoch 8 - Score: 0.3553\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0228(1.5269) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.0002(0.0002) Grad: nan  LR: 0.00000195  \n","Epoch: [9][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0004(0.0005) Grad: 0.0402  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0005(0.0005) Grad: 0.0319  LR: 0.00000083  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0005(0.0005) Grad: 0.0407  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.8311(0.8311) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0005  avg_val_loss: 1.5374  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0005  avg_val_loss: 1.5374  time: 41s\n","Epoch 9 - Score: 0.3553\n","INFO:__main__:Epoch 9 - Score: 0.3553\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0329(1.5374) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.0004(0.0004) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0002(0.0005) Grad: 0.0157  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0007(0.0005) Grad: 0.0375  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0001(0.0005) Grad: 0.0161  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.8302(0.8302) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0005  avg_val_loss: 1.5392  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0005  avg_val_loss: 1.5392  time: 41s\n","Epoch 10 - Score: 0.3553\n","INFO:__main__:Epoch 10 - Score: 0.3553\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0400(1.5392) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n","Score: 0.4211\n","INFO:__main__:Score: 0.4211\n","ACC BEST Score: 0.6901\n","INFO:__main__:ACC BEST Score: 0.6901\n","========== fold: 5 training ==========\n","INFO:__main__:========== fold: 5 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.6257(0.6257) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.6679(0.6135) Grad: 5.4943  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5924(0.6035) Grad: 1.0335  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4453(0.6014) Grad: 2.8897  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3763(0.3763) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6014  avg_val_loss: 0.6017  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6014  avg_val_loss: 0.6017  time: 41s\n","Epoch 1 - Score: 0.0592\n","INFO:__main__:Epoch 1 - Score: 0.0592\n","Epoch 1 - Save Best Score: 0.0592 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0592 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.0526(0.6017) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 49s) Loss: 0.5062(0.5062) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.6628(0.5345) Grad: 3.3481  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.9752(0.5294) Grad: 9.8305  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4942(0.5249) Grad: 3.1766  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.2489(0.2489) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5249  avg_val_loss: 0.6262  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5249  avg_val_loss: 0.6262  time: 41s\n","Epoch 2 - Score: 0.0789\n","INFO:__main__:Epoch 2 - Score: 0.0789\n","Epoch 2 - Save Best Score: 0.0789 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.0789 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.4267(0.6262) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.3220(0.3220) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.2712(0.3098) Grad: 11.5610  LR: 0.00001739  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.3651(0.3003) Grad: 16.3451  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1926(0.3008) Grad: 5.4255  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5940(0.5940) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3008  avg_val_loss: 0.7239  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3008  avg_val_loss: 0.7239  time: 41s\n","Epoch 3 - Score: 0.4342\n","INFO:__main__:Epoch 3 - Score: 0.4342\n","Epoch 3 - Save Best Score: 0.4342 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4342 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9103(0.7239) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 0.0777(0.0777) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0842(0.0555) Grad: 7.4505  LR: 0.00001495  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0120(0.0609) Grad: 0.8143  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0075(0.0543) Grad: 0.6247  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 1.1531(1.1531) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0543  avg_val_loss: 1.1684  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0543  avg_val_loss: 1.1684  time: 41s\n","Epoch 4 - Score: 0.4342\n","INFO:__main__:Epoch 4 - Score: 0.4342\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.5475(1.1684) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0075(0.0075) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0030(0.0109) Grad: 0.2309  LR: 0.00001203  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0027(0.0084) Grad: 0.1765  LR: 0.00001092  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.1365(0.0100) Grad: 17.2464  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.3760(0.3760) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0100  avg_val_loss: 1.3623  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0100  avg_val_loss: 1.3623  time: 41s\n","Epoch 5 - Score: 0.1908\n","INFO:__main__:Epoch 5 - Score: 0.1908\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.9222(1.3623) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0039(0.0039) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0010(0.0027) Grad: 0.0526  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0013(0.0027) Grad: 0.0814  LR: 0.00000781  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0008(0.0023) Grad: 0.0297  LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6465(0.6465) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0023  avg_val_loss: 1.4591  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0023  avg_val_loss: 1.4591  time: 41s\n","Epoch 6 - Score: 0.2566\n","INFO:__main__:Epoch 6 - Score: 0.2566\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.6722(1.4591) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 28s) Loss: 0.0007(0.0007) Grad: nan  LR: 0.00000695  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0005(0.0010) Grad: 0.0242  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0011(0.0010) Grad: 0.0492  LR: 0.00000491  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0006(0.0010) Grad: 0.0369  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.7932(0.7932) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0010  avg_val_loss: 1.5154  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0010  avg_val_loss: 1.5154  time: 41s\n","Epoch 7 - Score: 0.2829\n","INFO:__main__:Epoch 7 - Score: 0.2829\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.6053(1.5154) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 29s) Loss: 0.0007(0.0007) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0005(0.0008) Grad: 0.0299  LR: 0.00000329  \n","Epoch: [8][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0009(0.0008) Grad: 0.0520  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0004(0.0008) Grad: 0.0373  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.7958(0.7958) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0008  avg_val_loss: 1.5514  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0008  avg_val_loss: 1.5514  time: 41s\n","Epoch 8 - Score: 0.2763\n","INFO:__main__:Epoch 8 - Score: 0.2763\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.7056(1.5514) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 29s) Loss: 0.0002(0.0002) Grad: nan  LR: 0.00000195  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0006(0.0007) Grad: 0.0337  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0009(0.0007) Grad: 0.0534  LR: 0.00000083  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0015(0.0007) Grad: 0.2387  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7946(0.7946) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0007  avg_val_loss: 1.5663  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0007  avg_val_loss: 1.5663  time: 41s\n","Epoch 9 - Score: 0.2763\n","INFO:__main__:Epoch 9 - Score: 0.2763\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.7514(1.5663) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 29s) Loss: 0.0009(0.0009) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0010(0.0007) Grad: 0.0716  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0004(0.0006) Grad: 0.0209  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0010(0.0007) Grad: 0.0726  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.8005(0.8005) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0007  avg_val_loss: 1.5678  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0007  avg_val_loss: 1.5678  time: 41s\n","Epoch 10 - Score: 0.2763\n","INFO:__main__:Epoch 10 - Score: 0.2763\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.7457(1.5678) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 5 result ==========\n","INFO:__main__:========== fold: 5 result ==========\n","Score: 0.4342\n","INFO:__main__:Score: 0.4342\n","ACC BEST Score: 0.6640\n","INFO:__main__:ACC BEST Score: 0.6640\n","========== fold: 6 training ==========\n","INFO:__main__:========== fold: 6 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.8643(0.8643) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.5742(0.6481) Grad: 2.9423  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.7707(0.6251) Grad: 4.8847  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.5540(0.6228) Grad: 6.7533  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.4778(0.4778) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6228  avg_val_loss: 0.6050  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6228  avg_val_loss: 0.6050  time: 41s\n","Epoch 1 - Score: 0.0000\n","INFO:__main__:Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0000 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8973(0.6050) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 47s) Loss: 0.5965(0.5965) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.6590(0.5819) Grad: 4.5439  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.6967(0.5883) Grad: 1.4676  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.5758(0.5910) Grad: 3.6243  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.4737(0.4737) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5910  avg_val_loss: 0.5938  time: 42s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5910  avg_val_loss: 0.5938  time: 42s\n","Epoch 2 - Score: 0.0461\n","INFO:__main__:Epoch 2 - Score: 0.0461\n","Epoch 2 - Save Best Score: 0.0461 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.0461 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9034(0.5938) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.5662(0.5662) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.4155(0.5393) Grad: 2.8896  LR: 0.00001739  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.6478(0.5306) Grad: 4.7710  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.6236(0.5224) Grad: 5.1784  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.3716(0.3716) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5224  avg_val_loss: 0.5653  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.5224  avg_val_loss: 0.5653  time: 41s\n","Epoch 3 - Score: 0.2829\n","INFO:__main__:Epoch 3 - Score: 0.2829\n","Epoch 3 - Save Best Score: 0.2829 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.2829 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.1090(0.5653) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.3076(0.3076) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.1548(0.3696) Grad: 4.9580  LR: 0.00001495  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.4666(0.3448) Grad: 9.2167  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.4874(0.3459) Grad: 14.5198  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.1993(0.1993) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3459  avg_val_loss: 0.6493  time: 42s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3459  avg_val_loss: 0.6493  time: 42s\n","Epoch 4 - Score: 0.2368\n","INFO:__main__:Epoch 4 - Score: 0.2368\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.6715(0.6493) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.2195(0.2195) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0509(0.0965) Grad: 5.4632  LR: 0.00001203  \n","Epoch: [5][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0330(0.0986) Grad: 3.3203  LR: 0.00001092  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0966(0.0936) Grad: 9.2521  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 1.0634(1.0634) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0936  avg_val_loss: 0.8980  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0936  avg_val_loss: 0.8980  time: 41s\n","Epoch 5 - Score: 0.5855\n","INFO:__main__:Epoch 5 - Score: 0.5855\n","Epoch 5 - Save Best Score: 0.5855 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.5855 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.6154(0.8980) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.0206(0.0206) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0240(0.0237) Grad: 2.4421  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0160(0.0193) Grad: 1.8684  LR: 0.00000781  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0040(0.0191) Grad: 0.1864  LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6352(0.6352) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0191  avg_val_loss: 1.0573  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0191  avg_val_loss: 1.0573  time: 41s\n","Epoch 6 - Score: 0.3618\n","INFO:__main__:Epoch 6 - Score: 0.3618\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.5664(1.0573) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.0032(0.0032) Grad: nan  LR: 0.00000695  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0035(0.0069) Grad: 0.1933  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0020(0.0051) Grad: 0.0735  LR: 0.00000491  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0015(0.0048) Grad: 0.0620  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.8483(0.8483) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0048  avg_val_loss: 1.1574  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0048  avg_val_loss: 1.1574  time: 41s\n","Epoch 7 - Score: 0.3947\n","INFO:__main__:Epoch 7 - Score: 0.3947\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.6076(1.1574) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0036(0.0036) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0025(0.0023) Grad: 0.1546  LR: 0.00000329  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0015(0.0026) Grad: 0.1199  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0018(0.0032) Grad: 0.0736  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.8807(0.8807) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0032  avg_val_loss: 1.2012  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0032  avg_val_loss: 1.2012  time: 41s\n","Epoch 8 - Score: 0.3947\n","INFO:__main__:Epoch 8 - Score: 0.3947\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.7086(1.2012) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0019(0.0019) Grad: nan  LR: 0.00000195  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0015(0.0028) Grad: 0.0840  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0018(0.0030) Grad: 0.0732  LR: 0.00000083  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0012(0.0026) Grad: 0.0790  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.8544(0.8544) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0026  avg_val_loss: 1.2159  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0026  avg_val_loss: 1.2159  time: 41s\n","Epoch 9 - Score: 0.3816\n","INFO:__main__:Epoch 9 - Score: 0.3816\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.7757(1.2159) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0011(0.0011) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0012(0.0018) Grad: 0.0516  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0021(0.0023) Grad: 0.0834  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0021(0.0025) Grad: 0.1474  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.8532(0.8532) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0025  avg_val_loss: 1.2185  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0025  avg_val_loss: 1.2185  time: 41s\n","Epoch 10 - Score: 0.3816\n","INFO:__main__:Epoch 10 - Score: 0.3816\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.7850(1.2185) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 6 result ==========\n","INFO:__main__:========== fold: 6 result ==========\n","Score: 0.5855\n","INFO:__main__:Score: 0.5855\n","ACC BEST Score: 0.6881\n","INFO:__main__:ACC BEST Score: 0.6881\n","========== fold: 7 training ==========\n","INFO:__main__:========== fold: 7 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.9076(0.9076) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.4770(0.6337) Grad: 1.0541  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.6065(0.6131) Grad: 1.7285  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.8436(0.6101) Grad: 7.4279  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3022(0.3022) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6101  avg_val_loss: 0.5888  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6101  avg_val_loss: 0.5888  time: 41s\n","Epoch 1 - Score: 0.0000\n","INFO:__main__:Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0000 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.1865(0.5888) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.5918(0.5918) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.4386(0.5332) Grad: 4.7818  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5129(0.5402) Grad: 2.5437  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.5607(0.5384) Grad: 4.9772  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3112(0.3112) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5384  avg_val_loss: 0.5855  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5384  avg_val_loss: 0.5855  time: 41s\n","Epoch 2 - Score: 0.2566\n","INFO:__main__:Epoch 2 - Score: 0.2566\n","Epoch 2 - Save Best Score: 0.2566 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.2566 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.1095(0.5855) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 52s) Loss: 0.2758(0.2758) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.2072(0.3213) Grad: 3.9870  LR: 0.00001739  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.1839(0.3178) Grad: 7.9369  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3992(0.3162) Grad: 11.7917  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5940(0.5940) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3162  avg_val_loss: 0.8024  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3162  avg_val_loss: 0.8024  time: 41s\n","Epoch 3 - Score: 0.5592\n","INFO:__main__:Epoch 3 - Score: 0.5592\n","Epoch 3 - Save Best Score: 0.5592 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5592 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8154(0.8024) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.0927(0.0927) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.0171(0.0663) Grad: 1.2450  LR: 0.00001495  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0671(0.0598) Grad: 8.1861  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.0604(0.0682) Grad: 7.8026  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.9916(0.9916) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0682  avg_val_loss: 1.1865  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0682  avg_val_loss: 1.1865  time: 41s\n","Epoch 4 - Score: 0.5197\n","INFO:__main__:Epoch 4 - Score: 0.5197\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.3205(1.1865) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.0145(0.0145) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.0030(0.0136) Grad: 0.1811  LR: 0.00001203  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0160(0.0125) Grad: 2.8428  LR: 0.00001092  \n","Epoch: [5][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.0020(0.0106) Grad: 0.1931  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.7384(0.7384) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0106  avg_val_loss: 1.3595  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0106  avg_val_loss: 1.3595  time: 41s\n","Epoch 5 - Score: 0.3882\n","INFO:__main__:Epoch 5 - Score: 0.3882\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.8483(1.3595) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 35s) Loss: 0.0021(0.0021) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0033(0.0025) Grad: 0.3162  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0011(0.0023) Grad: 0.0352  LR: 0.00000781  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0012(0.0021) Grad: 0.0625  LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.9201(0.9201) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0021  avg_val_loss: 1.4708  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0021  avg_val_loss: 1.4708  time: 41s\n","Epoch 6 - Score: 0.4079\n","INFO:__main__:Epoch 6 - Score: 0.4079\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.8352(1.4708) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0010(0.0010) Grad: nan  LR: 0.00000695  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0009(0.0014) Grad: 0.0397  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0008(0.0012) Grad: 0.0526  LR: 0.00000491  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0008(0.0012) Grad: 0.0466  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.9452(0.9452) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0012  avg_val_loss: 1.5263  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0012  avg_val_loss: 1.5263  time: 41s\n","Epoch 7 - Score: 0.3947\n","INFO:__main__:Epoch 7 - Score: 0.3947\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0087(1.5263) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0011(0.0011) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0005(0.0009) Grad: 0.0276  LR: 0.00000329  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0008(0.0010) Grad: 0.0386  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0011(0.0009) Grad: 0.0816  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.9777(0.9777) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0009  avg_val_loss: 1.5572  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0009  avg_val_loss: 1.5572  time: 41s\n","Epoch 8 - Score: 0.4013\n","INFO:__main__:Epoch 8 - Score: 0.4013\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0628(1.5572) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 29s) Loss: 0.0013(0.0013) Grad: nan  LR: 0.00000195  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0008(0.0007) Grad: 0.0423  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.0007(0.0007) Grad: 0.0421  LR: 0.00000083  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0011(0.0008) Grad: 0.0917  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.9824(0.9824) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0008  avg_val_loss: 1.5686  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0008  avg_val_loss: 1.5686  time: 41s\n","Epoch 9 - Score: 0.4013\n","INFO:__main__:Epoch 9 - Score: 0.4013\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0993(1.5686) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 26s) Loss: 0.0009(0.0009) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0010(0.0007) Grad: 0.0726  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0008(0.0008) Grad: 0.0376  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0004(0.0008) Grad: 0.0319  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.9849(0.9849) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0008  avg_val_loss: 1.5704  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0008  avg_val_loss: 1.5704  time: 41s\n","Epoch 10 - Score: 0.4013\n","INFO:__main__:Epoch 10 - Score: 0.4013\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.1015(1.5704) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 7 result ==========\n","INFO:__main__:========== fold: 7 result ==========\n","Score: 0.5592\n","INFO:__main__:Score: 0.5592\n","ACC BEST Score: 0.6579\n","INFO:__main__:ACC BEST Score: 0.6579\n","========== fold: 8 training ==========\n","INFO:__main__:========== fold: 8 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 51s) Loss: 0.6728(0.6728) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.6460(0.6230) Grad: 3.5298  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5618(0.6147) Grad: 1.6153  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.6465(0.6059) Grad: 1.8756  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5189(0.5189) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6059  avg_val_loss: 0.5858  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6059  avg_val_loss: 0.5858  time: 41s\n","Epoch 1 - Score: 0.2171\n","INFO:__main__:Epoch 1 - Score: 0.2171\n","Epoch 1 - Save Best Score: 0.2171 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.2171 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8075(0.5858) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.6038(0.6038) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.5085(0.5423) Grad: 3.5463  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.5255(0.5258) Grad: 4.2949  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.4670(0.5216) Grad: 2.7547  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3208(0.3208) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5216  avg_val_loss: 0.5492  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5216  avg_val_loss: 0.5492  time: 41s\n","Epoch 2 - Score: 0.2434\n","INFO:__main__:Epoch 2 - Score: 0.2434\n","Epoch 2 - Save Best Score: 0.2434 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.2434 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.1842(0.5492) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 54s) Loss: 0.2876(0.2876) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.1120(0.2895) Grad: 5.0716  LR: 0.00001739  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.1178(0.2704) Grad: 5.5336  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.3903(0.2688) Grad: 10.1501  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6426(0.6426) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2688  avg_val_loss: 0.6511  time: 42s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2688  avg_val_loss: 0.6511  time: 42s\n","Epoch 3 - Score: 0.5526\n","INFO:__main__:Epoch 3 - Score: 0.5526\n","Epoch 3 - Save Best Score: 0.5526 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5526 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.9270(0.6511) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 35s) Loss: 0.1123(0.1123) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.0266(0.0496) Grad: 1.9993  LR: 0.00001495  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0314(0.0417) Grad: 3.8976  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0023(0.0387) Grad: 0.1388  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.4673(0.4673) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0387  avg_val_loss: 1.0973  time: 41s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0387  avg_val_loss: 1.0973  time: 41s\n","Epoch 4 - Score: 0.2895\n","INFO:__main__:Epoch 4 - Score: 0.2895\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0592(1.0973) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.0717(0.0717) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0041(0.0092) Grad: 0.3067  LR: 0.00001203  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0023(0.0068) Grad: 0.1548  LR: 0.00001092  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0009(0.0057) Grad: 0.0682  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.4989(0.4989) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0057  avg_val_loss: 1.1713  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0057  avg_val_loss: 1.1713  time: 41s\n","Epoch 5 - Score: 0.3487\n","INFO:__main__:Epoch 5 - Score: 0.3487\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.4769(1.1713) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.0005(0.0005) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0013(0.0017) Grad: 0.0804  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0016(0.0016) Grad: 0.3762  LR: 0.00000781  \n","Epoch: [6][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.0007(0.0015) Grad: 0.0357  LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6091(0.6091) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0015  avg_val_loss: 1.2223  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0015  avg_val_loss: 1.2223  time: 41s\n","Epoch 6 - Score: 0.4211\n","INFO:__main__:Epoch 6 - Score: 0.4211\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.5530(1.2223) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0005(0.0005) Grad: nan  LR: 0.00000695  \n","Epoch: [7][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0005(0.0008) Grad: 0.0285  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0011(0.0008) Grad: 0.1345  LR: 0.00000491  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0006(0.0008) Grad: 0.0513  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5773(0.5773) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0008  avg_val_loss: 1.2688  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0008  avg_val_loss: 1.2688  time: 41s\n","Epoch 7 - Score: 0.4079\n","INFO:__main__:Epoch 7 - Score: 0.4079\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.7826(1.2688) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0006(0.0006) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0007(0.0006) Grad: 0.0561  LR: 0.00000329  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0007(0.0007) Grad: 0.0485  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0008(0.0006) Grad: 0.0657  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5778(0.5778) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0006  avg_val_loss: 1.2922  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0006  avg_val_loss: 1.2922  time: 41s\n","Epoch 8 - Score: 0.4013\n","INFO:__main__:Epoch 8 - Score: 0.4013\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.8708(1.2922) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0004(0.0004) Grad: nan  LR: 0.00000195  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0004(0.0005) Grad: 0.0282  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0004(0.0005) Grad: 0.0278  LR: 0.00000083  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0002(0.0006) Grad: 0.0285  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5784(0.5784) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0006  avg_val_loss: 1.3017  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0006  avg_val_loss: 1.3017  time: 41s\n","Epoch 9 - Score: 0.4013\n","INFO:__main__:Epoch 9 - Score: 0.4013\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.9055(1.3017) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0002(0.0002) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0005(0.0005) Grad: 0.0380  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0002(0.0006) Grad: 0.0138  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0005(0.0005) Grad: 0.0371  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5786(0.5786) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0005  avg_val_loss: 1.3030  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0005  avg_val_loss: 1.3030  time: 41s\n","Epoch 10 - Score: 0.4013\n","INFO:__main__:Epoch 10 - Score: 0.4013\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.9102(1.3030) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 8 result ==========\n","INFO:__main__:========== fold: 8 result ==========\n","Score: 0.5526\n","INFO:__main__:Score: 0.5526\n","ACC BEST Score: 0.7022\n","INFO:__main__:ACC BEST Score: 0.7022\n","========== fold: 9 training ==========\n","INFO:__main__:========== fold: 9 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.7892(0.7892) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.7270(0.6116) Grad: 5.5718  LR: 0.00001994  \n","Epoch: [1][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.6701(0.6066) Grad: 2.1004  LR: 0.00001975  \n","Epoch: [1][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.7264(0.6028) Grad: 4.7933  LR: 0.00001951  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5881(0.5881) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6028  avg_val_loss: 0.6464  time: 41s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6028  avg_val_loss: 0.6464  time: 41s\n","Epoch 1 - Score: 0.2895\n","INFO:__main__:Epoch 1 - Score: 0.2895\n","Epoch 1 - Save Best Score: 0.2895 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.2895 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7552(0.6464) \n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 35s) Loss: 0.6107(0.6107) Grad: nan  LR: 0.00001951  \n","Epoch: [2][100/279] Elapsed 0m 14s (remain 0m 24s) Loss: 0.6598(0.5545) Grad: 2.2767  LR: 0.00001910  \n","Epoch: [2][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.6875(0.5520) Grad: 6.4094  LR: 0.00001858  \n","Epoch: [2][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.3962(0.5492) Grad: 2.8344  LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.1543(0.1543) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5492  avg_val_loss: 0.6454  time: 41s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5492  avg_val_loss: 0.6454  time: 41s\n","Epoch 2 - Score: 0.0263\n","INFO:__main__:Epoch 2 - Score: 0.0263\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.6310(0.6454) \n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.4968(0.4968) Grad: nan  LR: 0.00001809  \n","Epoch: [3][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.2525(0.3317) Grad: 6.1642  LR: 0.00001739  \n","Epoch: [3][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.4414(0.3449) Grad: 13.3500  LR: 0.00001658  \n","Epoch: [3][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.3927(0.3386) Grad: 15.3925  LR: 0.00001590  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6137(0.6137) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3386  avg_val_loss: 0.7992  time: 41s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3386  avg_val_loss: 0.7992  time: 41s\n","Epoch 3 - Score: 0.4671\n","INFO:__main__:Epoch 3 - Score: 0.4671\n","Epoch 3 - Save Best Score: 0.4671 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4671 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 1.3186(0.7992) \n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.1647(0.1647) Grad: nan  LR: 0.00001589  \n","Epoch: [4][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.0779(0.0863) Grad: 7.0064  LR: 0.00001495  \n","Epoch: [4][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0123(0.0772) Grad: 0.5643  LR: 0.00001394  \n","Epoch: [4][278/279] Elapsed 0m 38s (remain 0m 0s) Loss: 0.0340(0.0811) Grad: 3.8504  LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.3326(0.3326) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0811  avg_val_loss: 1.1191  time: 42s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0811  avg_val_loss: 1.1191  time: 42s\n","Epoch 4 - Score: 0.2237\n","INFO:__main__:Epoch 4 - Score: 0.2237\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.3122(1.1191) \n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 3s) Loss: 0.0174(0.0174) Grad: nan  LR: 0.00001311  \n","Epoch: [5][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0038(0.0263) Grad: 0.1838  LR: 0.00001203  \n","Epoch: [5][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0035(0.0209) Grad: 0.1670  LR: 0.00001092  \n","Epoch: [5][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0021(0.0201) Grad: 0.0810  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.4061(0.4061) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0201  avg_val_loss: 1.3126  time: 41s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0201  avg_val_loss: 1.3126  time: 41s\n","Epoch 5 - Score: 0.2763\n","INFO:__main__:Epoch 5 - Score: 0.2763\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.0642(1.3126) \n","Epoch: [6][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0067(0.0067) Grad: nan  LR: 0.00001003  \n","Epoch: [6][100/279] Elapsed 0m 13s (remain 0m 23s) Loss: 0.0029(0.0068) Grad: 0.1440  LR: 0.00000891  \n","Epoch: [6][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0016(0.0047) Grad: 0.0673  LR: 0.00000781  \n","Epoch: [6][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0066(0.0054) Grad: 1.1690  LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.6179(0.6179) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0054  avg_val_loss: 1.4449  time: 41s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0054  avg_val_loss: 1.4449  time: 41s\n","Epoch 6 - Score: 0.3618\n","INFO:__main__:Epoch 6 - Score: 0.3618\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 2.9074(1.4449) \n","Epoch: [7][0/279] Elapsed 0m 0s (remain 1m 32s) Loss: 0.0028(0.0028) Grad: nan  LR: 0.00000695  \n","Epoch: [7][100/279] Elapsed 0m 14s (remain 0m 25s) Loss: 0.0016(0.0019) Grad: 0.0712  LR: 0.00000590  \n","Epoch: [7][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0013(0.0022) Grad: 0.0648  LR: 0.00000491  \n","Epoch: [7][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0015(0.0029) Grad: 0.0810  LR: 0.00000417  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5155(0.5155) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0029  avg_val_loss: 1.5043  time: 41s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0029  avg_val_loss: 1.5043  time: 41s\n","Epoch 7 - Score: 0.3026\n","INFO:__main__:Epoch 7 - Score: 0.3026\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.4877(1.5043) \n","Epoch: [8][0/279] Elapsed 0m 0s (remain 1m 30s) Loss: 0.0016(0.0016) Grad: nan  LR: 0.00000416  \n","Epoch: [8][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0015(0.0016) Grad: 0.0841  LR: 0.00000329  \n","Epoch: [8][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0018(0.0025) Grad: 0.1084  LR: 0.00000250  \n","Epoch: [8][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0015(0.0021) Grad: 0.1108  LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5245(0.5245) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0021  avg_val_loss: 1.5398  time: 41s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0021  avg_val_loss: 1.5398  time: 41s\n","Epoch 8 - Score: 0.2961\n","INFO:__main__:Epoch 8 - Score: 0.2961\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.5868(1.5398) \n","Epoch: [9][0/279] Elapsed 0m 0s (remain 1m 29s) Loss: 0.0011(0.0011) Grad: nan  LR: 0.00000195  \n","Epoch: [9][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0009(0.0031) Grad: 0.0381  LR: 0.00000133  \n","Epoch: [9][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0012(0.0022) Grad: 0.0773  LR: 0.00000083  \n","Epoch: [9][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0010(0.0019) Grad: 0.0468  LR: 0.00000051  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5307(0.5307) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0019  avg_val_loss: 1.5534  time: 41s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0019  avg_val_loss: 1.5534  time: 41s\n","Epoch 9 - Score: 0.3026\n","INFO:__main__:Epoch 9 - Score: 0.3026\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.6163(1.5534) \n","Epoch: [10][0/279] Elapsed 0m 0s (remain 1m 33s) Loss: 0.0007(0.0007) Grad: nan  LR: 0.00000051  \n","Epoch: [10][100/279] Elapsed 0m 13s (remain 0m 24s) Loss: 0.0012(0.0012) Grad: 0.0589  LR: 0.00000022  \n","Epoch: [10][200/279] Elapsed 0m 27s (remain 0m 10s) Loss: 0.0013(0.0013) Grad: 0.0980  LR: 0.00000005  \n","Epoch: [10][278/279] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0009(0.0018) Grad: 0.0421  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 5s) Loss: 0.5310(0.5310) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0018  avg_val_loss: 1.5556  time: 41s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0018  avg_val_loss: 1.5556  time: 41s\n","Epoch 10 - Score: 0.3026\n","INFO:__main__:Epoch 10 - Score: 0.3026\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 3.6230(1.5556) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 9 result ==========\n","INFO:__main__:========== fold: 9 result ==========\n","Score: 0.4671\n","INFO:__main__:Score: 0.4671\n","ACC BEST Score: 0.6459\n","INFO:__main__:ACC BEST Score: 0.6459\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.4944\n","INFO:__main__:Score: 0.4944\n","ACC BEST Score: 0.6807\n","INFO:__main__:ACC BEST Score: 0.6807\n"]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"xLy2EqucW--T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WB0KGIO6CdB_"},"execution_count":null,"outputs":[]}]}