{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfxrKEF9uqvSsBooygo7fo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"3d2f540a20bc4883b178315c4bf7c83d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bddc11a5aea341729feb696f77d4022f","IPY_MODEL_9558d7c0a0a14ece810cfc006d3ce8cb","IPY_MODEL_272da65f24a84603b7ef7c0f2beb9f63"],"layout":"IPY_MODEL_41971d308c824adb99bb0818760d9f33"}},"bddc11a5aea341729feb696f77d4022f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_714b657370cd454bb91f700d5be38e17","placeholder":"​","style":"IPY_MODEL_add150dc103749d5ad538635f21e50bd","value":"Downloading (…)okenizer_config.json: 100%"}},"9558d7c0a0a14ece810cfc006d3ce8cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c77a35a8925b496b976286066fe5355f","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ca355b812af4c9d90d1bb0fac9002a4","value":52}},"272da65f24a84603b7ef7c0f2beb9f63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1decc4cc9f6a44198aaa0ef976bcae61","placeholder":"​","style":"IPY_MODEL_c3c24db89b5a4bcf9bcee60e55eeb94d","value":" 52.0/52.0 [00:00&lt;00:00, 2.81kB/s]"}},"41971d308c824adb99bb0818760d9f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714b657370cd454bb91f700d5be38e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"add150dc103749d5ad538635f21e50bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c77a35a8925b496b976286066fe5355f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ca355b812af4c9d90d1bb0fac9002a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1decc4cc9f6a44198aaa0ef976bcae61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3c24db89b5a4bcf9bcee60e55eeb94d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51600cbb5c3d4da4a61413add1959118":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bde5d347d9c149bf876adcdb3af8cb27","IPY_MODEL_04a3f3024cc34c49bc8410bec8ffd447","IPY_MODEL_9adb339f5390496d8a67a9a88a73a18d"],"layout":"IPY_MODEL_3ddeb0f199f4475395d9f04e3b16a892"}},"bde5d347d9c149bf876adcdb3af8cb27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f4425886db845369d65624d03e82f40","placeholder":"​","style":"IPY_MODEL_078f26574bdf4a6c99cf113bc3e20e26","value":"Downloading (…)lve/main/config.json: 100%"}},"04a3f3024cc34c49bc8410bec8ffd447":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b5777ac2c474f6ab154b488dbcf11f4","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ef5d152bfbb49e9a384d8995afd6c59","value":579}},"9adb339f5390496d8a67a9a88a73a18d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56d5699af10e4feb888d0cc347e27d54","placeholder":"​","style":"IPY_MODEL_29d072a2bf47428daf44cc90543c4cca","value":" 579/579 [00:00&lt;00:00, 31.2kB/s]"}},"3ddeb0f199f4475395d9f04e3b16a892":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f4425886db845369d65624d03e82f40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"078f26574bdf4a6c99cf113bc3e20e26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b5777ac2c474f6ab154b488dbcf11f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ef5d152bfbb49e9a384d8995afd6c59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56d5699af10e4feb888d0cc347e27d54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29d072a2bf47428daf44cc90543c4cca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae79b22c87948f3b6e50c7ec80a4509":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e768fe6f75c24e5d855d95b038e5288e","IPY_MODEL_685dc371e03f40c99d6bbec2438b9343","IPY_MODEL_45db82e4e4f448feb2098b821f08da3c"],"layout":"IPY_MODEL_8724a06a73bb46838c16e207a86949fe"}},"e768fe6f75c24e5d855d95b038e5288e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ccfab8265f4a048f454cc460ed8ab9","placeholder":"​","style":"IPY_MODEL_018241604c884a9ab8d2e0cbc13c960f","value":"Downloading spm.model: 100%"}},"685dc371e03f40c99d6bbec2438b9343":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e97369117bfe4aa88de2861727681893","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1edde52cfdcc4e098ee7a1eee57d2319","value":2464616}},"45db82e4e4f448feb2098b821f08da3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e362843781f445cdbb668456807d0e75","placeholder":"​","style":"IPY_MODEL_5e6447676c0744fb87e5e7b7b181853a","value":" 2.46M/2.46M [00:00&lt;00:00, 24.2MB/s]"}},"8724a06a73bb46838c16e207a86949fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50ccfab8265f4a048f454cc460ed8ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"018241604c884a9ab8d2e0cbc13c960f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e97369117bfe4aa88de2861727681893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1edde52cfdcc4e098ee7a1eee57d2319":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e362843781f445cdbb668456807d0e75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e6447676c0744fb87e5e7b7b181853a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06ca02f6af2e449e9e78e65ac984ccc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bec9a94604a442b810e4c56ef4db646","IPY_MODEL_f980f4743d3e4794af641203014d6754","IPY_MODEL_724c6e5512a94981b3dc391ae50d5d61"],"layout":"IPY_MODEL_5917112e4f594dee87aa46d0116a4c3d"}},"8bec9a94604a442b810e4c56ef4db646":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a8ca3658e0748c88a8c8da61b8c871d","placeholder":"​","style":"IPY_MODEL_d0a9ec3ac2cc491bb3eeda00f00f22e7","value":"Downloading pytorch_model.bin: 100%"}},"f980f4743d3e4794af641203014d6754":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3744b8e8410c4fb7bc91ace704999483","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6425a1e065da4af5a135167ae2a2be5c","value":371146213}},"724c6e5512a94981b3dc391ae50d5d61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1571f519221f43aba64648296d511a84","placeholder":"​","style":"IPY_MODEL_a73d800d0ad54280b2985911b6bc250d","value":" 371M/371M [00:06&lt;00:00, 59.6MB/s]"}},"5917112e4f594dee87aa46d0116a4c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a8ca3658e0748c88a8c8da61b8c871d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0a9ec3ac2cc491bb3eeda00f00f22e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3744b8e8410c4fb7bc91ace704999483":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6425a1e065da4af5a135167ae2a2be5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1571f519221f43aba64648296d511a84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73d800d0ad54280b2985911b6bc250d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMVmfQcW79nK","executionInfo":{"status":"ok","timestamp":1680450513038,"user_tz":-540,"elapsed":112543,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"74ea4bb2-17ac-444d-89c5-40f67a46daa2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMsVsVYs8Jib","executionInfo":{"status":"ok","timestamp":1680450534690,"user_tz":-540,"elapsed":21656,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"78707b98-2209-47ed-b4b4-b0a02481ce19"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qonwoL_F8Oe_","executionInfo":{"status":"ok","timestamp":1680450535089,"user_tz":-540,"elapsed":403,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"53df9cc7-386e-4955-c939-a96ffebe8e1c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Apr  2 15:48:54 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["\n","import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"y2tBjTH68Qnb","executionInfo":{"status":"ok","timestamp":1680450541504,"user_tz":-540,"elapsed":6416,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=6\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    target_cols = 'y'\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"],"metadata":{"id":"VCF2-czO8Svr","executionInfo":{"status":"ok","timestamp":1680450541505,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["DIR = \"/content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","OUTPUT_EXP_DIR = DIR + '/output/EXP014/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"],"metadata":{"id":"JyQ97ca88dRA","executionInfo":{"status":"ok","timestamp":1680450541913,"user_tz":-540,"elapsed":416,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return accuracy_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_acc_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = accuracy_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    return accuracy_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"7QkA50jQ80_3","executionInfo":{"status":"ok","timestamp":1680450541914,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"wRnSUEJR9A9y","executionInfo":{"status":"ok","timestamp":1680450541914,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train_data.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test_data.csv\"))\n","sample_sub = pd.read_csv(os.path.join(INPUT_DIR,\"submission.csv\"))\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(sample_sub.shape)\n","display(sample_sub.head(3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"id":"GUnukiIG9FM5","executionInfo":{"status":"ok","timestamp":1680450543374,"user_tz":-540,"elapsed":1463,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"8d74d466-cfa4-4b9f-c858-3f0d25bff272"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["(4974, 6)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                             title  year  \\\n","0   1      Hierarchical Adversarially Learned Inference  2018   \n","1   2    Learning to Compute Word Embeddings On the Fly  2018   \n","2   3  Graph2Seq: Scalable Learning Dynamics for Graphs  2018   \n","\n","                                            abstract  \\\n","0  We propose a novel hierarchical generative mod...   \n","1  Words in natural language follow a Zipfian dis...   \n","2  Neural networks are increasingly used as a gen...   \n","\n","                                            keywords  y  \n","0  generative, hierarchical, unsupervised, semisu...  0  \n","1      NLU, word embeddings, representation learning  0  \n","2                                                NaN  0  "],"text/html":["\n","  <div id=\"df-2b34c2c5-9b4b-412b-9505-2dac35e49727\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Hierarchical Adversarially Learned Inference</td>\n","      <td>2018</td>\n","      <td>We propose a novel hierarchical generative mod...</td>\n","      <td>generative, hierarchical, unsupervised, semisu...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Learning to Compute Word Embeddings On the Fly</td>\n","      <td>2018</td>\n","      <td>Words in natural language follow a Zipfian dis...</td>\n","      <td>NLU, word embeddings, representation learning</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Graph2Seq: Scalable Learning Dynamics for Graphs</td>\n","      <td>2018</td>\n","      <td>Neural networks are increasingly used as a gen...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b34c2c5-9b4b-412b-9505-2dac35e49727')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2b34c2c5-9b4b-412b-9505-2dac35e49727 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2b34c2c5-9b4b-412b-9505-2dac35e49727');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                              title  year  \\\n","0   1  StyleAlign: Analysis and Applications of Align...  2022   \n","1   2  Embedding a random graph via GNN: mean-field i...  2021   \n","2   3  BBRefinement: an universal scheme to improve p...  2021   \n","\n","                                            abstract  \\\n","0  In this paper, we perform an in-depth study of...   \n","1  We develop a theory for embedding a random gra...   \n","2  We present a conceptually simple yet powerful ...   \n","\n","                                            keywords  \n","0  StyleGAN, transfer learning, fine tuning, mode...  \n","1  Graph neural network, graph embedding, multi-r...  \n","2  object detection, deep neural networks, refine...  "],"text/html":["\n","  <div id=\"df-bd725475-e090-460c-8a1c-0d1afeda996a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>StyleAlign: Analysis and Applications of Align...</td>\n","      <td>2022</td>\n","      <td>In this paper, we perform an in-depth study of...</td>\n","      <td>StyleGAN, transfer learning, fine tuning, mode...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Embedding a random graph via GNN: mean-field i...</td>\n","      <td>2021</td>\n","      <td>We develop a theory for embedding a random gra...</td>\n","      <td>Graph neural network, graph embedding, multi-r...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>BBRefinement: an universal scheme to improve p...</td>\n","      <td>2021</td>\n","      <td>We present a conceptually simple yet powerful ...</td>\n","      <td>object detection, deep neural networks, refine...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd725475-e090-460c-8a1c-0d1afeda996a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bd725475-e090-460c-8a1c-0d1afeda996a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bd725475-e090-460c-8a1c-0d1afeda996a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["   id  y\n","0   1  0\n","1   2  0\n","2   3  0"],"text/html":["\n","  <div id=\"df-f1b2307f-3de9-48a7-822c-d3ef8541c969\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1b2307f-3de9-48a7-822c-d3ef8541c969')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f1b2307f-3de9-48a7-822c-d3ef8541c969 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f1b2307f-3de9-48a7-822c-d3ef8541c969');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["train[\"texts\"] = train[\"title\"] + \"[SEP]\" + train[\"abstract\"]"],"metadata":{"id":"S2LAKUbZ9L92","executionInfo":{"status":"ok","timestamp":1680450543374,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.y)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"9MRHQQ6K9Zot","executionInfo":{"status":"ok","timestamp":1680450543374,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["3d2f540a20bc4883b178315c4bf7c83d","bddc11a5aea341729feb696f77d4022f","9558d7c0a0a14ece810cfc006d3ce8cb","272da65f24a84603b7ef7c0f2beb9f63","41971d308c824adb99bb0818760d9f33","714b657370cd454bb91f700d5be38e17","add150dc103749d5ad538635f21e50bd","c77a35a8925b496b976286066fe5355f","9ca355b812af4c9d90d1bb0fac9002a4","1decc4cc9f6a44198aaa0ef976bcae61","c3c24db89b5a4bcf9bcee60e55eeb94d","51600cbb5c3d4da4a61413add1959118","bde5d347d9c149bf876adcdb3af8cb27","04a3f3024cc34c49bc8410bec8ffd447","9adb339f5390496d8a67a9a88a73a18d","3ddeb0f199f4475395d9f04e3b16a892","8f4425886db845369d65624d03e82f40","078f26574bdf4a6c99cf113bc3e20e26","0b5777ac2c474f6ab154b488dbcf11f4","5ef5d152bfbb49e9a384d8995afd6c59","56d5699af10e4feb888d0cc347e27d54","29d072a2bf47428daf44cc90543c4cca","cae79b22c87948f3b6e50c7ec80a4509","e768fe6f75c24e5d855d95b038e5288e","685dc371e03f40c99d6bbec2438b9343","45db82e4e4f448feb2098b821f08da3c","8724a06a73bb46838c16e207a86949fe","50ccfab8265f4a048f454cc460ed8ab9","018241604c884a9ab8d2e0cbc13c960f","e97369117bfe4aa88de2861727681893","1edde52cfdcc4e098ee7a1eee57d2319","e362843781f445cdbb668456807d0e75","5e6447676c0744fb87e5e7b7b181853a"]},"id":"kTf6lgW19iep","executionInfo":{"status":"ok","timestamp":1680450546220,"user_tz":-540,"elapsed":2849,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4dbba4c7-a3d6-4bcc-d9a4-b20fbfa7591c"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d2f540a20bc4883b178315c4bf7c83d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51600cbb5c3d4da4a61413add1959118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae79b22c87948f3b6e50c7ec80a4509"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 3 # cls\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wt2P1uC_9oRd","executionInfo":{"status":"ok","timestamp":1680450550112,"user_tz":-540,"elapsed":3896,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"2aa07c14-c0da-4c09-ccd3-5f99f6283daf"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4974/4974 [00:03<00:00, 1336.39it/s]\n","max_len: 522\n","INFO:__main__:max_len: 522\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['texts'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","    \n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"rmsbpfsc92bq","executionInfo":{"status":"ok","timestamp":1680450550112,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        feature = self.layer_norm1(feature)\n","        output = self.fc(feature)\n","        return output"],"metadata":{"id":"DbE2YLRd9-uk","executionInfo":{"status":"ok","timestamp":1680450550112,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"Evhi1yCQ-Xjb","executionInfo":{"status":"ok","timestamp":1680450550113,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['y'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"],"metadata":{"id":"pR91ZhBL_pW4","executionInfo":{"status":"ok","timestamp":1680450550113,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['y'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        acc_score = get_acc_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'ACC BEST Score: {acc_score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["06ca02f6af2e449e9e78e65ac984ccc0","8bec9a94604a442b810e4c56ef4db646","f980f4743d3e4794af641203014d6754","724c6e5512a94981b3dc391ae50d5d61","5917112e4f594dee87aa46d0116a4c3d","0a8ca3658e0748c88a8c8da61b8c871d","d0a9ec3ac2cc491bb3eeda00f00f22e7","3744b8e8410c4fb7bc91ace704999483","6425a1e065da4af5a135167ae2a2be5c","1571f519221f43aba64648296d511a84","a73d800d0ad54280b2985911b6bc250d"]},"id":"gZY5kSe1_1Fl","executionInfo":{"status":"ok","timestamp":1680451675654,"user_tz":-540,"elapsed":1125556,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"2c2b5a2f-d524-427a-a22d-3c393282eab7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06ca02f6af2e449e9e78e65ac984ccc0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/248] Elapsed 0m 4s (remain 17m 12s) Loss: 1.0488(1.0488) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/248] Elapsed 0m 15s (remain 0m 22s) Loss: 0.6767(0.6393) Grad: 3.1847  LR: 0.00001977  \n","Epoch: [1][200/248] Elapsed 0m 27s (remain 0m 6s) Loss: 0.5489(0.6296) Grad: 5.2055  LR: 0.00001912  \n","Epoch: [1][247/248] Elapsed 0m 33s (remain 0m 0s) Loss: 0.6207(0.6246) Grad: 2.3336  LR: 0.00001867  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.4701(0.4701) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6246  avg_val_loss: 0.6176  time: 40s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6246  avg_val_loss: 0.6176  time: 40s\n","Epoch 1 - Score: 0.6945\n","INFO:__main__:Epoch 1 - Score: 0.6945\n","Epoch 1 - Save Best Score: 0.6945 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6945 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.9023(0.6176) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [2][0/248] Elapsed 0m 0s (remain 1m 19s) Loss: 0.5513(0.5513) Grad: nan  LR: 0.00001866  \n","Epoch: [2][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.6038(0.5968) Grad: 1.1525  LR: 0.00001742  \n","Epoch: [2][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.6025(0.5958) Grad: 1.0499  LR: 0.00001585  \n","Epoch: [2][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.6617(0.5934) Grad: 3.4961  LR: 0.00001502  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4739(0.4739) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5934  avg_val_loss: 0.6075  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5934  avg_val_loss: 0.6075  time: 36s\n","Epoch 2 - Score: 0.6945\n","INFO:__main__:Epoch 2 - Score: 0.6945\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.7667(0.6075) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [3][0/248] Elapsed 0m 0s (remain 1m 15s) Loss: 0.5495(0.5495) Grad: nan  LR: 0.00001501  \n","Epoch: [3][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.5912(0.5434) Grad: 3.9101  LR: 0.00001309  \n","Epoch: [3][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.7354(0.5326) Grad: 4.1980  LR: 0.00001103  \n","Epoch: [3][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.3796(0.5300) Grad: 4.1755  LR: 0.00001004  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.3079(0.3079) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5300  avg_val_loss: 0.5761  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.5300  avg_val_loss: 0.5761  time: 36s\n","Epoch 3 - Score: 0.7095\n","INFO:__main__:Epoch 3 - Score: 0.7095\n","Epoch 3 - Save Best Score: 0.7095 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7095 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.7463(0.5761) \n","f1 score : 0.3620309050772627\n","recall score : 0.26973684210526316\n","precision score : 0.5503355704697986\n","Epoch: [4][0/248] Elapsed 0m 0s (remain 1m 20s) Loss: 0.4289(0.4289) Grad: nan  LR: 0.00001002  \n","Epoch: [4][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.2358(0.3723) Grad: 3.6903  LR: 0.00000793  \n","Epoch: [4][200/248] Elapsed 0m 24s (remain 0m 5s) Loss: 0.3143(0.3547) Grad: 6.4130  LR: 0.00000593  \n","Epoch: [4][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.2112(0.3540) Grad: 7.5469  LR: 0.00000505  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.2752(0.2752) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3540  avg_val_loss: 0.6917  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3540  avg_val_loss: 0.6917  time: 36s\n","Epoch 4 - Score: 0.7005\n","INFO:__main__:Epoch 4 - Score: 0.7005\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.3336(0.6917) \n","f1 score : 0.39676113360323884\n","recall score : 0.3223684210526316\n","precision score : 0.5157894736842106\n","Epoch: [5][0/248] Elapsed 0m 0s (remain 1m 17s) Loss: 0.1409(0.1409) Grad: nan  LR: 0.00000503  \n","Epoch: [5][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0399(0.1257) Grad: 3.9407  LR: 0.00000333  \n","Epoch: [5][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0274(0.1204) Grad: 2.1428  LR: 0.00000192  \n","Epoch: [5][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0400(0.1155) Grad: 3.3450  LR: 0.00000138  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6527(0.6527) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1155  avg_val_loss: 1.0888  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1155  avg_val_loss: 1.0888  time: 36s\n","Epoch 5 - Score: 0.6523\n","INFO:__main__:Epoch 5 - Score: 0.6523\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 2.8590(1.0888) \n","f1 score : 0.4525316455696203\n","recall score : 0.47039473684210525\n","precision score : 0.43597560975609756\n","Epoch: [6][0/248] Elapsed 0m 0s (remain 1m 14s) Loss: 0.0132(0.0132) Grad: nan  LR: 0.00000136  \n","Epoch: [6][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0101(0.0439) Grad: 0.3299  LR: 0.00000050  \n","Epoch: [6][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0140(0.0424) Grad: 0.4096  LR: 0.00000006  \n","Epoch: [6][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0183(0.0411) Grad: 0.6955  LR: 0.00000000  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5140(0.5140) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0411  avg_val_loss: 1.1222  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0411  avg_val_loss: 1.1222  time: 36s\n","Epoch 6 - Score: 0.6653\n","INFO:__main__:Epoch 6 - Score: 0.6653\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 3.6922(1.1222) \n","f1 score : 0.408525754884547\n","recall score : 0.3782894736842105\n","precision score : 0.444015444015444\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.7095\n","INFO:__main__:Score: 0.7095\n","ACC BEST Score: 0.7196\n","INFO:__main__:ACC BEST Score: 0.7196\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.3620309050772627\n","recall score : 0.26973684210526316\n","precision score : 0.5503355704697986\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/248] Elapsed 0m 0s (remain 1m 28s) Loss: 0.6437(0.6437) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.6903(0.6265) Grad: 2.7052  LR: 0.00001977  \n","Epoch: [1][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.4235(0.6143) Grad: 3.1411  LR: 0.00001912  \n","Epoch: [1][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.6040(0.6150) Grad: 4.7076  LR: 0.00001867  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.4861(0.4861) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6150  avg_val_loss: 0.6135  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6150  avg_val_loss: 0.6135  time: 36s\n","Epoch 1 - Score: 0.6935\n","INFO:__main__:Epoch 1 - Score: 0.6935\n","Epoch 1 - Save Best Score: 0.6935 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6935 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.8273(0.6135) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [2][0/248] Elapsed 0m 0s (remain 1m 22s) Loss: 0.4795(0.4795) Grad: nan  LR: 0.00001866  \n","Epoch: [2][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.5344(0.5722) Grad: 2.6775  LR: 0.00001742  \n","Epoch: [2][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.6994(0.5459) Grad: 10.6357  LR: 0.00001585  \n","Epoch: [2][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.5851(0.5491) Grad: 5.4288  LR: 0.00001502  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.5142(0.5142) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5491  avg_val_loss: 0.6060  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5491  avg_val_loss: 0.6060  time: 36s\n","Epoch 2 - Score: 0.6734\n","INFO:__main__:Epoch 2 - Score: 0.6734\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6791(0.6060) \n","f1 score : 0.5255474452554745\n","recall score : 0.5901639344262295\n","precision score : 0.47368421052631576\n","Epoch: [3][0/248] Elapsed 0m 0s (remain 1m 18s) Loss: 0.4547(0.4547) Grad: nan  LR: 0.00001501  \n","Epoch: [3][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.1211(0.2941) Grad: 6.5697  LR: 0.00001309  \n","Epoch: [3][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.2947(0.2606) Grad: 9.8802  LR: 0.00001103  \n","Epoch: [3][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.1600(0.2587) Grad: 8.1870  LR: 0.00001004  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.5282(0.5282) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2587  avg_val_loss: 0.7252  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2587  avg_val_loss: 0.7252  time: 36s\n","Epoch 3 - Score: 0.6663\n","INFO:__main__:Epoch 3 - Score: 0.6663\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.2061(0.7252) \n","f1 score : 0.4779874213836478\n","recall score : 0.49836065573770494\n","precision score : 0.459214501510574\n","Epoch: [4][0/248] Elapsed 0m 0s (remain 1m 19s) Loss: 0.0445(0.0445) Grad: nan  LR: 0.00001002  \n","Epoch: [4][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0226(0.0372) Grad: 2.6387  LR: 0.00000793  \n","Epoch: [4][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0184(0.0292) Grad: 3.3244  LR: 0.00000593  \n","Epoch: [4][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0083(0.0266) Grad: 0.3861  LR: 0.00000505  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.3494(0.3494) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0266  avg_val_loss: 1.0242  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0266  avg_val_loss: 1.0242  time: 36s\n","Epoch 4 - Score: 0.6844\n","INFO:__main__:Epoch 4 - Score: 0.6844\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 3.3568(1.0242) \n","f1 score : 0.38910505836575876\n","recall score : 0.32786885245901637\n","precision score : 0.4784688995215311\n","Epoch: [5][0/248] Elapsed 0m 0s (remain 1m 16s) Loss: 0.0063(0.0063) Grad: nan  LR: 0.00000503  \n","Epoch: [5][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0050(0.0052) Grad: 0.3095  LR: 0.00000333  \n","Epoch: [5][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0037(0.0047) Grad: 0.1680  LR: 0.00000192  \n","Epoch: [5][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0044(0.0046) Grad: 0.2251  LR: 0.00000138  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.3208(0.3208) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0046  avg_val_loss: 1.1249  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0046  avg_val_loss: 1.1249  time: 36s\n","Epoch 5 - Score: 0.6824\n","INFO:__main__:Epoch 5 - Score: 0.6824\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 4.0561(1.1249) \n","f1 score : 0.373015873015873\n","recall score : 0.3081967213114754\n","precision score : 0.4723618090452261\n","Epoch: [6][0/248] Elapsed 0m 0s (remain 1m 19s) Loss: 0.0045(0.0045) Grad: nan  LR: 0.00000136  \n","Epoch: [6][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.0050(0.0036) Grad: 0.3436  LR: 0.00000050  \n","Epoch: [6][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0031(0.0036) Grad: 0.1016  LR: 0.00000006  \n","Epoch: [6][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0040(0.0036) Grad: 0.1481  LR: 0.00000000  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.3210(0.3210) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0036  avg_val_loss: 1.1365  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0036  avg_val_loss: 1.1365  time: 36s\n","Epoch 6 - Score: 0.6824\n","INFO:__main__:Epoch 6 - Score: 0.6824\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 4.1192(1.1365) \n","f1 score : 0.373015873015873\n","recall score : 0.3081967213114754\n","precision score : 0.4723618090452261\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.6935\n","INFO:__main__:Score: 0.6935\n","ACC BEST Score: 0.7055\n","INFO:__main__:ACC BEST Score: 0.7055\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/248] Elapsed 0m 0s (remain 1m 26s) Loss: 0.5637(0.5637) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.5198(0.6187) Grad: 3.5967  LR: 0.00001977  \n","Epoch: [1][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.6723(0.6094) Grad: 4.6654  LR: 0.00001912  \n","Epoch: [1][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.5741(0.6119) Grad: 1.7543  LR: 0.00001867  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4289(0.4289) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6119  avg_val_loss: 0.5961  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6119  avg_val_loss: 0.5961  time: 36s\n","Epoch 1 - Score: 0.6975\n","INFO:__main__:Epoch 1 - Score: 0.6975\n","Epoch 1 - Save Best Score: 0.6975 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6975 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.8530(0.5961) \n","f1 score : 0.02588996763754045\n","recall score : 0.013114754098360656\n","precision score : 1.0\n","Epoch: [2][0/248] Elapsed 0m 0s (remain 1m 21s) Loss: 0.5148(0.5148) Grad: nan  LR: 0.00001866  \n","Epoch: [2][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.6701(0.5156) Grad: 10.3291  LR: 0.00001742  \n","Epoch: [2][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.6589(0.5274) Grad: 3.4113  LR: 0.00001585  \n","Epoch: [2][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.4548(0.5265) Grad: 3.4114  LR: 0.00001502  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.4165(0.4165) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5265  avg_val_loss: 0.5851  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5265  avg_val_loss: 0.5851  time: 36s\n","Epoch 2 - Score: 0.6945\n","INFO:__main__:Epoch 2 - Score: 0.6945\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.8887(0.5851) \n","f1 score : 0.3303964757709251\n","recall score : 0.2459016393442623\n","precision score : 0.5033557046979866\n","Epoch: [3][0/248] Elapsed 0m 0s (remain 1m 23s) Loss: 0.2947(0.2947) Grad: nan  LR: 0.00001501  \n","Epoch: [3][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.2044(0.3114) Grad: 6.1052  LR: 0.00001309  \n","Epoch: [3][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.3122(0.2824) Grad: 11.5005  LR: 0.00001103  \n","Epoch: [3][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.1305(0.2722) Grad: 11.4153  LR: 0.00001004  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.4312(0.4312) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2722  avg_val_loss: 0.8330  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2722  avg_val_loss: 0.8330  time: 36s\n","Epoch 3 - Score: 0.6724\n","INFO:__main__:Epoch 3 - Score: 0.6724\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.6769(0.8330) \n","f1 score : 0.3319672131147541\n","recall score : 0.26557377049180325\n","precision score : 0.4426229508196721\n","Epoch: [4][0/248] Elapsed 0m 0s (remain 1m 24s) Loss: 0.3489(0.3489) Grad: nan  LR: 0.00001002  \n","Epoch: [4][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.0196(0.0455) Grad: 2.1008  LR: 0.00000793  \n","Epoch: [4][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.3292(0.0413) Grad: 4.7269  LR: 0.00000593  \n","Epoch: [4][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0213(0.0372) Grad: 3.6759  LR: 0.00000505  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6284(0.6284) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0372  avg_val_loss: 1.1216  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0372  avg_val_loss: 1.1216  time: 36s\n","Epoch 4 - Score: 0.6774\n","INFO:__main__:Epoch 4 - Score: 0.6774\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.6266(1.1216) \n","f1 score : 0.3885714285714285\n","recall score : 0.3344262295081967\n","precision score : 0.4636363636363636\n","Epoch: [5][0/248] Elapsed 0m 0s (remain 1m 17s) Loss: 0.0054(0.0054) Grad: nan  LR: 0.00000503  \n","Epoch: [5][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0061(0.0094) Grad: 0.4266  LR: 0.00000333  \n","Epoch: [5][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0049(0.0079) Grad: 0.3102  LR: 0.00000192  \n","Epoch: [5][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0044(0.0084) Grad: 0.2463  LR: 0.00000138  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 13s) Loss: 0.7564(0.7564) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0084  avg_val_loss: 1.2143  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0084  avg_val_loss: 1.2143  time: 36s\n","Epoch 5 - Score: 0.6643\n","INFO:__main__:Epoch 5 - Score: 0.6643\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.5855(1.2143) \n","f1 score : 0.3927272727272727\n","recall score : 0.3540983606557377\n","precision score : 0.44081632653061226\n","Epoch: [6][0/248] Elapsed 0m 0s (remain 1m 18s) Loss: 0.0044(0.0044) Grad: nan  LR: 0.00000136  \n","Epoch: [6][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0033(0.0063) Grad: 0.1807  LR: 0.00000050  \n","Epoch: [6][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0035(0.0060) Grad: 0.0944  LR: 0.00000006  \n","Epoch: [6][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0049(0.0057) Grad: 0.4310  LR: 0.00000000  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.7697(0.7697) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0057  avg_val_loss: 1.2234  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0057  avg_val_loss: 1.2234  time: 36s\n","Epoch 6 - Score: 0.6633\n","INFO:__main__:Epoch 6 - Score: 0.6633\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.5705(1.2234) \n","f1 score : 0.39421338155515373\n","recall score : 0.35737704918032787\n","precision score : 0.43951612903225806\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.6975\n","INFO:__main__:Score: 0.6975\n","ACC BEST Score: 0.6995\n","INFO:__main__:ACC BEST Score: 0.6995\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.02588996763754045\n","recall score : 0.013114754098360656\n","precision score : 1.0\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/248] Elapsed 0m 0s (remain 1m 26s) Loss: 0.7845(0.7845) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.8779(0.6359) Grad: 8.5131  LR: 0.00001977  \n","Epoch: [1][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.6193(0.6227) Grad: 0.6727  LR: 0.00001912  \n","Epoch: [1][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.4074(0.6171) Grad: 4.6525  LR: 0.00001867  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 13s) Loss: 0.3356(0.3356) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6171  avg_val_loss: 0.5921  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6171  avg_val_loss: 0.5921  time: 36s\n","Epoch 1 - Score: 0.6935\n","INFO:__main__:Epoch 1 - Score: 0.6935\n","Epoch 1 - Save Best Score: 0.6935 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6935 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.1065(0.5921) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [2][0/248] Elapsed 0m 0s (remain 1m 30s) Loss: 0.4953(0.4953) Grad: nan  LR: 0.00001866  \n","Epoch: [2][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.5818(0.5512) Grad: 6.8944  LR: 0.00001742  \n","Epoch: [2][200/248] Elapsed 0m 24s (remain 0m 5s) Loss: 0.4428(0.5521) Grad: 1.6330  LR: 0.00001585  \n","Epoch: [2][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.4949(0.5503) Grad: 2.8630  LR: 0.00001502  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2760(0.2760) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5503  avg_val_loss: 0.5861  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5503  avg_val_loss: 0.5861  time: 36s\n","Epoch 2 - Score: 0.7075\n","INFO:__main__:Epoch 2 - Score: 0.7075\n","Epoch 2 - Save Best Score: 0.7075 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7075 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.8509(0.5861) \n","f1 score : 0.24806201550387597\n","recall score : 0.15737704918032788\n","precision score : 0.5853658536585366\n","Epoch: [3][0/248] Elapsed 0m 0s (remain 1m 23s) Loss: 0.5085(0.5085) Grad: nan  LR: 0.00001501  \n","Epoch: [3][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.2198(0.3254) Grad: 7.8743  LR: 0.00001309  \n","Epoch: [3][200/248] Elapsed 0m 24s (remain 0m 5s) Loss: 0.2304(0.3160) Grad: 5.5701  LR: 0.00001103  \n","Epoch: [3][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.2220(0.3057) Grad: 6.8008  LR: 0.00001004  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.1702(0.1702) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3057  avg_val_loss: 0.7827  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3057  avg_val_loss: 0.7827  time: 36s\n","Epoch 3 - Score: 0.7075\n","INFO:__main__:Epoch 3 - Score: 0.7075\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.4858(0.7827) \n","f1 score : 0.3576158940397351\n","recall score : 0.26557377049180325\n","precision score : 0.5472972972972973\n","Epoch: [4][0/248] Elapsed 0m 0s (remain 1m 22s) Loss: 0.0534(0.0534) Grad: nan  LR: 0.00001002  \n","Epoch: [4][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0201(0.0571) Grad: 1.2040  LR: 0.00000793  \n","Epoch: [4][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0055(0.0423) Grad: 0.1883  LR: 0.00000593  \n","Epoch: [4][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0294(0.0401) Grad: 4.0628  LR: 0.00000505  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 13s) Loss: 0.1355(0.1355) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0401  avg_val_loss: 1.0644  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0401  avg_val_loss: 1.0644  time: 36s\n","Epoch 4 - Score: 0.6995\n","INFO:__main__:Epoch 4 - Score: 0.6995\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 2.5162(1.0644) \n","f1 score : 0.3757828810020877\n","recall score : 0.29508196721311475\n","precision score : 0.5172413793103449\n","Epoch: [5][0/248] Elapsed 0m 0s (remain 1m 20s) Loss: 0.0037(0.0037) Grad: nan  LR: 0.00000503  \n","Epoch: [5][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.0046(0.0069) Grad: 0.1999  LR: 0.00000333  \n","Epoch: [5][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0067(0.0069) Grad: 0.2687  LR: 0.00000192  \n","Epoch: [5][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0047(0.0065) Grad: 0.2253  LR: 0.00000138  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.2657(0.2657) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0065  avg_val_loss: 1.1371  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0065  avg_val_loss: 1.1371  time: 36s\n","Epoch 5 - Score: 0.6844\n","INFO:__main__:Epoch 5 - Score: 0.6844\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 2.3438(1.1371) \n","f1 score : 0.41417910447761197\n","recall score : 0.3639344262295082\n","precision score : 0.4805194805194805\n","Epoch: [6][0/248] Elapsed 0m 0s (remain 1m 17s) Loss: 0.0043(0.0043) Grad: nan  LR: 0.00000136  \n","Epoch: [6][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0042(0.0041) Grad: 0.1866  LR: 0.00000050  \n","Epoch: [6][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0086(0.0042) Grad: 0.6710  LR: 0.00000006  \n","Epoch: [6][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0032(0.0041) Grad: 0.1164  LR: 0.00000000  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2730(0.2730) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0041  avg_val_loss: 1.1494  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0041  avg_val_loss: 1.1494  time: 36s\n","Epoch 6 - Score: 0.6834\n","INFO:__main__:Epoch 6 - Score: 0.6834\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 2.3574(1.1494) \n","f1 score : 0.4134078212290503\n","recall score : 0.3639344262295082\n","precision score : 0.47844827586206895\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.7075\n","INFO:__main__:Score: 0.7075\n","ACC BEST Score: 0.7106\n","INFO:__main__:ACC BEST Score: 0.7106\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.24806201550387597\n","recall score : 0.15737704918032788\n","precision score : 0.5853658536585366\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/248] Elapsed 0m 0s (remain 1m 26s) Loss: 0.9381(0.9381) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.5472(0.6456) Grad: 5.2954  LR: 0.00001977  \n","Epoch: [1][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.6459(0.6268) Grad: 3.1163  LR: 0.00001912  \n","Epoch: [1][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.4931(0.6237) Grad: 0.8296  LR: 0.00001867  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 12s) Loss: 0.1636(0.1636) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6237  avg_val_loss: 0.6660  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6237  avg_val_loss: 0.6660  time: 36s\n","Epoch 1 - Score: 0.6942\n","INFO:__main__:Epoch 1 - Score: 0.6942\n","Epoch 1 - Save Best Score: 0.6942 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6942 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.7054(0.6660) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [2][0/248] Elapsed 0m 0s (remain 1m 25s) Loss: 0.7546(0.7546) Grad: nan  LR: 0.00001866  \n","Epoch: [2][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.3957(0.5837) Grad: 8.1014  LR: 0.00001742  \n","Epoch: [2][200/248] Elapsed 0m 24s (remain 0m 5s) Loss: 0.5935(0.5796) Grad: 1.4834  LR: 0.00001585  \n","Epoch: [2][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.6189(0.5794) Grad: 1.8745  LR: 0.00001502  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.3348(0.3348) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5794  avg_val_loss: 0.5710  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5794  avg_val_loss: 0.5710  time: 36s\n","Epoch 2 - Score: 0.7022\n","INFO:__main__:Epoch 2 - Score: 0.7022\n","Epoch 2 - Save Best Score: 0.7022 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7022 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 0.8074(0.5710) \n","f1 score : 0.34801762114537443\n","recall score : 0.2598684210526316\n","precision score : 0.5266666666666666\n","Epoch: [3][0/248] Elapsed 0m 0s (remain 1m 26s) Loss: 0.4624(0.4624) Grad: nan  LR: 0.00001501  \n","Epoch: [3][100/248] Elapsed 0m 12s (remain 0m 18s) Loss: 0.2892(0.5394) Grad: 4.6753  LR: 0.00001309  \n","Epoch: [3][200/248] Elapsed 0m 24s (remain 0m 5s) Loss: 0.6725(0.5295) Grad: 7.9773  LR: 0.00001103  \n","Epoch: [3][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.4945(0.5247) Grad: 2.3085  LR: 0.00001004  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.2609(0.2609) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5247  avg_val_loss: 0.5705  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.5247  avg_val_loss: 0.5705  time: 36s\n","Epoch 3 - Score: 0.7052\n","INFO:__main__:Epoch 3 - Score: 0.7052\n","Epoch 3 - Save Best Score: 0.7052 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7052 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.1658(0.5705) \n","f1 score : 0.16524216524216523\n","recall score : 0.09539473684210527\n","precision score : 0.6170212765957447\n","Epoch: [4][0/248] Elapsed 0m 0s (remain 1m 20s) Loss: 0.4744(0.4744) Grad: nan  LR: 0.00001002  \n","Epoch: [4][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.4467(0.3670) Grad: 7.2963  LR: 0.00000793  \n","Epoch: [4][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.3658(0.3464) Grad: 6.8206  LR: 0.00000593  \n","Epoch: [4][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.2360(0.3402) Grad: 5.9277  LR: 0.00000505  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.3711(0.3711) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3402  avg_val_loss: 0.6540  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3402  avg_val_loss: 0.6540  time: 36s\n","Epoch 4 - Score: 0.6720\n","INFO:__main__:Epoch 4 - Score: 0.6720\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.0145(0.6540) \n","f1 score : 0.4673202614379085\n","recall score : 0.47039473684210525\n","precision score : 0.4642857142857143\n","Epoch: [5][0/248] Elapsed 0m 0s (remain 1m 20s) Loss: 0.1916(0.1916) Grad: nan  LR: 0.00000503  \n","Epoch: [5][100/248] Elapsed 0m 12s (remain 0m 17s) Loss: 0.0674(0.1214) Grad: 7.0610  LR: 0.00000333  \n","Epoch: [5][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0469(0.1082) Grad: 4.3727  LR: 0.00000192  \n","Epoch: [5][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0981(0.1009) Grad: 7.6404  LR: 0.00000138  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.3188(0.3188) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1009  avg_val_loss: 0.8635  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1009  avg_val_loss: 0.8635  time: 36s\n","Epoch 5 - Score: 0.6891\n","INFO:__main__:Epoch 5 - Score: 0.6891\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.8169(0.8635) \n","f1 score : 0.4452423698384201\n","recall score : 0.40789473684210525\n","precision score : 0.4901185770750988\n","Epoch: [6][0/248] Elapsed 0m 0s (remain 1m 19s) Loss: 0.0207(0.0207) Grad: nan  LR: 0.00000136  \n","Epoch: [6][100/248] Elapsed 0m 11s (remain 0m 17s) Loss: 0.0240(0.0354) Grad: 2.8209  LR: 0.00000050  \n","Epoch: [6][200/248] Elapsed 0m 23s (remain 0m 5s) Loss: 0.0138(0.0352) Grad: 0.4245  LR: 0.00000006  \n","Epoch: [6][247/248] Elapsed 0m 29s (remain 0m 0s) Loss: 0.0282(0.0343) Grad: 2.1296  LR: 0.00000000  \n","EVAL: [0/32] Elapsed 0m 0s (remain 0m 11s) Loss: 0.3410(0.3410) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0343  avg_val_loss: 0.8976  time: 36s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0343  avg_val_loss: 0.8976  time: 36s\n","Epoch 6 - Score: 0.6891\n","INFO:__main__:Epoch 6 - Score: 0.6891\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [31/32] Elapsed 0m 6s (remain 0m 0s) Loss: 1.8827(0.8976) \n","f1 score : 0.45502645502645506\n","recall score : 0.4243421052631579\n","precision score : 0.49049429657794674\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n","Score: 0.7052\n","INFO:__main__:Score: 0.7052\n","ACC BEST Score: 0.7082\n","INFO:__main__:ACC BEST Score: 0.7082\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.7027\n","INFO:__main__:Score: 0.7027\n","ACC BEST Score: 0.7035\n","INFO:__main__:ACC BEST Score: 0.7035\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.16524216524216523\n","recall score : 0.09539473684210527\n","precision score : 0.6170212765957447\n","f1 score : 0.18060941828254848\n","recall score : 0.10702560735390676\n","precision score : 0.5780141843971631\n"]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"xLy2EqucW--T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WB0KGIO6CdB_"},"execution_count":null,"outputs":[]}]}