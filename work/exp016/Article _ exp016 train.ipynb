{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2921,"status":"ok","timestamp":1680530860377,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"sMVmfQcW79nK","outputId":"0a07c773-5529-46b5-9158-0641cabbbbe2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12988,"status":"ok","timestamp":1680530873363,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"PMsVsVYs8Jib","outputId":"0d2038c6-7a39-4a05-975e-e0b7bce767fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.97)\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680530873363,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"qonwoL_F8Oe_","outputId":"57642f07-85fc-4d97-ff92-ce3f4437d3d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Apr  3 14:07:52 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    48W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5166,"status":"ok","timestamp":1680530878527,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"y2tBjTH68Qnb"},"outputs":[],"source":["\n","import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1680530878528,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"VCF2-czO8Svr"},"outputs":[],"source":["\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    # model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = True\n","    freezing = True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680530878528,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"JyQ97ca88dRA"},"outputs":[],"source":["DIR = \"/content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","OUTPUT_EXP_DIR = DIR + '/output/EXP016/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680530878528,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"7QkA50jQ80_3"},"outputs":[],"source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return accuracy_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_acc_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = accuracy_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    return accuracy_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680530878529,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"wRnSUEJR9A9y"},"outputs":[],"source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680530878529,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"GUnukiIG9FM5","outputId":"f9c1c1df-b94b-4fd5-b7fd-39baa66deb26"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4974, 6)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                             title  year  \\\n","0   1      Hierarchical Adversarially Learned Inference  2018   \n","1   2    Learning to Compute Word Embeddings On the Fly  2018   \n","2   3  Graph2Seq: Scalable Learning Dynamics for Graphs  2018   \n","\n","                                            abstract  \\\n","0  We propose a novel hierarchical generative mod...   \n","1  Words in natural language follow a Zipfian dis...   \n","2  Neural networks are increasingly used as a gen...   \n","\n","                                            keywords  y  \n","0  generative, hierarchical, unsupervised, semisu...  0  \n","1      NLU, word embeddings, representation learning  0  \n","2                                                NaN  0  "],"text/html":["\n","  <div id=\"df-5f8c4569-f9c4-4141-9422-5de8fe2ca074\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Hierarchical Adversarially Learned Inference</td>\n","      <td>2018</td>\n","      <td>We propose a novel hierarchical generative mod...</td>\n","      <td>generative, hierarchical, unsupervised, semisu...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Learning to Compute Word Embeddings On the Fly</td>\n","      <td>2018</td>\n","      <td>Words in natural language follow a Zipfian dis...</td>\n","      <td>NLU, word embeddings, representation learning</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Graph2Seq: Scalable Learning Dynamics for Graphs</td>\n","      <td>2018</td>\n","      <td>Neural networks are increasingly used as a gen...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f8c4569-f9c4-4141-9422-5de8fe2ca074')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5f8c4569-f9c4-4141-9422-5de8fe2ca074 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5f8c4569-f9c4-4141-9422-5de8fe2ca074');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                              title  year  \\\n","0   1  StyleAlign: Analysis and Applications of Align...  2022   \n","1   2  Embedding a random graph via GNN: mean-field i...  2021   \n","2   3  BBRefinement: an universal scheme to improve p...  2021   \n","\n","                                            abstract  \\\n","0  In this paper, we perform an in-depth study of...   \n","1  We develop a theory for embedding a random gra...   \n","2  We present a conceptually simple yet powerful ...   \n","\n","                                            keywords  \n","0  StyleGAN, transfer learning, fine tuning, mode...  \n","1  Graph neural network, graph embedding, multi-r...  \n","2  object detection, deep neural networks, refine...  "],"text/html":["\n","  <div id=\"df-3e51621d-f901-459a-b4a7-958f1d476c6a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>StyleAlign: Analysis and Applications of Align...</td>\n","      <td>2022</td>\n","      <td>In this paper, we perform an in-depth study of...</td>\n","      <td>StyleGAN, transfer learning, fine tuning, mode...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Embedding a random graph via GNN: mean-field i...</td>\n","      <td>2021</td>\n","      <td>We develop a theory for embedding a random gra...</td>\n","      <td>Graph neural network, graph embedding, multi-r...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>BBRefinement: an universal scheme to improve p...</td>\n","      <td>2021</td>\n","      <td>We present a conceptually simple yet powerful ...</td>\n","      <td>object detection, deep neural networks, refine...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e51621d-f901-459a-b4a7-958f1d476c6a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3e51621d-f901-459a-b4a7-958f1d476c6a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3e51621d-f901-459a-b4a7-958f1d476c6a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["   id  y\n","0   1  0\n","1   2  0\n","2   3  0"],"text/html":["\n","  <div id=\"df-4b90e3c9-848e-42b7-b567-e85fa62e7ddf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b90e3c9-848e-42b7-b567-e85fa62e7ddf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b90e3c9-848e-42b7-b567-e85fa62e7ddf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b90e3c9-848e-42b7-b567-e85fa62e7ddf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train_data.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test_data.csv\"))\n","sample_sub = pd.read_csv(os.path.join(INPUT_DIR,\"submission.csv\"))\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(sample_sub.shape)\n","display(sample_sub.head(3))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680530878529,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"S2LAKUbZ9L92"},"outputs":[],"source":["train[\"texts\"] = train[\"title\"].str.lower() + \"[SEP]\" + train[\"abstract\"].str.lower()  "]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680530878530,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"9MRHQQ6K9Zot"},"outputs":[],"source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.y)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2320,"status":"ok","timestamp":1680530880841,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"kTf6lgW19iep","outputId":"f98a345a-c5d6-480b-f581-7da33a14783a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3364,"status":"ok","timestamp":1680530884199,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"wt2P1uC_9oRd","outputId":"56f51868-f7ce-46c0-f30b-4b6461977215"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4974/4974 [00:03<00:00, 1389.17it/s]\n","max_len: 536\n","INFO:__main__:max_len: 536\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 3 # cls\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1680530884200,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"rmsbpfsc92bq"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df['y'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.half)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","class ValidDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df['y'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680530884200,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"DbE2YLRd9-uk"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self.sig = nn.Sigmoid()\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        feature = self.layer_norm1(feature)\n","        output = self.fc(feature)\n","        #output = self.sig(output)\n","        return output"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680530884200,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"Evhi1yCQ-Xjb"},"outputs":[],"source":["\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        #print(y_preds.sigmoid().squeeze().view(1, -1))\n","        loss = criterion(y_preds.sigmoid().squeeze(), labels.squeeze())\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.sigmoid().squeeze(), labels.squeeze())\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680530884201,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"pR91ZhBL_pW4"},"outputs":[],"source":["\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['y'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = ValidDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCELoss()\n","    \n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZY5kSe1_1Fl","executionInfo":{"status":"ok","timestamp":1680535492242,"user_tz":-540,"elapsed":4608056,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c08d017f-4e46-414a-f299-2357d1074302"},"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 2s (remain 9m 34s) Loss: 0.6909(0.6909) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 38s (remain 1m 7s) Loss: 0.6479(0.6375) Grad: 4.0682  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 14s (remain 0m 28s) Loss: 0.4978(0.6333) Grad: 2.5521  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 43s (remain 0m 0s) Loss: 0.7134(0.6275) Grad: 4.9415  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.2751(0.2751) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6275  avg_val_loss: 0.6253  time: 113s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6275  avg_val_loss: 0.6253  time: 113s\n","Epoch 1 - Score: 0.6948\n","INFO:__main__:Epoch 1 - Score: 0.6948\n","Epoch 1 - Save Best Score: 0.6948 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6948 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.4223(0.6253) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 52s) Loss: 0.7041(0.7041) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 37s (remain 1m 6s) Loss: 0.4448(0.6147) Grad: 5.1957  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 14s (remain 0m 28s) Loss: 0.5654(0.6103) Grad: 1.2453  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.6899(0.6182) Grad: 2.0086  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4706(0.4706) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6182  avg_val_loss: 0.6250  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.6182  avg_val_loss: 0.6250  time: 112s\n","Epoch 2 - Score: 0.6948\n","INFO:__main__:Epoch 2 - Score: 0.6948\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.9748(0.6250) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 59s) Loss: 0.5381(0.5381) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.5972(0.6121) Grad: 3.7888  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.6392(0.6028) Grad: 5.4380  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 40s (remain 0m 0s) Loss: 0.5337(0.6006) Grad: 6.6965  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.1925(0.1925) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.6006  avg_val_loss: 0.6336  time: 111s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.6006  avg_val_loss: 0.6336  time: 111s\n","Epoch 3 - Score: 0.6948\n","INFO:__main__:Epoch 3 - Score: 0.6948\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.4981(0.6336) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 25s) Loss: 0.4075(0.4075) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 36s (remain 1m 3s) Loss: 0.5225(0.5706) Grad: 3.5685  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.5010(0.5465) Grad: 6.5095  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.6533(0.5542) Grad: 3.9976  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.3359(0.3359) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.5542  avg_val_loss: 0.5906  time: 111s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.5542  avg_val_loss: 0.5906  time: 111s\n","Epoch 4 - Score: 0.6807\n","INFO:__main__:Epoch 4 - Score: 0.6807\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.9817(0.5906) \n","f1 score : 0.3614457831325301\n","recall score : 0.29605263157894735\n","precision score : 0.4639175257731959\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.6948\n","INFO:__main__:Score: 0.6948\n","ACC BEST Score: 0.6948\n","INFO:__main__:ACC BEST Score: 0.6948\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 4m 33s) Loss: 0.7773(0.7773) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 36s (remain 1m 3s) Loss: 0.5566(0.6372) Grad: 1.4301  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 11s (remain 0m 27s) Loss: 0.4746(0.6214) Grad: 3.2017  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 40s (remain 0m 0s) Loss: 0.8223(0.6171) Grad: 11.4466  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2819(0.2819) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6171  avg_val_loss: 0.5886  time: 111s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6171  avg_val_loss: 0.5886  time: 111s\n","Epoch 1 - Score: 0.6928\n","INFO:__main__:Epoch 1 - Score: 0.6928\n","Epoch 1 - Save Best Score: 0.6928 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6928 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.2740(0.5886) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 58s) Loss: 0.5439(0.5439) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.3525(0.4954) Grad: 4.0780  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.4160(0.4955) Grad: 6.4832  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.4832(0.4909) Grad: 4.2352  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.5080(0.5080) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4909  avg_val_loss: 0.6103  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4909  avg_val_loss: 0.6103  time: 112s\n","Epoch 2 - Score: 0.6667\n","INFO:__main__:Epoch 2 - Score: 0.6667\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.8797(0.6103) \n","f1 score : 0.5257142857142857\n","recall score : 0.6013071895424836\n","precision score : 0.467005076142132\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 42s) Loss: 0.2042(0.2042) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 36s (remain 1m 5s) Loss: 0.0313(0.1415) Grad: 2.0848  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0082(0.1114) Grad: 0.3532  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0732(0.0982) Grad: 10.7179  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.6924(0.6924) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0982  avg_val_loss: 0.9031  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0982  avg_val_loss: 0.9031  time: 112s\n","Epoch 3 - Score: 0.6747\n","INFO:__main__:Epoch 3 - Score: 0.6747\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 2.5001(0.9031) \n","f1 score : 0.45637583892617445\n","recall score : 0.4444444444444444\n","precision score : 0.4689655172413793\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 3m 41s) Loss: 0.0059(0.0059) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 36s (remain 1m 5s) Loss: 0.0028(0.0166) Grad: 0.0972  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0042(0.0117) Grad: 0.3198  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0038(0.0110) Grad: 0.2094  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.5414(0.5414) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0110  avg_val_loss: 0.9587  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0110  avg_val_loss: 0.9587  time: 112s\n","Epoch 4 - Score: 0.7028\n","INFO:__main__:Epoch 4 - Score: 0.7028\n","Epoch 4 - Save Best Score: 0.7028 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7028 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 3.1421(0.9587) \n","f1 score : 0.4558823529411765\n","recall score : 0.40522875816993464\n","precision score : 0.5210084033613446\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.7028\n","INFO:__main__:Score: 0.7028\n","ACC BEST Score: 0.7349\n","INFO:__main__:ACC BEST Score: 0.7349\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4558823529411765\n","recall score : 0.40522875816993464\n","precision score : 0.5210084033613446\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 55s) Loss: 0.9893(0.9893) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.3767(0.6128) Grad: 5.3982  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.6367(0.6179) Grad: 1.9986  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.7031(0.6107) Grad: 1.9548  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.3064(0.3064) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6107  avg_val_loss: 0.5569  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6107  avg_val_loss: 0.5569  time: 112s\n","Epoch 1 - Score: 0.7048\n","INFO:__main__:Epoch 1 - Score: 0.7048\n","Epoch 1 - Save Best Score: 0.7048 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7048 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.1122(0.5569) \n","f1 score : 0.07547169811320754\n","recall score : 0.0392156862745098\n","precision score : 1.0\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 3m 0s) Loss: 0.4155(0.4155) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 36s (remain 1m 5s) Loss: 0.4138(0.4745) Grad: 3.8345  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.4087(0.4685) Grad: 7.8568  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.3992(0.4454) Grad: 7.4687  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2891(0.2891) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4454  avg_val_loss: 0.6200  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4454  avg_val_loss: 0.6200  time: 112s\n","Epoch 2 - Score: 0.6867\n","INFO:__main__:Epoch 2 - Score: 0.6867\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.3264(0.6200) \n","f1 score : 0.3709677419354839\n","recall score : 0.3006535947712418\n","precision score : 0.4842105263157895\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 37s) Loss: 0.0817(0.0817) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.0420(0.0725) Grad: 4.9382  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.0416(0.0591) Grad: 5.3206  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0207(0.0566) Grad: 5.1337  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.9006(0.9006) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0566  avg_val_loss: 1.0020  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0566  avg_val_loss: 1.0020  time: 112s\n","Epoch 3 - Score: 0.6406\n","INFO:__main__:Epoch 3 - Score: 0.6406\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.3080(1.0020) \n","f1 score : 0.5149051490514904\n","recall score : 0.6209150326797386\n","precision score : 0.4398148148148148\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 49s) Loss: 0.0125(0.0125) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 36s (remain 1m 5s) Loss: 0.0027(0.0091) Grad: 0.1424  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 11s (remain 0m 27s) Loss: 0.0025(0.0072) Grad: 0.2567  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 40s (remain 0m 0s) Loss: 0.0016(0.0071) Grad: 0.1067  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4182(0.4182) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0071  avg_val_loss: 0.9759  time: 111s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0071  avg_val_loss: 0.9759  time: 111s\n","Epoch 4 - Score: 0.6807\n","INFO:__main__:Epoch 4 - Score: 0.6807\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 2.2863(0.9759) \n","f1 score : 0.4\n","recall score : 0.3464052287581699\n","precision score : 0.4732142857142857\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.7048\n","INFO:__main__:Score: 0.7048\n","ACC BEST Score: 0.7269\n","INFO:__main__:ACC BEST Score: 0.7269\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.07547169811320754\n","recall score : 0.0392156862745098\n","precision score : 1.0\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 48s) Loss: 0.5278(0.5278) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 37s (remain 1m 6s) Loss: 0.6055(0.6188) Grad: 2.3614  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.6455(0.6115) Grad: 2.2809  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.4966(0.5995) Grad: 2.3155  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.3449(0.3449) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5995  avg_val_loss: 0.5822  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5995  avg_val_loss: 0.5822  time: 112s\n","Epoch 1 - Score: 0.6968\n","INFO:__main__:Epoch 1 - Score: 0.6968\n","Epoch 1 - Save Best Score: 0.6968 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6968 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.0449(0.5822) \n","f1 score : 0.05031446540880503\n","recall score : 0.026143790849673203\n","precision score : 0.6666666666666666\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 48s) Loss: 0.6997(0.6997) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 36s (remain 1m 3s) Loss: 0.4822(0.4557) Grad: 7.3224  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.6548(0.4346) Grad: 9.2723  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.5337(0.4242) Grad: 8.6310  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2148(0.2148) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4242  avg_val_loss: 0.6838  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4242  avg_val_loss: 0.6838  time: 112s\n","Epoch 2 - Score: 0.6908\n","INFO:__main__:Epoch 2 - Score: 0.6908\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.5622(0.6838) \n","f1 score : 0.25242718446601947\n","recall score : 0.16993464052287582\n","precision score : 0.49056603773584906\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 3m 12s) Loss: 0.1440(0.1440) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.0059(0.0674) Grad: 0.2651  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0148(0.0631) Grad: 2.3957  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0239(0.0564) Grad: 2.7964  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2250(0.2250) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0564  avg_val_loss: 1.2526  time: 111s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0564  avg_val_loss: 1.2526  time: 111s\n","Epoch 3 - Score: 0.6988\n","INFO:__main__:Epoch 3 - Score: 0.6988\n","Epoch 3 - Save Best Score: 0.6988 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.6988 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 3.7282(1.2526) \n","f1 score : 0.21875\n","recall score : 0.13725490196078433\n","precision score : 0.5384615384615384\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 54s) Loss: 0.1509(0.1509) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 37s (remain 1m 6s) Loss: 0.0096(0.0195) Grad: 1.6679  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0021(0.0192) Grad: 0.1073  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0021(0.0153) Grad: 0.0917  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.7257(0.7257) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0153  avg_val_loss: 1.1353  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0153  avg_val_loss: 1.1353  time: 112s\n","Epoch 4 - Score: 0.6727\n","INFO:__main__:Epoch 4 - Score: 0.6727\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.9032(1.1353) \n","f1 score : 0.40727272727272723\n","recall score : 0.3660130718954248\n","precision score : 0.45901639344262296\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.6988\n","INFO:__main__:Score: 0.6988\n","ACC BEST Score: 0.7088\n","INFO:__main__:ACC BEST Score: 0.7088\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.21875\n","recall score : 0.13725490196078433\n","precision score : 0.5384615384615384\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 3m 31s) Loss: 0.6128(0.6128) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.4468(0.5900) Grad: 1.4276  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.5420(0.6002) Grad: 2.5261  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.6802(0.6028) Grad: 3.6673  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4253(0.4253) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6028  avg_val_loss: 0.5752  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6028  avg_val_loss: 0.5752  time: 112s\n","Epoch 1 - Score: 0.7404\n","INFO:__main__:Epoch 1 - Score: 0.7404\n","Epoch 1 - Save Best Score: 0.7404 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7404 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.8722(0.5752) \n","f1 score : 0.39999999999999997\n","recall score : 0.28289473684210525\n","precision score : 0.6825396825396826\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 46s) Loss: 0.4570(0.4570) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 36s (remain 1m 5s) Loss: 0.4741(0.4821) Grad: 5.5444  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.3770(0.4660) Grad: 6.4081  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.4534(0.4591) Grad: 7.0612  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2557(0.2557) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4591  avg_val_loss: 0.6120  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4591  avg_val_loss: 0.6120  time: 112s\n","Epoch 2 - Score: 0.7042\n","INFO:__main__:Epoch 2 - Score: 0.7042\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.2051(0.6120) \n","f1 score : 0.40485829959514175\n","recall score : 0.32894736842105265\n","precision score : 0.5263157894736842\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 42s) Loss: 0.0843(0.0843) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 37s (remain 1m 6s) Loss: 0.0603(0.0697) Grad: 9.1201  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0336(0.0659) Grad: 5.2624  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0102(0.0607) Grad: 1.3981  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4569(0.4569) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0607  avg_val_loss: 1.0011  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0607  avg_val_loss: 1.0011  time: 112s\n","Epoch 3 - Score: 0.6680\n","INFO:__main__:Epoch 3 - Score: 0.6680\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.6145(1.0011) \n","f1 score : 0.4290657439446367\n","recall score : 0.40789473684210525\n","precision score : 0.45255474452554745\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 3m 25s) Loss: 0.0038(0.0038) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.0020(0.0157) Grad: 0.1551  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 12s (remain 0m 27s) Loss: 0.0023(0.0126) Grad: 0.1140  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0054(0.0112) Grad: 0.3792  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4577(0.4577) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0112  avg_val_loss: 1.0448  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0112  avg_val_loss: 1.0448  time: 112s\n","Epoch 4 - Score: 0.6841\n","INFO:__main__:Epoch 4 - Score: 0.6841\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.7525(1.0448) \n","f1 score : 0.4332129963898917\n","recall score : 0.39473684210526316\n","precision score : 0.48\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n","Score: 0.7404\n","INFO:__main__:Score: 0.7404\n","ACC BEST Score: 0.7404\n","INFO:__main__:ACC BEST Score: 0.7404\n","========== fold: 5 training ==========\n","INFO:__main__:========== fold: 5 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.39999999999999997\n","recall score : 0.28289473684210525\n","precision score : 0.6825396825396826\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 56s) Loss: 0.6880(0.6880) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.7007(0.6024) Grad: 7.4489  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 14s (remain 0m 28s) Loss: 0.6597(0.6003) Grad: 1.4510  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.5308(0.5995) Grad: 1.6394  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4878(0.4878) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5995  avg_val_loss: 0.6000  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5995  avg_val_loss: 0.6000  time: 112s\n","Epoch 1 - Score: 0.6539\n","INFO:__main__:Epoch 1 - Score: 0.6539\n","Epoch 1 - Save Best Score: 0.6539 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6539 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 0.8051(0.6000) \n","f1 score : 0.2950819672131147\n","recall score : 0.23684210526315788\n","precision score : 0.391304347826087\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 3m 20s) Loss: 0.5679(0.5679) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.2177(0.4652) Grad: 5.3416  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.5737(0.4560) Grad: 5.9210  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.4792(0.4493) Grad: 10.8769  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2333(0.2333) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4493  avg_val_loss: 0.6681  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4493  avg_val_loss: 0.6681  time: 112s\n","Epoch 2 - Score: 0.6821\n","INFO:__main__:Epoch 2 - Score: 0.6821\n","Epoch 2 - Save Best Score: 0.6821 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.6821 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.3449(0.6681) \n","f1 score : 0.22549019607843138\n","recall score : 0.1513157894736842\n","precision score : 0.4423076923076923\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 51s) Loss: 0.2023(0.2023) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 38s (remain 1m 6s) Loss: 0.0587(0.0818) Grad: 7.8259  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0148(0.0806) Grad: 1.3560  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 42s (remain 0m 0s) Loss: 0.0086(0.0712) Grad: 1.0477  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2853(0.2853) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0712  avg_val_loss: 1.1558  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0712  avg_val_loss: 1.1558  time: 112s\n","Epoch 3 - Score: 0.6680\n","INFO:__main__:Epoch 3 - Score: 0.6680\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 2.1288(1.1558) \n","f1 score : 0.28571428571428575\n","recall score : 0.21710526315789475\n","precision score : 0.4177215189873418\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 53s) Loss: 0.0203(0.0203) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.0036(0.0149) Grad: 0.3111  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0036(0.0171) Grad: 0.1894  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0027(0.0149) Grad: 0.1490  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4373(0.4373) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0149  avg_val_loss: 1.1913  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0149  avg_val_loss: 1.1913  time: 112s\n","Epoch 4 - Score: 0.6620\n","INFO:__main__:Epoch 4 - Score: 0.6620\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.8540(1.1913) \n","f1 score : 0.34375\n","recall score : 0.2894736842105263\n","precision score : 0.4230769230769231\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 5 result ==========\n","INFO:__main__:========== fold: 5 result ==========\n","Score: 0.6821\n","INFO:__main__:Score: 0.6821\n","ACC BEST Score: 0.7022\n","INFO:__main__:ACC BEST Score: 0.7022\n","========== fold: 6 training ==========\n","INFO:__main__:========== fold: 6 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.22549019607843138\n","recall score : 0.1513157894736842\n","precision score : 0.4423076923076923\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 59s) Loss: 0.8350(0.8350) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 36s (remain 1m 3s) Loss: 0.8784(0.6187) Grad: 14.2425  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 12s (remain 0m 27s) Loss: 0.6499(0.6058) Grad: 3.4097  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 40s (remain 0m 0s) Loss: 0.5596(0.6019) Grad: 2.8832  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.4954(0.4954) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6019  avg_val_loss: 0.5927  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6019  avg_val_loss: 0.5927  time: 112s\n","Epoch 1 - Score: 0.7082\n","INFO:__main__:Epoch 1 - Score: 0.7082\n","Epoch 1 - Save Best Score: 0.7082 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7082 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 0.7989(0.5927) \n","f1 score : 0.24083769633507854\n","recall score : 0.1513157894736842\n","precision score : 0.5897435897435898\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 57s) Loss: 0.6118(0.6118) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.4407(0.4803) Grad: 7.7376  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.2776(0.4822) Grad: 4.1587  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.3440(0.4674) Grad: 5.2637  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.3821(0.3821) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4674  avg_val_loss: 0.5981  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4674  avg_val_loss: 0.5981  time: 112s\n","Epoch 2 - Score: 0.7082\n","INFO:__main__:Epoch 2 - Score: 0.7082\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.1804(0.5981) \n","f1 score : 0.45692883895131087\n","recall score : 0.40131578947368424\n","precision score : 0.5304347826086957\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 3m 10s) Loss: 0.1266(0.1266) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.0351(0.0956) Grad: 3.0554  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0172(0.0953) Grad: 2.8451  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0704(0.0933) Grad: 9.4863  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.4347(0.4347) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0933  avg_val_loss: 0.8748  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0933  avg_val_loss: 0.8748  time: 112s\n","Epoch 3 - Score: 0.7042\n","INFO:__main__:Epoch 3 - Score: 0.7042\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 2.6180(0.8748) \n","f1 score : 0.4235294117647059\n","recall score : 0.35526315789473684\n","precision score : 0.5242718446601942\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 50s) Loss: 0.0084(0.0084) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 36s (remain 1m 4s) Loss: 0.0046(0.0171) Grad: 0.4409  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0659(0.0169) Grad: 7.9060  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0068(0.0165) Grad: 0.6866  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.5898(0.5898) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0165  avg_val_loss: 0.9361  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0165  avg_val_loss: 0.9361  time: 112s\n","Epoch 4 - Score: 0.6942\n","INFO:__main__:Epoch 4 - Score: 0.6942\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 2.5801(0.9361) \n","f1 score : 0.4242424242424242\n","recall score : 0.3684210526315789\n","precision score : 0.5\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 6 result ==========\n","INFO:__main__:========== fold: 6 result ==========\n","Score: 0.7082\n","INFO:__main__:Score: 0.7082\n","ACC BEST Score: 0.7082\n","INFO:__main__:ACC BEST Score: 0.7082\n","========== fold: 7 training ==========\n","INFO:__main__:========== fold: 7 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.24083769633507854\n","recall score : 0.1513157894736842\n","precision score : 0.5897435897435898\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 4m 14s) Loss: 0.8901(0.8901) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.5244(0.6451) Grad: 1.9965  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 14s (remain 0m 28s) Loss: 0.6045(0.6279) Grad: 1.2944  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.3057(0.6113) Grad: 1.8851  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.1671(0.1671) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6113  avg_val_loss: 0.6319  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6113  avg_val_loss: 0.6319  time: 112s\n","Epoch 1 - Score: 0.7143\n","INFO:__main__:Epoch 1 - Score: 0.7143\n","Epoch 1 - Save Best Score: 0.7143 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7143 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.5316(0.6319) \n","f1 score : 0.12345679012345677\n","recall score : 0.06578947368421052\n","precision score : 1.0\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 3m 20s) Loss: 0.7246(0.7246) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.6538(0.4687) Grad: 5.6003  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.4626(0.4630) Grad: 4.7503  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 42s (remain 0m 0s) Loss: 0.3223(0.4636) Grad: 3.3526  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.2542(0.2542) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4636  avg_val_loss: 0.6170  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4636  avg_val_loss: 0.6170  time: 112s\n","Epoch 2 - Score: 0.7223\n","INFO:__main__:Epoch 2 - Score: 0.7223\n","Epoch 2 - Save Best Score: 0.7223 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7223 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.2823(0.6170) \n","f1 score : 0.3490566037735849\n","recall score : 0.24342105263157895\n","precision score : 0.6166666666666667\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 3m 20s) Loss: 0.1792(0.1792) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.0606(0.1018) Grad: 5.5455  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0319(0.0740) Grad: 4.7253  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0684(0.0656) Grad: 8.6515  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.5532(0.5532) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0656  avg_val_loss: 0.9668  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0656  avg_val_loss: 0.9668  time: 112s\n","Epoch 3 - Score: 0.6700\n","INFO:__main__:Epoch 3 - Score: 0.6700\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.6878(0.9668) \n","f1 score : 0.43448275862068964\n","recall score : 0.4144736842105263\n","precision score : 0.45652173913043476\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 3m 9s) Loss: 0.0021(0.0021) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 37s (remain 1m 6s) Loss: 0.0021(0.0044) Grad: 0.1439  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0043(0.0082) Grad: 0.6168  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0035(0.0090) Grad: 0.2799  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.4904(0.4904) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0090  avg_val_loss: 1.0418  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0090  avg_val_loss: 1.0418  time: 112s\n","Epoch 4 - Score: 0.6841\n","INFO:__main__:Epoch 4 - Score: 0.6841\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 2.0014(1.0418) \n","f1 score : 0.4163568773234201\n","recall score : 0.3684210526315789\n","precision score : 0.47863247863247865\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 7 result ==========\n","INFO:__main__:========== fold: 7 result ==========\n","Score: 0.7223\n","INFO:__main__:Score: 0.7223\n","ACC BEST Score: 0.7264\n","INFO:__main__:ACC BEST Score: 0.7264\n","========== fold: 8 training ==========\n","INFO:__main__:========== fold: 8 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.3490566037735849\n","recall score : 0.24342105263157895\n","precision score : 0.6166666666666667\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 45s) Loss: 0.9121(0.9121) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.4290(0.6338) Grad: 2.9176  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.5327(0.6153) Grad: 7.5070  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.5806(0.6103) Grad: 3.4169  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.4022(0.4022) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6103  avg_val_loss: 0.5562  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6103  avg_val_loss: 0.5562  time: 112s\n","Epoch 1 - Score: 0.7062\n","INFO:__main__:Epoch 1 - Score: 0.7062\n","Epoch 1 - Save Best Score: 0.7062 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7062 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.0180(0.5562) \n","f1 score : 0.20652173913043478\n","recall score : 0.125\n","precision score : 0.59375\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 3m 14s) Loss: 0.5762(0.5762) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 37s (remain 1m 6s) Loss: 0.5737(0.4982) Grad: 13.2036  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.5127(0.4608) Grad: 6.6390  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 42s (remain 0m 0s) Loss: 0.4763(0.4449) Grad: 6.4549  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.1707(0.1707) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4449  avg_val_loss: 0.6493  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4449  avg_val_loss: 0.6493  time: 112s\n","Epoch 2 - Score: 0.7163\n","INFO:__main__:Epoch 2 - Score: 0.7163\n","Epoch 2 - Save Best Score: 0.7163 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7163 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.8215(0.6493) \n","f1 score : 0.24598930481283424\n","recall score : 0.1513157894736842\n","precision score : 0.6571428571428571\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 3m 22s) Loss: 0.0983(0.0983) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.0167(0.0591) Grad: 1.3630  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.0090(0.0493) Grad: 0.7205  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0026(0.0449) Grad: 0.1515  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.6583(0.6583) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0449  avg_val_loss: 0.9257  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0449  avg_val_loss: 0.9257  time: 112s\n","Epoch 3 - Score: 0.7002\n","INFO:__main__:Epoch 3 - Score: 0.7002\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 2.2348(0.9257) \n","f1 score : 0.4983164983164983\n","recall score : 0.4868421052631579\n","precision score : 0.5103448275862069\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 3m 6s) Loss: 0.0054(0.0054) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 36s (remain 1m 5s) Loss: 0.0024(0.0147) Grad: 0.1163  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.0057(0.0131) Grad: 0.9154  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 40s (remain 0m 0s) Loss: 0.0020(0.0110) Grad: 0.0991  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 14s) Loss: 0.4507(0.4507) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0110  avg_val_loss: 0.9656  time: 111s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0110  avg_val_loss: 0.9656  time: 111s\n","Epoch 4 - Score: 0.7203\n","INFO:__main__:Epoch 4 - Score: 0.7203\n","Epoch 4 - Save Best Score: 0.7203 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7203 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 2.9082(0.9656) \n","f1 score : 0.47940074906367036\n","recall score : 0.42105263157894735\n","precision score : 0.5565217391304348\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 8 result ==========\n","INFO:__main__:========== fold: 8 result ==========\n","Score: 0.7203\n","INFO:__main__:Score: 0.7203\n","ACC BEST Score: 0.7344\n","INFO:__main__:ACC BEST Score: 0.7344\n","========== fold: 9 training ==========\n","INFO:__main__:========== fold: 9 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.47940074906367036\n","recall score : 0.42105263157894735\n","precision score : 0.5565217391304348\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.27.4\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/279] Elapsed 0m 0s (remain 3m 22s) Loss: 0.7065(0.7065) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.6284(0.6025) Grad: 2.1033  LR: 0.00001960  \n","Epoch: [1][200/279] Elapsed 1m 14s (remain 0m 28s) Loss: 0.6973(0.6055) Grad: 6.7416  LR: 0.00001845  \n","Epoch: [1][278/279] Elapsed 1m 42s (remain 0m 0s) Loss: 0.5103(0.6013) Grad: 3.9450  LR: 0.00001709  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.2264(0.2264) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6013  avg_val_loss: 0.5922  time: 113s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6013  avg_val_loss: 0.5922  time: 113s\n","Epoch 1 - Score: 0.6982\n","INFO:__main__:Epoch 1 - Score: 0.6982\n","Epoch 1 - Save Best Score: 0.6982 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6982 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 1.3634(0.5922) \n","f1 score : 0.062499999999999986\n","recall score : 0.03289473684210526\n","precision score : 0.625\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 48s) Loss: 0.6362(0.6362) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/279] Elapsed 0m 36s (remain 1m 3s) Loss: 0.3130(0.4698) Grad: 5.2688  LR: 0.00001483  \n","Epoch: [2][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.2788(0.4488) Grad: 8.6827  LR: 0.00001221  \n","Epoch: [2][278/279] Elapsed 1m 40s (remain 0m 0s) Loss: 0.4094(0.4314) Grad: 6.8290  LR: 0.00001004  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 13s) Loss: 0.3285(0.3285) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4314  avg_val_loss: 0.6216  time: 111s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4314  avg_val_loss: 0.6216  time: 111s\n","Epoch 2 - Score: 0.6499\n","INFO:__main__:Epoch 2 - Score: 0.6499\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 10s (remain 0m 0s) Loss: 1.0944(0.6216) \n","f1 score : 0.3785714285714286\n","recall score : 0.34868421052631576\n","precision score : 0.4140625\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 3m 15s) Loss: 0.1620(0.1620) Grad: nan  LR: 0.00001001  \n","Epoch: [3][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.0055(0.0749) Grad: 0.1930  LR: 0.00000724  \n","Epoch: [3][200/279] Elapsed 1m 12s (remain 0m 28s) Loss: 0.0039(0.0572) Grad: 0.2030  LR: 0.00000469  \n","Epoch: [3][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0092(0.0581) Grad: 1.5273  LR: 0.00000297  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.1439(0.1439) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0581  avg_val_loss: 1.1658  time: 112s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0581  avg_val_loss: 1.1658  time: 112s\n","Epoch 3 - Score: 0.6740\n","INFO:__main__:Epoch 3 - Score: 0.6740\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 2.6064(1.1658) \n","f1 score : 0.3360655737704918\n","recall score : 0.26973684210526316\n","precision score : 0.44565217391304346\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 59s) Loss: 0.0026(0.0026) Grad: nan  LR: 0.00000295  \n","Epoch: [4][100/279] Elapsed 0m 37s (remain 1m 5s) Loss: 0.0017(0.0059) Grad: 0.0884  LR: 0.00000126  \n","Epoch: [4][200/279] Elapsed 1m 13s (remain 0m 28s) Loss: 0.1150(0.0098) Grad: 10.5590  LR: 0.00000026  \n","Epoch: [4][278/279] Elapsed 1m 41s (remain 0m 0s) Loss: 0.0050(0.0144) Grad: 0.5012  LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.2053(0.2053) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0144  avg_val_loss: 1.1710  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0144  avg_val_loss: 1.1710  time: 112s\n","Epoch 4 - Score: 0.6700\n","INFO:__main__:Epoch 4 - Score: 0.6700\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 9s (remain 0m 0s) Loss: 2.3447(1.1710) \n","f1 score : 0.36923076923076925\n","recall score : 0.3157894736842105\n","precision score : 0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 9 result ==========\n","INFO:__main__:========== fold: 9 result ==========\n","Score: 0.6982\n","INFO:__main__:Score: 0.6982\n","ACC BEST Score: 0.7103\n","INFO:__main__:ACC BEST Score: 0.7103\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.7073\n","INFO:__main__:Score: 0.7073\n","ACC BEST Score: 0.7077\n","INFO:__main__:ACC BEST Score: 0.7077\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.062499999999999986\n","recall score : 0.03289473684210526\n","precision score : 0.625\n","f1 score : 0.2806324110671937\n","recall score : 0.18647406434668418\n","precision score : 0.5668662674650699\n"]}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['y'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        acc_score = get_acc_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'ACC BEST Score: {acc_score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLy2EqucW--T"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBcToO10Ok_c"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNlmlN+OVaqAcWNmS5GoGr9"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}