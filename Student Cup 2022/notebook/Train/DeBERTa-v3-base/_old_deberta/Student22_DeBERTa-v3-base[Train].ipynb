{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Student22/DeBERTa-v3-base[Train].ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMVJbBAdMGoT7+z7iAvVUAA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BySnjPX7PXz5","executionInfo":{"status":"ok","timestamp":1659630996596,"user_tz":-540,"elapsed":3057,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"df9b0880-d05a-430d-e2f7-6f35e497bfee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75m2xhfBPqp4","executionInfo":{"status":"ok","timestamp":1659630998997,"user_tz":-540,"elapsed":2411,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"e113e43b-dbcf-4b99-e67e-d88001c6dd5b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eba8I100PsyG","executionInfo":{"status":"ok","timestamp":1659631002155,"user_tz":-540,"elapsed":3166,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"3021e5c7-8d6e-441c-875b-99096ed23832"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"o8r0GW8uPvH1","executionInfo":{"status":"ok","timestamp":1659631006066,"user_tz":-540,"elapsed":3919,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["INPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/input/'\n","OUTPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/output/'\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'Submission')\n","OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'Model/DeBERTa-base/')"],"metadata":{"id":"5ZzXtBUuP3Xo","executionInfo":{"status":"ok","timestamp":1659631006074,"user_tz":-540,"elapsed":72,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class CFG:\n","    wandb = False\n","    apex = True\n","    model = 'microsoft/deberta-v3-base'\n","    seed = 42\n","    n_splits = 5\n","    max_len = 512\n","    dropout = 0.2\n","    target_size=4\n","    n_accumulate=1\n","    print_freq = 50\n","    min_lr=1e-6\n","    scheduler = 'cosine'\n","    batch_size = 16\n","    num_workers = 2\n","    lr = 3e-5\n","    weigth_decay = 0.01\n","    epochs = 5\n","    n_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    train = True \n","    num_warmup_steps = 0\n","    num_cycles=0.5\n","    debug = False\n","    debug_ver2 = False\n","    gradient_checkpointing = True\n","    freezing = True"],"metadata":{"id":"eHaPjAWUP9nl","executionInfo":{"status":"ok","timestamp":1659631006076,"user_tz":-540,"elapsed":70,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Loss Func\n","def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)\n","\n","def softmax(z):\n","    assert len(z.shape) == 2\n","    s = np.max(z, axis=1)\n","    s = s[:, np.newaxis] # necessary step to do broadcasting\n","    e_x = np.exp(z - s)\n","    div = np.sum(e_x, axis=1)\n","    div = div[:, np.newaxis] # dito\n","    return e_x / div\n","\"\"\"\n","def get_score(y_true, y_pred):\n","    y_pred = softmax(y_pred)\n","    score = log_loss(y_true, y_pred)\n","    return round(score, 5)\n","\"\"\"\n","def get_score(outputs, labels):\n","    outputs = F.softmax(torch.tensor(outputs)).numpy()\n","    return f1_score(np.argmax(outputs,axis=1),labels ,average='macro')\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)\n","\n","def prepare_input(cfg, text, text_2=None):\n","    inputs = cfg.tokenizer(text, text_2,\n","                           padding=\"max_length\",\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           truncation=True)\n","\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","        \n","    return inputs"],"metadata":{"id":"HtdolflkQF-N","executionInfo":{"status":"ok","timestamp":1659631006078,"user_tz":-540,"elapsed":71,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"I-zmI7wcQIWQ","executionInfo":{"status":"ok","timestamp":1659631006079,"user_tz":-540,"elapsed":71,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n","submission_df = pd.read_csv(os.path.join(INPUT_DIR, 'submit_sample.csv'))\n","\n","display(train.head())\n","print(train.shape)\n","display(test.head())\n","print(test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"u0MWWeigQQ-m","executionInfo":{"status":"ok","timestamp":1659631006081,"user_tz":-540,"elapsed":72,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"f9863164-0c5f-4f91-8214-32150b009cc2"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["   id                                        description  jobflag\n","0   0  <li>Develop cutting-edge web applications that...        3\n","1   1  <li> Designs and develops high quality, scalab...        3\n","2   2  <li>Functions as a point person for Network St...        4\n","3   3  <li> Work on the technical design, development...        3\n","4   4  <li>Quantify the resources required for a task...        4"],"text/html":["\n","  <div id=\"df-18401497-4b66-4b13-a929-e6e587935889\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>jobflag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>&lt;li&gt;Develop cutting-edge web applications that...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>&lt;li&gt; Designs and develops high quality, scalab...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>&lt;li&gt;Functions as a point person for Network St...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>&lt;li&gt; Work on the technical design, development...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>&lt;li&gt;Quantify the resources required for a task...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18401497-4b66-4b13-a929-e6e587935889')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-18401497-4b66-4b13-a929-e6e587935889 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-18401497-4b66-4b13-a929-e6e587935889');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1516, 3)\n"]},{"output_type":"display_data","data":{"text/plain":["     id                                        description\n","0  1516  <li>Building decision-making models and propos...\n","1  1517  <li>Educate homeowners on the benefits of sola...\n","2  1518  <li><span>Design, develop, document, and imple...\n","3  1519  <li>Apply advanced technical expertise and ski...\n","4  1520  <li>Project manage and deliver against our roa..."],"text/html":["\n","  <div id=\"df-d4212521-b1b8-4e2f-8c47-922973661fde\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>&lt;li&gt;Building decision-making models and propos...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>&lt;li&gt;Educate homeowners on the benefits of sola...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>&lt;li&gt;&lt;span&gt;Design, develop, document, and imple...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>&lt;li&gt;Apply advanced technical expertise and ski...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>&lt;li&gt;Project manage and deliver against our roa...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4212521-b1b8-4e2f-8c47-922973661fde')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d4212521-b1b8-4e2f-8c47-922973661fde button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d4212521-b1b8-4e2f-8c47-922973661fde');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1517, 2)\n"]}]},{"cell_type":"code","source":["def remove_tag(x):\n","    p = re.compile(r\"<[^>]*?>\")\n","    return p.sub('',x)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_tag(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text\n","\n","train['description'] = cleaning(train['description'])\n","test['description'] = cleaning(test['description'])\n","train['inputs'] = train['description'].apply(lambda x : resolve_encodings_and_normalize(x))\n","test['inputs'] = test['description'].apply(lambda x : resolve_encodings_and_normalize(x))\n","train = train.rename(columns = {\"jobflag\": \"label\"})\n","train[\"label\"] = train[\"label\"].apply(lambda x : 0 if x == 4 else x)\n","train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"VzIaDXs2Qc02","executionInfo":{"status":"ok","timestamp":1659631006082,"user_tz":-540,"elapsed":36,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"7750a864-64f6-41b8-f2f8-96190f3a5d1f"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                        description  label  \\\n","0        0  Develop cutting-edge web applications that per...      3   \n","1        1   Designs and develops high quality, scalable a...      3   \n","2        2  Functions as a point person for Network Strate...      0   \n","3        3   Work on the technical design, development, re...      3   \n","4        4  Quantify the resources required for a task/pro...      0   \n","...    ...                                                ...    ...   \n","1511  1511  Support detailed reporting, statistical analys...      1   \n","1512  1512  Collaborate with teams to support the ML techn...      2   \n","1513  1513   Work with executives and other business leade...      1   \n","1514  1514  Leading design ideation sessions to ensure we ...      3   \n","1515  1515  Detection of Issues &amp; Impact Assessments e...      1   \n","\n","                                                 inputs  \n","0     Develop cutting-edge web applications that per...  \n","1      Designs and develops high quality, scalable a...  \n","2     Functions as a point person for Network Strate...  \n","3      Work on the technical design, development, re...  \n","4     Quantify the resources required for a task/pro...  \n","...                                                 ...  \n","1511  Support detailed reporting, statistical analys...  \n","1512  Collaborate with teams to support the ML techn...  \n","1513   Work with executives and other business leade...  \n","1514  Leading design ideation sessions to ensure we ...  \n","1515  Detection of Issues &amp; Impact Assessments e...  \n","\n","[1516 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-0be60d01-64db-4e69-9055-4f2b0ea1e301\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>label</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Develop cutting-edge web applications that per...</td>\n","      <td>3</td>\n","      <td>Develop cutting-edge web applications that per...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","      <td>3</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Functions as a point person for Network Strate...</td>\n","      <td>0</td>\n","      <td>Functions as a point person for Network Strate...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Work on the technical design, development, re...</td>\n","      <td>3</td>\n","      <td>Work on the technical design, development, re...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Quantify the resources required for a task/pro...</td>\n","      <td>0</td>\n","      <td>Quantify the resources required for a task/pro...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1511</th>\n","      <td>1511</td>\n","      <td>Support detailed reporting, statistical analys...</td>\n","      <td>1</td>\n","      <td>Support detailed reporting, statistical analys...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>1512</td>\n","      <td>Collaborate with teams to support the ML techn...</td>\n","      <td>2</td>\n","      <td>Collaborate with teams to support the ML techn...</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>1513</td>\n","      <td>Work with executives and other business leade...</td>\n","      <td>1</td>\n","      <td>Work with executives and other business leade...</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>1514</td>\n","      <td>Leading design ideation sessions to ensure we ...</td>\n","      <td>3</td>\n","      <td>Leading design ideation sessions to ensure we ...</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>1515</td>\n","      <td>Detection of Issues &amp;amp; Impact Assessments e...</td>\n","      <td>1</td>\n","      <td>Detection of Issues &amp;amp; Impact Assessments e...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1516 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0be60d01-64db-4e69-9055-4f2b0ea1e301')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0be60d01-64db-4e69-9055-4f2b0ea1e301 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0be60d01-64db-4e69-9055-4f2b0ea1e301');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_splits,shuffle=True,random_state=2022)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.label)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)"],"metadata":{"id":"-Oaxhj1tQqyH","executionInfo":{"status":"ok","timestamp":1659631006083,"user_tz":-540,"elapsed":33,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer\n","SEP = tokenizer.sep_token"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JozVPxKoRCCj","executionInfo":{"status":"ok","timestamp":1659631014857,"user_tz":-540,"elapsed":8806,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"ee9c7744-3b98-4707-8225-1383d0866cd2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["class Dataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG.tokenizer\n","        self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"0-62YNlsRGQ8","executionInfo":{"status":"ok","timestamp":1659631014859,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Dynamic Padding (Collate)\n","#collate_fn = DataCollatorWithPadding(tokenizer=CFG.tokenizer)\n","class Collate:\n","    def __init__(self, tokenizer, isTrain=True):\n","        self.tokenizer = tokenizer\n","        self.isTrain = isTrain\n","        # self.args = args\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","        if self.isTrain:\n","            output[\"target\"] = [sample[\"target\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","        if self.isTrain:\n","            output[\"target\"] = torch.tensor(output[\"target\"], dtype=torch.long)\n","\n","        return output\n","    \n","collate_fn = Collate(CFG.tokenizer, isTrain=True)"],"metadata":{"id":"_sh69Da6RQFz","executionInfo":{"status":"ok","timestamp":1659631014860,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9) #\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings"],"metadata":{"id":"H_GyjbDnRStd","executionInfo":{"status":"ok","timestamp":1659631014861,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        self.drop = nn.Dropout(p=CFG.dropout)\n","        self.pooler = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, CFG.target_size)\n","        \n","    def forward(self, ids, mask):        \n","        out = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        out = self.pooler(out.last_hidden_state, mask)\n","        out = self.drop(out)\n","        outputs = self.fc(out)\n","        return outputs"],"metadata":{"id":"Tm7w8yAcRVP3","executionInfo":{"status":"ok","timestamp":1659631015564,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def asMinutes(s):\n","    m = math.floor(s/60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler == 'linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler == 'cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    return scheduler\n","\n","def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","\n","        batch_size = ids.size(0)\n","        \n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","\n","        #accumulate\n","        loss = loss / CFG.n_accumulate \n","        loss.backward()\n","        if (step +1) % CFG.n_accumulate == 0:\n","            optimizer.step()\n","\n","            optimizer.zero_grad()\n","            if scheduler is not None:\n","                scheduler.step()\n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","        \n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  .format(epoch+1, step, len(dataloader), \n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","\n","    gc.collect()\n","\n","    return epoch_loss\n","\n","\n","@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","    pred = []\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","\n","        batch_size = ids.size(0)\n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","        pred.append(outputs.to('cpu').numpy())\n","\n","        running_loss += (loss.item()* batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","\n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  .format(step, len(dataloader),\n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","            \n","    pred = np.concatenate(pred)\n","            \n","    return epoch_loss, pred"],"metadata":{"id":"TEFbXjOCRguX","executionInfo":{"status":"ok","timestamp":1659631015565,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def train_loop(fold):\n","    #wandb.watch(model, log_freq=100)\n","\n","    LOGGER.info(f'-------------fold:{fold} training-------------')\n","\n","    train_data = train[train.kfold != fold].reset_index(drop=True)\n","    valid_data = train[train.kfold == fold].reset_index(drop=True)\n","    valid_labels = valid_data.label.values\n","\n","    trainDataset = Dataset(train_data, CFG.tokenizer, CFG.max_len)\n","    validDataset = Dataset(valid_data, CFG.tokenizer, CFG.max_len)\n","\n","    train_loader = DataLoader(trainDataset,\n","                              batch_size = CFG.batch_size,\n","                              shuffle=True,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=True)\n","    \n","    valid_loader = DataLoader(validDataset,\n","                              batch_size = CFG.batch_size*2,\n","                              shuffle=False,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=False)\n","    \n","    model = CustomModel(CFG.model)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weigth_decay)\n","    num_train_steps = int(len(train_data) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # loop\n","    best_score = 0\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device, epoch)\n","        valid_epoch_loss, pred = valid_one_epoch(model, valid_loader, device, epoch)\n","\n","        score = get_score(pred, valid_labels)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_epoch_loss:.4f}  avg_val_loss: {valid_epoch_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": train_epoch_loss, \n","                       f\"[fold{fold}] avg_val_loss\": valid_epoch_loss,\n","                       f\"[fold{fold}] score\": score})\n","            \n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': pred},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","            \n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_data['Consultant'] = predictions[:, 0]\n","    valid_data['Data scientist'] = predictions[:, 1]\n","    valid_data['Machine learning engineer'] = predictions[:, 2]\n","    valid_data['Software engineer'] = predictions[:, 3]\n","    \n","    \n","    temp = valid_data[['Consultant','Data scientist','Machine learning engineer','Software engineer']].values.tolist()\n","    print(get_score(temp, valid_data['label'].values))\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_data"],"metadata":{"id":"Iftyf0agiWRJ","executionInfo":{"status":"ok","timestamp":1659631015566,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['label'].values\n","        preds = oof_df[['Consultant','Data scientist','Machine learning engineer','Software engineer']].values.tolist()\n","        score = get_score(preds, labels)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","        oof_df.to_csv(OUTPUT_MODEL_DIR+f'oof_df.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DG0hD6XiZ2S","executionInfo":{"status":"ok","timestamp":1659633796102,"user_tz":-540,"elapsed":2780547,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"b501c2bf-d89c-40a5-c296-0b11954bb5c6"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["-------------fold:0 training-------------\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 2s (remain 3m 22s) \n","Epoch: [1][50/75] Elapsed 1m 6s (remain 0m 31s) \n","Epoch: [1][74/75] Elapsed 1m 38s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 1.0340  avg_val_loss: 0.8143  time: 106s\n","Epoch 1 - Score: 0.5431\n","Epoch 1 - Save Best Score: 0.5431 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 7s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 1s (remain 2m 1s) \n","Epoch: [2][50/75] Elapsed 1m 8s (remain 0m 32s) \n","Epoch: [2][74/75] Elapsed 1m 39s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6275  avg_val_loss: 0.6923  time: 107s\n","Epoch 2 - Score: 0.6341\n","Epoch 2 - Save Best Score: 0.6341 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 7s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 1s (remain 2m 7s) \n","Epoch: [3][50/75] Elapsed 1m 9s (remain 0m 32s) \n","Epoch: [3][74/75] Elapsed 1m 41s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4730  avg_val_loss: 0.6427  time: 109s\n","Epoch 3 - Score: 0.6584\n","Epoch 3 - Save Best Score: 0.6584 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 7s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 1s (remain 1m 49s) \n","Epoch: [4][50/75] Elapsed 1m 9s (remain 0m 32s) \n","Epoch: [4][74/75] Elapsed 1m 39s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3266  avg_val_loss: 0.6957  time: 107s\n","Epoch 4 - Score: 0.6870\n","Epoch 4 - Save Best Score: 0.6870 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 7s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 1s (remain 1m 56s) \n","Epoch: [5][50/75] Elapsed 1m 13s (remain 0m 34s) \n","Epoch: [5][74/75] Elapsed 1m 43s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2499  avg_val_loss: 0.6831  time: 111s\n","Epoch 5 - Score: 0.6836\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 7s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","Score: 0.6870\n","-------------fold:1 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.6870140706824196\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 2s (remain 3m 19s) \n","Epoch: [1][50/75] Elapsed 1m 10s (remain 0m 33s) \n","Epoch: [1][74/75] Elapsed 1m 39s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 9s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 1.0234  avg_val_loss: 0.7183  time: 107s\n","Epoch 1 - Score: 0.5396\n","Epoch 1 - Save Best Score: 0.5396 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 6s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 3s (remain 3m 47s) \n","Epoch: [2][50/75] Elapsed 1m 8s (remain 0m 32s) \n","Epoch: [2][74/75] Elapsed 1m 42s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 9s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6774  avg_val_loss: 0.6652  time: 110s\n","Epoch 2 - Score: 0.6722\n","Epoch 2 - Save Best Score: 0.6722 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 6s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 1s (remain 1m 24s) \n","Epoch: [3][50/75] Elapsed 1m 13s (remain 0m 34s) \n","Epoch: [3][74/75] Elapsed 1m 42s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 9s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4896  avg_val_loss: 0.6096  time: 110s\n","Epoch 3 - Score: 0.6757\n","Epoch 3 - Save Best Score: 0.6757 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 6s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 1s (remain 1m 15s) \n","Epoch: [4][50/75] Elapsed 1m 6s (remain 0m 31s) \n","Epoch: [4][74/75] Elapsed 1m 43s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 9s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3563  avg_val_loss: 0.5684  time: 111s\n","Epoch 4 - Score: 0.7439\n","Epoch 4 - Save Best Score: 0.7439 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 6s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 0s (remain 1m 11s) \n","Epoch: [5][50/75] Elapsed 1m 6s (remain 0m 31s) \n","Epoch: [5][74/75] Elapsed 1m 42s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 9s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2701  avg_val_loss: 0.5713  time: 110s\n","Epoch 5 - Score: 0.7574\n","Epoch 5 - Save Best Score: 0.7574 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 6s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","Score: 0.7574\n","-------------fold:2 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.757379083891724\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 0s (remain 1m 7s) \n","Epoch: [1][50/75] Elapsed 1m 1s (remain 0m 29s) \n","Epoch: [1][74/75] Elapsed 1m 34s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 1.0619  avg_val_loss: 0.7796  time: 103s\n","Epoch 1 - Score: 0.4981\n","Epoch 1 - Save Best Score: 0.4981 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 0s (remain 1m 7s) \n","Epoch: [2][50/75] Elapsed 1m 3s (remain 0m 29s) \n","Epoch: [2][74/75] Elapsed 1m 37s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6943  avg_val_loss: 0.5563  time: 107s\n","Epoch 2 - Score: 0.6590\n","Epoch 2 - Save Best Score: 0.6590 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 1s (remain 1m 35s) \n","Epoch: [3][50/75] Elapsed 1m 5s (remain 0m 30s) \n","Epoch: [3][74/75] Elapsed 1m 38s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5145  avg_val_loss: 0.5474  time: 107s\n","Epoch 3 - Score: 0.6798\n","Epoch 3 - Save Best Score: 0.6798 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 1s (remain 1m 16s) \n","Epoch: [4][50/75] Elapsed 1m 8s (remain 0m 32s) \n","Epoch: [4][74/75] Elapsed 1m 37s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3743  avg_val_loss: 0.5177  time: 106s\n","Epoch 4 - Score: 0.7564\n","Epoch 4 - Save Best Score: 0.7564 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 1s (remain 1m 43s) \n","Epoch: [5][50/75] Elapsed 1m 6s (remain 0m 31s) \n","Epoch: [5][74/75] Elapsed 1m 40s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.3035  avg_val_loss: 0.5229  time: 110s\n","Epoch 5 - Score: 0.7436\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","Score: 0.7564\n","-------------fold:3 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.7563562433161481\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 1s (remain 1m 32s) \n","Epoch: [1][50/75] Elapsed 1m 4s (remain 0m 30s) \n","Epoch: [1][74/75] Elapsed 1m 37s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 11s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 1.0437  avg_val_loss: 0.7196  time: 107s\n","Epoch 1 - Score: 0.5516\n","Epoch 1 - Save Best Score: 0.5516 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 9s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 1s (remain 1m 56s) \n","Epoch: [2][50/75] Elapsed 1m 5s (remain 0m 30s) \n","Epoch: [2][74/75] Elapsed 1m 37s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 11s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6517  avg_val_loss: 0.6945  time: 107s\n","Epoch 2 - Score: 0.5760\n","Epoch 2 - Save Best Score: 0.5760 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 9s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 1s (remain 1m 20s) \n","Epoch: [3][50/75] Elapsed 1m 4s (remain 0m 30s) \n","Epoch: [3][74/75] Elapsed 1m 36s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 11s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5024  avg_val_loss: 0.6459  time: 106s\n","Epoch 3 - Score: 0.6529\n","Epoch 3 - Save Best Score: 0.6529 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 9s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 0s (remain 1m 12s) \n","Epoch: [4][50/75] Elapsed 1m 5s (remain 0m 30s) \n","Epoch: [4][74/75] Elapsed 1m 37s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 11s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3357  avg_val_loss: 0.6669  time: 107s\n","Epoch 4 - Score: 0.6785\n","Epoch 4 - Save Best Score: 0.6785 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 9s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 1s (remain 1m 22s) \n","Epoch: [5][50/75] Elapsed 1m 7s (remain 0m 31s) \n","Epoch: [5][74/75] Elapsed 1m 40s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 1s (remain 0m 11s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2513  avg_val_loss: 0.6617  time: 110s\n","Epoch 5 - Score: 0.6684\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 9s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","Score: 0.6785\n","-------------fold:4 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.678541937410931\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 1s (remain 1m 22s) \n","Epoch: [1][50/75] Elapsed 1m 9s (remain 0m 32s) \n","Epoch: [1][74/75] Elapsed 1m 37s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 1.0890  avg_val_loss: 0.8284  time: 107s\n","Epoch 1 - Score: 0.4989\n","Epoch 1 - Save Best Score: 0.4989 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 1s (remain 1m 53s) \n","Epoch: [2][50/75] Elapsed 1m 7s (remain 0m 31s) \n","Epoch: [2][74/75] Elapsed 1m 39s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6909  avg_val_loss: 0.6554  time: 109s\n","Epoch 2 - Score: 0.5795\n","Epoch 2 - Save Best Score: 0.5795 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 0s (remain 1m 5s) \n","Epoch: [3][50/75] Elapsed 1m 3s (remain 0m 29s) \n","Epoch: [3][74/75] Elapsed 1m 34s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5062  avg_val_loss: 0.6021  time: 104s\n","Epoch 3 - Score: 0.6848\n","Epoch 3 - Save Best Score: 0.6848 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 1s (remain 1m 48s) \n","Epoch: [4][50/75] Elapsed 1m 10s (remain 0m 33s) \n","Epoch: [4][74/75] Elapsed 1m 39s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3566  avg_val_loss: 0.6406  time: 109s\n","Epoch 4 - Score: 0.6854\n","Epoch 4 - Save Best Score: 0.6854 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 0s (remain 1m 13s) \n","Epoch: [5][50/75] Elapsed 1m 7s (remain 0m 31s) \n","Epoch: [5][74/75] Elapsed 1m 40s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2719  avg_val_loss: 0.6414  time: 109s\n","Epoch 5 - Score: 0.6971\n","Epoch 5 - Save Best Score: 0.6971 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 8s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","Score: 0.6971\n","========== CV ==========\n","Score: 0.7159\n"]},{"output_type":"stream","name":"stdout","text":["0.6970886123622193\n"]}]},{"cell_type":"code","source":["A = pd.read_csv(OUTPUT_MODEL_DIR+'oof_df.csv')\n","A.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"p7aGlmzxq_Zy","executionInfo":{"status":"ok","timestamp":1659635626103,"user_tz":-540,"elapsed":432,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"55622f60-4acf-40f0-e351-f3efafd33c09"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                        description  label  \\\n","0   1   Designs and develops high quality, scalable a...      3   \n","1   5  Participates in standard business and technica...      3   \n","2   7  Facilitate pre-sales initiatives, such as live...      0   \n","3   9  Maintain and improve existing predictive model...      1   \n","4  13  Research, prototype, identify, and build predi...      2   \n","\n","                                              inputs  kfold  Consultant  \\\n","0   Designs and develops high quality, scalable a...      0   -0.237893   \n","1  Participates in standard business and technica...      0    1.741166   \n","2  Facilitate pre-sales initiatives, such as live...      0    5.083238   \n","3  Maintain and improve existing predictive model...      0   -0.501314   \n","4  Research, prototype, identify, and build predi...      0   -1.785935   \n","\n","   Data scientist  Machine learning engineer  Software engineer  \n","0       -1.248257                  -2.090317           2.456362  \n","1       -0.316498                  -2.358713           0.427342  \n","2       -0.571194                  -2.836229          -1.561467  \n","3        3.869465                  -1.112253          -2.527882  \n","4        2.116324                   2.617582          -1.317208  "],"text/html":["\n","  <div id=\"df-d1aeb025-0a5a-4267-8c30-672380700464\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>label</th>\n","      <th>inputs</th>\n","      <th>kfold</th>\n","      <th>Consultant</th>\n","      <th>Data scientist</th>\n","      <th>Machine learning engineer</th>\n","      <th>Software engineer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","      <td>3</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","      <td>0</td>\n","      <td>-0.237893</td>\n","      <td>-1.248257</td>\n","      <td>-2.090317</td>\n","      <td>2.456362</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>Participates in standard business and technica...</td>\n","      <td>3</td>\n","      <td>Participates in standard business and technica...</td>\n","      <td>0</td>\n","      <td>1.741166</td>\n","      <td>-0.316498</td>\n","      <td>-2.358713</td>\n","      <td>0.427342</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7</td>\n","      <td>Facilitate pre-sales initiatives, such as live...</td>\n","      <td>0</td>\n","      <td>Facilitate pre-sales initiatives, such as live...</td>\n","      <td>0</td>\n","      <td>5.083238</td>\n","      <td>-0.571194</td>\n","      <td>-2.836229</td>\n","      <td>-1.561467</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>Maintain and improve existing predictive model...</td>\n","      <td>1</td>\n","      <td>Maintain and improve existing predictive model...</td>\n","      <td>0</td>\n","      <td>-0.501314</td>\n","      <td>3.869465</td>\n","      <td>-1.112253</td>\n","      <td>-2.527882</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13</td>\n","      <td>Research, prototype, identify, and build predi...</td>\n","      <td>2</td>\n","      <td>Research, prototype, identify, and build predi...</td>\n","      <td>0</td>\n","      <td>-1.785935</td>\n","      <td>2.116324</td>\n","      <td>2.617582</td>\n","      <td>-1.317208</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1aeb025-0a5a-4267-8c30-672380700464')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d1aeb025-0a5a-4267-8c30-672380700464 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d1aeb025-0a5a-4267-8c30-672380700464');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[""],"metadata":{"id":"eCPvJIzF_W9x"},"execution_count":null,"outputs":[]}]}