{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# ライブラリ\n",
    "# ----------\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from psutil import virtual_memory\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "import scipy.stats as stats\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import fontstyle\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# DIR = \"/content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測\"\n",
    "DIR = '/workspace'\n",
    "INPUT_DIR = os.path.join(DIR,\"input\")\n",
    "OUTPUT_DIR = os.path.join(DIR,\"output\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# 設定\n",
    "# ----------\n",
    "num_fold = 5\n",
    "seed = 0\n",
    "\n",
    "DEVICE = \"cuda\" # \"cpu\" or \"cuda\"\n",
    "tokenizer = None\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 768\n",
    "\n",
    "# テキスト特徴として連結するカラム\n",
    "txt_columns = ['title', 'keywords', 'abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# 関数\n",
    "# ----------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "        ram_gb = virtual_memory().total / 1e9\n",
    "        print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "def get_stratifiedkfold(train, target_col, n_splits, seed):\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train.to_numpy(), train.get_column(target_col).to_numpy())\n",
    "    fold_array = np.zeros(len(train))\n",
    "    for fold, (_, idx_valid) in enumerate(generator):\n",
    "        fold_array[idx_valid] = fold\n",
    "    return fold_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用にtitle, abstract, keywordsの要素数を特徴として追加しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA RTX A4000\n",
      "Your runtime has 16.6 gigabytes of available RAM\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>title</th><th>year</th><th>abstract</th><th>keywords</th><th>y</th><th>txt_feat</th><th>num_title</th><th>num_abstract</th><th>num_keywords</th><th>group</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>u32</td><td>u32</td><td>u32</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Hierarchical A…</td><td>2018</td><td>&quot;We propose a n…</td><td>&quot;generative, hi…</td><td>0</td><td>&quot;Hierarchical A…</td><td>4</td><td>155</td><td>7</td><td>&quot;2018-0&quot;</td></tr><tr><td>2</td><td>&quot;Learning to Co…</td><td>2018</td><td>&quot;Words in natur…</td><td>&quot;NLU, word embe…</td><td>0</td><td>&quot;Learning to Co…</td><td>8</td><td>130</td><td>5</td><td>&quot;2018-0&quot;</td></tr><tr><td>3</td><td>&quot;Graph2Seq: Sca…</td><td>2018</td><td>&quot;Neural network…</td><td>&quot;&quot;</td><td>0</td><td>&quot;Graph2Seq: Sca…</td><td>6</td><td>143</td><td>0</td><td>&quot;2018-0&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 11)\n",
       "┌─────┬───────────────┬──────┬──────────────┬───┬───────────┬──────────────┬──────────────┬────────┐\n",
       "│ id  ┆ title         ┆ year ┆ abstract     ┆ … ┆ num_title ┆ num_abstract ┆ num_keywords ┆ group  │\n",
       "│ --- ┆ ---           ┆ ---  ┆ ---          ┆   ┆ ---       ┆ ---          ┆ ---          ┆ ---    │\n",
       "│ i64 ┆ str           ┆ i64  ┆ str          ┆   ┆ u32       ┆ u32          ┆ u32          ┆ str    │\n",
       "╞═════╪═══════════════╪══════╪══════════════╪═══╪═══════════╪══════════════╪══════════════╪════════╡\n",
       "│ 1   ┆ Hierarchical  ┆ 2018 ┆ We propose a ┆ … ┆ 4         ┆ 155          ┆ 7            ┆ 2018-0 │\n",
       "│     ┆ Adversarially ┆      ┆ novel        ┆   ┆           ┆              ┆              ┆        │\n",
       "│     ┆ Learn…        ┆      ┆ hierarchical ┆   ┆           ┆              ┆              ┆        │\n",
       "│     ┆               ┆      ┆ …            ┆   ┆           ┆              ┆              ┆        │\n",
       "│ 2   ┆ Learning to   ┆ 2018 ┆ Words in     ┆ … ┆ 8         ┆ 130          ┆ 5            ┆ 2018-0 │\n",
       "│     ┆ Compute Word  ┆      ┆ natural      ┆   ┆           ┆              ┆              ┆        │\n",
       "│     ┆ Embeddi…      ┆      ┆ language     ┆   ┆           ┆              ┆              ┆        │\n",
       "│     ┆               ┆      ┆ follow…      ┆   ┆           ┆              ┆              ┆        │\n",
       "│ 3   ┆ Graph2Seq:    ┆ 2018 ┆ Neural       ┆ … ┆ 6         ┆ 143          ┆ 0            ┆ 2018-0 │\n",
       "│     ┆ Scalable      ┆      ┆ networks are ┆   ┆           ┆              ┆              ┆        │\n",
       "│     ┆ Learning Dyn… ┆      ┆ increasingly ┆   ┆           ┆              ┆              ┆        │\n",
       "│     ┆               ┆      ┆ …            ┆   ┆           ┆              ┆              ┆        │\n",
       "└─────┴───────────────┴──────┴──────────────┴───┴───────────┴──────────────┴──────────────┴────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>title</th><th>year</th><th>abstract</th><th>keywords</th><th>txt_feat</th><th>num_title</th><th>num_abstract</th><th>num_keywords</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>&quot;StyleAlign: An…</td><td>2022</td><td>&quot;In this paper,…</td><td>&quot;StyleGAN, tran…</td><td>&quot;StyleAlign: An…</td><td>8</td><td>209</td><td>11</td></tr><tr><td>2</td><td>&quot;Embedding a ra…</td><td>2021</td><td>&quot;We develop a t…</td><td>&quot;Graph neural n…</td><td>&quot;Embedding a ra…</td><td>16</td><td>272</td><td>11</td></tr><tr><td>3</td><td>&quot;BBRefinement: …</td><td>2021</td><td>&quot;We present a c…</td><td>&quot;object detecti…</td><td>&quot;BBRefinement: …</td><td>11</td><td>152</td><td>6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 9)\n",
       "┌─────┬──────────────┬──────┬──────────────┬───┬─────────────┬───────────┬────────────┬────────────┐\n",
       "│ id  ┆ title        ┆ year ┆ abstract     ┆ … ┆ txt_feat    ┆ num_title ┆ num_abstra ┆ num_keywor │\n",
       "│ --- ┆ ---          ┆ ---  ┆ ---          ┆   ┆ ---         ┆ ---       ┆ ct         ┆ ds         │\n",
       "│ i64 ┆ str          ┆ i64  ┆ str          ┆   ┆ str         ┆ u32       ┆ ---        ┆ ---        │\n",
       "│     ┆              ┆      ┆              ┆   ┆             ┆           ┆ u32        ┆ u32        │\n",
       "╞═════╪══════════════╪══════╪══════════════╪═══╪═════════════╪═══════════╪════════════╪════════════╡\n",
       "│ 1   ┆ StyleAlign:  ┆ 2022 ┆ In this      ┆ … ┆ StyleAlign: ┆ 8         ┆ 209        ┆ 11         │\n",
       "│     ┆ Analysis and ┆      ┆ paper, we    ┆   ┆ Analysis    ┆           ┆            ┆            │\n",
       "│     ┆ Applica…     ┆      ┆ perform an   ┆   ┆ and         ┆           ┆            ┆            │\n",
       "│     ┆              ┆      ┆ in-…         ┆   ┆ Applica…    ┆           ┆            ┆            │\n",
       "│ 2   ┆ Embedding a  ┆ 2021 ┆ We develop a ┆ … ┆ Embedding a ┆ 16        ┆ 272        ┆ 11         │\n",
       "│     ┆ random graph ┆      ┆ theory for   ┆   ┆ random      ┆           ┆            ┆            │\n",
       "│     ┆ via GNN…     ┆      ┆ embeddin…    ┆   ┆ graph via   ┆           ┆            ┆            │\n",
       "│     ┆              ┆      ┆              ┆   ┆ GNN…        ┆           ┆            ┆            │\n",
       "│ 3   ┆ BBRefinement ┆ 2021 ┆ We present a ┆ … ┆ BBRefinemen ┆ 11        ┆ 152        ┆ 6          │\n",
       "│     ┆ : an         ┆      ┆ conceptually ┆   ┆ t: an       ┆           ┆            ┆            │\n",
       "│     ┆ universal    ┆      ┆ simple…      ┆   ┆ universal   ┆           ┆            ┆            │\n",
       "│     ┆ schem…       ┆      ┆              ┆   ┆ schem…      ┆           ┆            ┆            │\n",
       "└─────┴──────────────┴──────┴──────────────┴───┴─────────────┴───────────┴────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------\n",
    "# データ\n",
    "# ----------\n",
    "train = pl.read_csv(os.path.join(INPUT_DIR,'train_data.csv'))\n",
    "test = pl.read_csv(os.path.join(INPUT_DIR,'test_data.csv'))\n",
    "sub = pl.read_csv(os.path.join(INPUT_DIR,'submission.csv'))\n",
    "\n",
    "# ----------\n",
    "# 前処理・特徴生成\n",
    "# ----------\n",
    "set_seed(seed)\n",
    "\n",
    "# テキスト特徴の作成\n",
    "# グループごとにFold数を設定\n",
    "train =\\\n",
    "train.with_columns(\n",
    "    pl.concat_str(txt_columns, separator='_').alias('txt_feat'),\n",
    "    # title\n",
    "    pl.when(pl.col('title').str.to_lowercase().is_in(['', 'nan', '0', 'blank']))\n",
    "    .then(0)\n",
    "    .otherwise(pl.col('title').str.to_lowercase().str.count_match(' ') + 1)\n",
    "    .alias('num_title'),\n",
    "    # abstract\n",
    "    pl.when(pl.col('abstract').str.to_lowercase().is_in(['', 'nan', '0', 'blank']))\n",
    "    .then(0)\n",
    "    .otherwise(pl.col('abstract').str.to_lowercase().str.count_match(' ') + 1)\n",
    "    .alias('num_abstract'),\n",
    "    # keywords\n",
    "    pl.when(pl.col('keywords').str.to_lowercase().is_in(['', 'nan', '0', 'blank']))\n",
    "    .then(0)\n",
    "    .otherwise(pl.col('keywords').str.to_lowercase().str.count_match(' ') + 1)\n",
    "    .alias('num_keywords'),\n",
    "    # group\n",
    "    pl.concat_str(['year', 'y'], separator='-').alias('group'),\n",
    "    )\n",
    "\n",
    "test = \\\n",
    "test.with_columns(\n",
    "    pl.concat_str(txt_columns, separator='. ').alias('txt_feat'),\n",
    "    # title\n",
    "    pl.when(pl.col('title').str.to_lowercase().is_in(['', 'nan', '0', 'blank']))\n",
    "    .then(0)\n",
    "    .otherwise(pl.col('title').str.to_lowercase().str.count_match(' ') + 1)\n",
    "    .alias('num_title'),\n",
    "    # abstract\n",
    "    pl.when(pl.col('abstract').str.to_lowercase().is_in(['', 'nan', '0', 'blank']))\n",
    "    .then(0)\n",
    "    .otherwise(pl.col('abstract').str.to_lowercase().str.count_match(' ') + 1)\n",
    "    .alias('num_abstract'),\n",
    "    # keywords\n",
    "    pl.when(pl.col('keywords').str.to_lowercase().is_in(['', 'nan', '0', 'blank']))\n",
    "    .then(0)\n",
    "    .otherwise(pl.col('keywords').str.to_lowercase().str.count_match(' ') + 1)\n",
    "    .alias('num_keywords'),\n",
    "    )\n",
    "\n",
    "display(train.head(3))\n",
    "display(test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# BERT\n",
    "# ----------\n",
    "\n",
    "# Dataset\n",
    "class EmbedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df[idx, 'txt_feat']\n",
    "        tokens = tokenizer(\n",
    "                text,\n",
    "                None,\n",
    "                add_special_tokens=True,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=MAX_LEN,\n",
    "                return_tensors=\"pt\")\n",
    "        tokens = {k:v.squeeze(0) for k,v in tokens.items()}\n",
    "        return tokens\n",
    "\n",
    "# Pooling\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state.detach().cpu()\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "def get_embeddings(MODEL_NM='', MAX_LEN=512, BATCH_SIZE=4, verbose=True):\n",
    "    global tokenizer, DEVICE\n",
    "\n",
    "    model = AutoModel.from_pretrained(MODEL_NM)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NM)\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "        \n",
    "    # train\n",
    "    all_train_text_feats = []\n",
    "    for batch in tqdm(embed_dataloader_tr,total=len(embed_dataloader_tr)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n",
    "        # Normalize the embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n",
    "        all_train_text_feats.extend(sentence_embeddings)\n",
    "    all_train_text_feats = np.array(all_train_text_feats)\n",
    "    if verbose:\n",
    "        print('Train embeddings shape',all_train_text_feats.shape)\n",
    "    \n",
    "    # test\n",
    "    te_text_feats = []\n",
    "    for batch in tqdm(embed_dataloader_te,total=len(embed_dataloader_te)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n",
    "        # Normalize the embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n",
    "        te_text_feats.extend(sentence_embeddings)\n",
    "    te_text_feats = np.array(te_text_feats)\n",
    "    if verbose:\n",
    "        print('Test embeddings shape',te_text_feats.shape)\n",
    "        \n",
    "    # save feat\n",
    "    np.save(f\"{MODEL_NM.split('/')[-1]}_train\", all_train_text_feats)\n",
    "    np.save(f\"{MODEL_NM.split('/')[-1]}_test\", te_text_feats)\n",
    "\n",
    "    return all_train_text_feats, te_text_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_tr = EmbedDataset(train)\n",
    "embed_dataloader_tr = torch.utils.data.DataLoader(ds_tr,\\\n",
    "                        batch_size=BATCH_SIZE,\\\n",
    "                        shuffle=False)\n",
    "ds_te = EmbedDataset(test)\n",
    "embed_dataloader_te = torch.utils.data.DataLoader(ds_te,\\\n",
    "                        batch_size=BATCH_SIZE,\\\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e07d588c1e943f08002e23faa2ef945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape (4974, 768)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c51a10546a470dbe051f14ccf6e48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape (6393, 768)\n",
      "CPU times: user 9min 56s, sys: 30.9 s, total: 10min 26s\n",
      "Wall time: 9min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL_NM = 'microsoft/deberta-v3-base'\n",
    "train_emb, test_emb = get_embeddings(MODEL_NM, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb_col = [f'emb{i}' for i in range(train_emb.shape[1])]\n",
    "train_emb_df = pl.DataFrame(train_emb, schema=emb_col)\n",
    "train = pl.concat([train, train_emb_df], how='horizontal')\n",
    "test_emb_df = pl.DataFrame(test_emb, schema=emb_col)\n",
    "test = pl.concat([test, test_emb_df], how='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m\u001b[1m< Seed : 0 >\u001b[0m\n",
      "Device: NVIDIA RTX A4000\n",
      "Your runtime has 16.6 gigabytes of available RAM\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69119\n",
      "[100]\tvalidation_0-logloss:0.59761\n",
      "[200]\tvalidation_0-logloss:0.57961\n",
      "[300]\tvalidation_0-logloss:0.57701\n",
      "[389]\tvalidation_0-logloss:0.57869\n",
      "Fold : 1 Accuracy score: 0.7045226130653266\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69144\n",
      "[100]\tvalidation_0-logloss:0.60074\n",
      "[200]\tvalidation_0-logloss:0.58018\n",
      "[300]\tvalidation_0-logloss:0.57685\n",
      "[400]\tvalidation_0-logloss:0.57729\n",
      "[473]\tvalidation_0-logloss:0.57966\n",
      "Fold : 2 Accuracy score: 0.6924623115577889\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69109\n",
      "[100]\tvalidation_0-logloss:0.59339\n",
      "[200]\tvalidation_0-logloss:0.57009\n",
      "[300]\tvalidation_0-logloss:0.56556\n",
      "[400]\tvalidation_0-logloss:0.56567\n",
      "[421]\tvalidation_0-logloss:0.56658\n",
      "Fold : 3 Accuracy score: 0.7175879396984924\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69121\n",
      "[100]\tvalidation_0-logloss:0.59920\n",
      "[200]\tvalidation_0-logloss:0.58108\n",
      "[300]\tvalidation_0-logloss:0.57978\n",
      "[369]\tvalidation_0-logloss:0.58167\n",
      "Fold : 4 Accuracy score: 0.700502512562814\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69114\n",
      "[100]\tvalidation_0-logloss:0.59542\n",
      "[200]\tvalidation_0-logloss:0.57238\n",
      "[300]\tvalidation_0-logloss:0.56809\n",
      "[399]\tvalidation_0-logloss:0.57122\n",
      "Fold : 5 Accuracy score: 0.7032193158953722\n",
      "\n",
      "\u001b[30m\u001b[1mSeed0 Accuracy score : 0.7036590269400884\u001b[0m\n",
      "\n",
      "\u001b[30m\u001b[1m< Seed : 1 >\u001b[0m\n",
      "Device: NVIDIA RTX A4000\n",
      "Your runtime has 16.6 gigabytes of available RAM\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69129\n",
      "[100]\tvalidation_0-logloss:0.58950\n",
      "[200]\tvalidation_0-logloss:0.56372\n",
      "[300]\tvalidation_0-logloss:0.55677\n",
      "[400]\tvalidation_0-logloss:0.55598\n",
      "[447]\tvalidation_0-logloss:0.55707\n",
      "Fold : 1 Accuracy score: 0.7095477386934673\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69153\n",
      "[100]\tvalidation_0-logloss:0.60307\n",
      "[200]\tvalidation_0-logloss:0.59063\n",
      "[300]\tvalidation_0-logloss:0.59477\n",
      "[301]\tvalidation_0-logloss:0.59489\n",
      "Fold : 2 Accuracy score: 0.7045226130653266\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69100\n",
      "[100]\tvalidation_0-logloss:0.59313\n",
      "[200]\tvalidation_0-logloss:0.57065\n",
      "[300]\tvalidation_0-logloss:0.56701\n",
      "[400]\tvalidation_0-logloss:0.56837\n",
      "[434]\tvalidation_0-logloss:0.56887\n",
      "Fold : 3 Accuracy score: 0.6984924623115578\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69109\n",
      "[100]\tvalidation_0-logloss:0.59790\n",
      "[200]\tvalidation_0-logloss:0.57872\n",
      "[300]\tvalidation_0-logloss:0.57391\n",
      "[400]\tvalidation_0-logloss:0.57565\n",
      "[408]\tvalidation_0-logloss:0.57584\n",
      "Fold : 4 Accuracy score: 0.714572864321608\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69142\n",
      "[100]\tvalidation_0-logloss:0.60193\n",
      "[200]\tvalidation_0-logloss:0.58439\n",
      "[300]\tvalidation_0-logloss:0.58014\n",
      "[400]\tvalidation_0-logloss:0.57990\n",
      "[485]\tvalidation_0-logloss:0.58282\n",
      "Fold : 5 Accuracy score: 0.6941649899396378\n",
      "\n",
      "\u001b[30m\u001b[1mSeed1 Accuracy score : 0.7042621632488942\u001b[0m\n",
      "\n",
      "\u001b[30m\u001b[1m< Seed : 2 >\u001b[0m\n",
      "Device: NVIDIA RTX A4000\n",
      "Your runtime has 16.6 gigabytes of available RAM\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69129\n",
      "[100]\tvalidation_0-logloss:0.60204\n",
      "[200]\tvalidation_0-logloss:0.58233\n",
      "[300]\tvalidation_0-logloss:0.57881\n",
      "[391]\tvalidation_0-logloss:0.58133\n",
      "Fold : 1 Accuracy score: 0.7045226130653266\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69131\n",
      "[100]\tvalidation_0-logloss:0.59819\n",
      "[200]\tvalidation_0-logloss:0.58281\n",
      "[300]\tvalidation_0-logloss:0.58404\n",
      "[329]\tvalidation_0-logloss:0.58481\n",
      "Fold : 2 Accuracy score: 0.6954773869346733\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69114\n",
      "[100]\tvalidation_0-logloss:0.59120\n",
      "[200]\tvalidation_0-logloss:0.56635\n",
      "[300]\tvalidation_0-logloss:0.56049\n",
      "[400]\tvalidation_0-logloss:0.56052\n",
      "[433]\tvalidation_0-logloss:0.56199\n",
      "Fold : 3 Accuracy score: 0.7015075376884422\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69102\n",
      "[100]\tvalidation_0-logloss:0.59866\n",
      "[200]\tvalidation_0-logloss:0.57851\n",
      "[300]\tvalidation_0-logloss:0.57523\n",
      "[366]\tvalidation_0-logloss:0.57578\n",
      "Fold : 4 Accuracy score: 0.7185929648241206\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.69115\n",
      "[100]\tvalidation_0-logloss:0.59747\n",
      "[200]\tvalidation_0-logloss:0.57638\n",
      "[300]\tvalidation_0-logloss:0.57451\n",
      "[358]\tvalidation_0-logloss:0.57485\n",
      "Fold : 5 Accuracy score: 0.693158953722334\n",
      "\n",
      "\u001b[30m\u001b[1mSeed2 Accuracy score : 0.7026537997587454\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[30m\u001b[1mwhole Accuracy score: 0.7070767993566546\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>counts</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>6082</td></tr><tr><td>1</td><td>311</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────┬────────┐\n",
       "│     ┆ counts │\n",
       "│ --- ┆ ---    │\n",
       "│ i64 ┆ u32    │\n",
       "╞═════╪════════╡\n",
       "│ 0   ┆ 6082   │\n",
       "│ 1   ┆ 311    │\n",
       "└─────┴────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run XGBoost\n",
    "use_col = ['num_title', 'num_abstract', 'num_keywords'] + emb_col\n",
    "test_x = test.select(use_col).to_numpy()\n",
    "\n",
    "whole_va_preds = []\n",
    "whole_test_preds = []\n",
    "for seed in range(3):\n",
    "    print(fontstyle.apply(f'< Seed : {seed} >', 'BLACK/BOLD'))\n",
    "    set_seed(seed)\n",
    "    train = train.with_columns(\n",
    "        pl.Series(get_stratifiedkfold(train, 'group', num_fold, seed))\n",
    "        .alias('folds')\n",
    "        )\n",
    "    \n",
    "    oof_preds = np.zeros((len(train), ), dtype=np.float32)\n",
    "    preds = []\n",
    "    for fold in range(num_fold):\n",
    "        tr_x = train.filter(pl.col('folds')!=fold).select(use_col).to_numpy()\n",
    "        tr_y = train.filter(pl.col('folds')!=fold).select('y').to_numpy()\n",
    "        va_x = train.filter(pl.col('folds')==fold).select(use_col).to_numpy()\n",
    "        va_y = train.filter(pl.col('folds')==fold).select('y').to_numpy()\n",
    "\n",
    "        params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'n_estimators': 10000,\n",
    "        'random_state': 0, \n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 8,\n",
    "        'colsample_bytree': 1.0,\n",
    "        'colsample_bylevel': 0.5,\n",
    "        'subsample': 0.9,\n",
    "        'gamma': 0,\n",
    "        'lambda': 1,\n",
    "        'alpha': 0,\n",
    "        'min_child_weight': 1,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        }\n",
    "\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        clf.fit(\n",
    "            tr_x, tr_y,\n",
    "            eval_set=[(va_x, va_y)],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100)\n",
    "\n",
    "        va_preds_p = clf.predict_proba(va_x)[:, 1]\n",
    "        oof_preds[\n",
    "            train.select(\n",
    "                pl.when(pl.col('folds')==fold).then(True).otherwise(False)\n",
    "                ).to_numpy().reshape(-1).astype(bool)\n",
    "                ] = va_preds_p\n",
    "        va_preds = (va_preds_p > 0.5).astype(int)\n",
    "        score = accuracy_score(va_y, va_preds)\n",
    "        print(f'Fold : {fold+1} Accuracy score: {score}')\n",
    "        print()\n",
    "        test_preds_p = clf.predict_proba(test_x)[:, 1]\n",
    "        preds.append(test_preds_p)\n",
    "\n",
    "    score_s = accuracy_score(train.select('y').to_numpy(), oof_preds > 0.5)\n",
    "    print(fontstyle.apply(f'Seed{seed} Accuracy score : {score_s}', 'BLACK/BOLD'))\n",
    "    print()\n",
    "    whole_va_preds.append(oof_preds)\n",
    "    whole_test_preds.append(preds)\n",
    "\n",
    "# preds_va_p = np.mean(whole_va_preds, axis=0)\n",
    "# whole_score = accuracy_score(train.select('y').to_numpy(), preds_va_p > 0.5)\n",
    "# preds_test = (np.mean(np.mean(whole_test_preds, axis=0), axis=0) > 0.5).astype(int)\n",
    "preds_va = np.array([np.where(preds > 0.5, 1, 0) for preds in whole_va_preds])\n",
    "whole_score = accuracy_score(train.select('y').to_numpy(), stats.mode(preds_va, axis=0).mode.flatten())\n",
    "test_preds_array = np.array(whole_test_preds)\n",
    "test_preds_array = test_preds_array.reshape(test_preds_array.shape[0]*test_preds_array.shape[1], -1)\n",
    "preds_test = np.array([np.where(preds > 0.5, 1, 0) for preds in test_preds_array])\n",
    "preds_test = stats.mode(preds_test, axis=0).mode.flatten()\n",
    "print()  \n",
    "print(fontstyle.apply(f'whole Accuracy score: {whole_score}', 'BLACK/BOLD'))\n",
    "print()\n",
    "\n",
    "display(pl.Series(preds_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
